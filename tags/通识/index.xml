<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>通识 on Nono Blogs</title><link>https://blog.jqknono.com/tags/%E9%80%9A%E8%AF%86/</link><description>Recent content in 通识 on Nono Blogs</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 14 Oct 2025 09:59:51 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/tags/%E9%80%9A%E8%AF%86/index.xml" rel="self" type="application/rss+xml"/><item><title>为何大模型的召回率指标重要</title><link>https://blog.jqknono.com/blog/2025/10/14/%E4%B8%BA%E4%BD%95%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%8C%87%E6%A0%87%E9%87%8D%E8%A6%81/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/10/14/%E4%B8%BA%E4%BD%95%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%8C%87%E6%A0%87%E9%87%8D%E8%A6%81/</guid><description>&lt;p&gt;读了一些系统提示词, 基本都非常冗长, 表达不精炼. 一些提示词主要是教模型做事.&lt;/p&gt;
&lt;p&gt;另外看到 roo code 里有重复将系统提示词发送到模型的开关, 说明是可以强化角色设定, 和指令遵循. 但会增加 token 消耗.&lt;/p&gt;
&lt;p&gt;可能是因为重要的东西需要重复多次, 以提升在计算时的权重, 提升被确认的概率, 最终得到更有可能正确的结果. 可惜的是, 这样的结果仍然是概率性正确.&lt;/p&gt;
&lt;p&gt;长时间用过 claude 模型和 gpt5high 的可能有感触, gpt5high 尽管很慢, 但是正确率非常高.&lt;/p&gt;
&lt;p&gt;是否可能和 gpt5 的召回率达到 100%有关.&lt;/p&gt;
&lt;p&gt;我在使用 AGENTS.md 指挥 gpt5 干活时发现, 只需要非常简练, 精炼的话, 即可以指挥 codex cli 干活.
而使用 claude code 时, 常常需要将 CLAUDE.md 写的非常&amp;quot;啰嗦&amp;quot;, 即使这样, claude 也会忽略一些明确要求的注意事项. 改善方式也并不一定需要重复说一个要求, 使用不同的词汇如&amp;quot;必须&amp;quot;, &amp;ldquo;重要&amp;quot;等字词, 使用括号, markdown 的加粗(**), 都可以加强遵循性.&lt;/p&gt;
&lt;p&gt;也就是说, 使用 claude 模型时, 对提示词的要求较高, 细微词汇变化即会影响模型表现.
而使用 gpt5 时, 对提示词的要求不高, 只要精炼的表达不存在逻辑矛盾之处, codex cli 就可以做的很好. 如果存在逻辑矛盾之处, gpt5 会指出来.&lt;/p&gt;</description></item></channel></rss>