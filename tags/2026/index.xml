<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2026 on jqknono Blogs</title><link>https://blog.jqknono.com/tags/2026/</link><description>Recent content in 2026 on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 11 Feb 2026 10:55:39 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/tags/2026/index.xml" rel="self" type="application/rss+xml"/><item><title>return-to-gpt-non-codex</title><link>https://blog.jqknono.com/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;OpenAI seems eager to push the Codex model; GPT-5.3 isn&amp;rsquo;t out yet, but GPT-5.3-Codex came out first. For the same price, Codex generates output more proactively, has shorter execution times, and occupies memory for less time, offering greater profit margins.&lt;/p&gt;
&lt;p&gt;I had a great experience using GPT-5.3-Codex during its first week of release, mainly due to its speed and timely feedback. However, by the second week, its speed decreased noticeably. Furthermore, its logical rigor is not as good as the GPT non-Codex series. Therefore, I still recommend the non-Codex series. The probability of getting it right on the first try remains the highest. It won&amp;rsquo;t do anything beyond what is described, but what is described, it does without bugs.&lt;/p&gt;</description></item><item><title>Debugging Record: OpenRouter gpt-oss-120b Model Does Not Support Chinese Requests</title><link>https://blog.jqknono.com/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><guid>https://blog.jqknono.com/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;While using the free model API provided by &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, I encountered a confusing issue. With the exact same request structure, simply changing the language of the prompt resulted in completely different outcomes.&lt;/p&gt;
&lt;h2 id="problem-reproduction"&gt;Problem Reproduction&lt;/h2&gt;
&lt;p&gt;I used the &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; model for testing. The only difference between the two requests was the language of the prompt. The first request used a Chinese prompt:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This request always returned a 429 status code, indicating that the request rate was too high or the quota limit was exceeded. However, when I used an English prompt:&lt;/p&gt;</description></item></channel></rss>