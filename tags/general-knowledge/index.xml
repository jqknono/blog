<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>General Knowledge on jqknono Blogs</title><link>https://blog.jqknono.com/tags/general-knowledge/</link><description>Recent content in General Knowledge on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 14 Oct 2025 09:59:51 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/tags/general-knowledge/index.xml" rel="self" type="application/rss+xml"/><item><title>Why Recall Rate Metrics Are Important for Large Models</title><link>https://blog.jqknono.com/blog/2025/10/14/why-recall-rate-metrics-are-important-for-large-models/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/10/14/why-recall-rate-metrics-are-important-for-large-models/</guid><description>&lt;p&gt;I&amp;rsquo;ve read some system prompts, and most are very verbose and not concise. Some prompts mainly teach the model how to do things.&lt;/p&gt;
&lt;p&gt;Additionally, I noticed that in roo code there&amp;rsquo;s a switch to repeatedly send the system prompt to the model, indicating that it can reinforce role settings and instruction following. However, this increases token consumption.&lt;/p&gt;
&lt;p&gt;This might be because important things need to be repeated multiple times to increase their weight during computation, enhance the probability of confirmation, and ultimately obtain more likely correct results. Unfortunately, such results are still probabilistically correct.&lt;/p&gt;</description></item></channel></rss>