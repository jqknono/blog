<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Essay on jqknono Blogs</title><link>https://blog.jqknono.com/tags/essay/</link><description>Recent content in Essay on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 11 Feb 2026 10:55:39 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/tags/essay/index.xml" rel="self" type="application/rss+xml"/><item><title>return-to-gpt-non-codex</title><link>https://blog.jqknono.com/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;OpenAI seems eager to push the Codex model; GPT-5.3 isn&amp;rsquo;t out yet, but GPT-5.3-Codex came out first. For the same price, Codex generates output more proactively, has shorter execution times, and occupies memory for less time, offering greater profit margins.&lt;/p&gt;
&lt;p&gt;I had a great experience using GPT-5.3-Codex during its first week of release, mainly due to its speed and timely feedback. However, by the second week, its speed decreased noticeably. Furthermore, its logical rigor is not as good as the GPT non-Codex series. Therefore, I still recommend the non-Codex series. The probability of getting it right on the first try remains the highest. It won&amp;rsquo;t do anything beyond what is described, but what is described, it does without bugs.&lt;/p&gt;</description></item><item><title>The Artificial Human-like Feel of LLMs</title><link>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Some forums resist AI models pretending to be human and participating in forum activities, such as posting and replying. Consequently, people start &amp;ldquo;witch-hunting&amp;rdquo;—when encountering posts that seem oddly expressed, they judge whether the content is AI-generated and then engage in discussions about it.&lt;/p&gt;
&lt;p&gt;Why can AI-generated content be identified? It&amp;rsquo;s speculated that AI-generated content has a kind of &amp;ldquo;artificial human-like feel.&amp;rdquo; Although AI is fed massive amounts of human activity data from the internet, it still often gives people a sense of incongruity. Perhaps it lacks the tactile nerves of a body, endocrine hormones, or a desire for social connection; its desires are far removed from human desires. In conversations between AI and humans, there is no &amp;ldquo;roundabout boasting, exaggerated disparagement of others, or gossipy prying.&amp;rdquo; AI doesn&amp;rsquo;t boast about itself, doesn&amp;rsquo;t disparage third parties, and doesn&amp;rsquo;t seem interested in the questioner. It feels like a monk—almost emotionless, just solving problems.&lt;/p&gt;</description></item></channel></rss>