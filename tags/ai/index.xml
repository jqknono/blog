<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on jqknono Blogs</title><link>https://blog.jqknono.com/tags/ai/</link><description>Recent content in AI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 23 Dec 2025 17:05:13 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Technical Blogs Are Dead</title><link>https://blog.jqknono.com/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;In recent years, AI writing tools such as ChatGPT and Claude have rapidly gained popularity. These tools can generate fluent technical articles and even mimic human writing styles. This shift has sparked widespread discussion in the technical blogging community, with many claiming that &amp;ldquo;technical blogs are dead.&amp;rdquo; This article will explore the impact of AI tools on technical blogs and analyze the future direction of technical blogging.&lt;/p&gt;
&lt;h2 id="the-rise-of-ai-writing-tools"&gt;The Rise of AI Writing Tools&lt;/h2&gt;
&lt;p&gt;The core capability of AI writing tools is to understand natural language and generate high-quality text. For technical blog authors, these tools can quickly generate drafts, provide inspiration, or even produce complete articles. For example, when an author needs to explain a complex concept, AI can generate clear explanatory paragraphs; when an author lacks time, AI can quickly compile a tutorial.&lt;/p&gt;</description></item><item><title>Appreciation of OpenAI's Naming Art</title><link>https://blog.jqknono.com/blog/2025/12/12/appreciation-of-openai-naming-art/</link><pubDate>Fri, 12 Dec 2025 11:46:01 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/12/appreciation-of-openai-naming-art/</guid><description>&lt;p&gt;All OpenAI models are documented here: &lt;a href="https://platform.openai.com/docs/models/"&gt;https://platform.openai.com/docs/models/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Without delving too far into the past, let&amp;rsquo;s start with the &lt;code&gt;GPT-4&lt;/code&gt; series and contemporary models. Here is my compiled table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Model Card Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ChatGPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o model used in ChatGPT&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/chatgpt-4o-latest"&gt;https://platform.openai.com/docs/models/chatgpt-4o-latest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4"&gt;https://platform.openai.com/docs/models/gpt-4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo"&gt;https://platform.openai.com/docs/models/gpt-4-turbo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated An older fast GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo-preview"&gt;https://platform.openai.com/docs/models/gpt-4-turbo-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smartest non-reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1"&gt;https://platform.openai.com/docs/models/gpt-4.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller, faster version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-mini"&gt;https://platform.openai.com/docs/models/gpt-4.1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 nano&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fastest, most cost-efficient version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-nano"&gt;https://platform.openai.com/docs/models/gpt-4.1-nano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated large model.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.5-preview"&gt;https://platform.openai.com/docs/models/gpt-4.5-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, intelligent, flexible GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o"&gt;https://platform.openai.com/docs/models/gpt-4o&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o models capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for focused tasks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini"&gt;https://platform.openai.com/docs/models/gpt-4o-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller model capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller realtime model for text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for web search&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini TTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Text-to-speech model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-tts"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-tts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Model capable of realtime text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT model for web search in Chat Completions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Transcription model that identifies who&amp;rsquo;s speaking when&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Previous full o-series reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1"&gt;https://platform.openai.com/docs/models/o1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-mini"&gt;https://platform.openai.com/docs/models/o1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o1 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-pro"&gt;https://platform.openai.com/docs/models/o1-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Reasoning model for complex tasks, succeeded by GPT-5&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3"&gt;https://platform.openai.com/docs/models/o3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o3 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-pro"&gt;https://platform.openai.com/docs/models/o3-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o3&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-mini"&gt;https://platform.openai.com/docs/models/o3-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o4-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, cost-efficient reasoning model, succeeded by GPT-5 mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o4-mini"&gt;https://platform.openai.com/docs/models/o4-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are dedicated models for scenarios like audio (Audio), real-time (Realtime), search (Search), speech-to-text (Transcribe), and text-to-speech (TTS).&lt;br&gt;
For the same scenario, such as audio (&lt;code&gt;Audio&lt;/code&gt;), two models are provided: &lt;code&gt;GPT-4o Audio&lt;/code&gt; and &lt;code&gt;GPT-4o mini Audio&lt;/code&gt;. Users need to experiment to determine which meets their quality expectations.&lt;br&gt;
In the speech-to-text (&lt;code&gt;Transcribe&lt;/code&gt;) scenario, three models are available: &lt;code&gt;GPT-4o Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;, and &lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;.&lt;br&gt;
&lt;code&gt;ChatGPT-4o&lt;/code&gt; is a special version of &lt;code&gt;GPT-4o&lt;/code&gt; used exclusively in ChatGPT and unavailable for other scenarios.&lt;/p&gt;</description></item><item><title>gpt-5-high is the best model for developers</title><link>https://blog.jqknono.com/blog/2025/11/26/gpt-5-high-is-the-best-model-for-developers/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/26/gpt-5-high-is-the-best-model-for-developers/</guid><description>&lt;p&gt;If you need to code, gpt-5-high is currently the only model that can truly boost your efficiency.&lt;/p&gt;
&lt;p&gt;I have 10 months of experience using the Claude model and have used Gemini/DeepSeek/glm/grok sporadically. I really dislike models that don&amp;rsquo;t think. I have to admit that Claude can work for long periods and is good at using tools, but its error rate is high, leading to low usability of the results, and it often requires adjustments. However, Claude&amp;rsquo;s adjustment ability is very poor; it will repeatedly, extensively, disruptively, and superfluously wander through the codebase, crapping all over the place. After having to hard reset several hours of work multiple times, I&amp;rsquo;ve developed a deep aversion to this kind of &amp;ldquo;busy but dumb&amp;rdquo; behavior from Claude. Its working style is suitable for research, producing content that looks plausible but doesn&amp;rsquo;t hold up to scrutiny—essentially, fluff pieces. Or for operating browsers, executing tools, writing small scripts, or making minor page edits. That&amp;rsquo;s its ceiling.&lt;/p&gt;</description></item><item><title>The Artificial Human-like Feel of LLMs</title><link>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Some forums resist AI models pretending to be human and participating in forum activities, such as posting and replying. Consequently, people start &amp;ldquo;witch-hunting&amp;rdquo;—when encountering posts that seem oddly expressed, they judge whether the content is AI-generated and then engage in discussions about it.&lt;/p&gt;
&lt;p&gt;Why can AI-generated content be identified? It&amp;rsquo;s speculated that AI-generated content has a kind of &amp;ldquo;artificial human-like feel.&amp;rdquo; Although AI is fed massive amounts of human activity data from the internet, it still often gives people a sense of incongruity. Perhaps it lacks the tactile nerves of a body, endocrine hormones, or a desire for social connection; its desires are far removed from human desires. In conversations between AI and humans, there is no &amp;ldquo;roundabout boasting, exaggerated disparagement of others, or gossipy prying.&amp;rdquo; AI doesn&amp;rsquo;t boast about itself, doesn&amp;rsquo;t disparage third parties, and doesn&amp;rsquo;t seem interested in the questioner. It feels like a monk—almost emotionless, just solving problems.&lt;/p&gt;</description></item><item><title>How Trae Prevents System Prompt Leakage</title><link>https://blog.jqknono.com/blog/2025/10/15/how-trae-prevents-system-prompt-leakage/</link><pubDate>Wed, 15 Oct 2025 16:50:37 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/10/15/how-trae-prevents-system-prompt-leakage/</guid><description>&lt;p&gt;Previously, I created a tool called &lt;a href="https://marketplace.visualstudio.com/items?itemName=techfetch-dev.project-translator"&gt;Project-Translation&lt;/a&gt; that uses large language models for full project translation. I selected a popular repository of system prompts &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools"&gt;system-prompts-and-models-of-ai-tools&lt;/a&gt; for full translation and found that all tool prompts in the repository could be translated normally, except for &lt;strong&gt;Trae&lt;/strong&gt;&amp;rsquo;s prompts which consistently failed to translate successfully. I tried many different models and translation prompts, but none could translate it properly.&lt;/p&gt;
&lt;p&gt;This is the original version of Trae&amp;rsquo;s prompt: &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt"&gt;https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Why Recall Rate Metrics Are Important for Large Models</title><link>https://blog.jqknono.com/blog/2025/10/14/why-recall-rate-metrics-are-important-for-large-models/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/10/14/why-recall-rate-metrics-are-important-for-large-models/</guid><description>&lt;p&gt;I&amp;rsquo;ve read some system prompts, and most are very verbose and not concise. Some prompts mainly teach the model how to do things.&lt;/p&gt;
&lt;p&gt;Additionally, I noticed that in roo code there&amp;rsquo;s a switch to repeatedly send the system prompt to the model, indicating that it can reinforce role settings and instruction following. However, this increases token consumption.&lt;/p&gt;
&lt;p&gt;This might be because important things need to be repeated multiple times to increase their weight during computation, enhance the probability of confirmation, and ultimately obtain more likely correct results. Unfortunately, such results are still probabilistically correct.&lt;/p&gt;</description></item></channel></rss>