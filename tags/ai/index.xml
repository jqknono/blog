<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on jqknono Blogs</title><link>https://blog.jqknono.com/tags/ai/</link><description>Recent content in AI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 26 Nov 2025 14:44:57 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>gpt-5-high is the best model for developers</title><link>https://blog.jqknono.com/blog/2025/11/26/gpt-5-high-is-the-best-model-for-developers/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/26/gpt-5-high-is-the-best-model-for-developers/</guid><description>&lt;p&gt;If you need to code, gpt-5-high is currently the only model that can truly boost your efficiency.&lt;/p&gt;
&lt;p&gt;I have 10 months of experience using the Claude model and have used Gemini/DeepSeek/glm/grok sporadically. I really dislike models that don&amp;rsquo;t think. I have to admit that Claude can work for long periods and is good at using tools, but its error rate is high, leading to low usability of the results, and it often requires adjustments. However, Claude&amp;rsquo;s adjustment ability is very poor; it will repeatedly, extensively, disruptively, and superfluously wander through the codebase, crapping all over the place. After having to hard reset several hours of work multiple times, I&amp;rsquo;ve developed a deep aversion to this kind of &amp;ldquo;busy but dumb&amp;rdquo; behavior from Claude. Its working style is suitable for research, producing content that looks plausible but doesn&amp;rsquo;t hold up to scrutiny—essentially, fluff pieces. Or for operating browsers, executing tools, writing small scripts, or making minor page edits. That&amp;rsquo;s its ceiling.&lt;/p&gt;</description></item><item><title>The Artificial Human-like Feel of LLMs</title><link>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Some forums resist AI models pretending to be human and participating in forum activities, such as posting and replying. Consequently, people start &amp;ldquo;witch-hunting&amp;rdquo;—when encountering posts that seem oddly expressed, they judge whether the content is AI-generated and then engage in discussions about it.&lt;/p&gt;
&lt;p&gt;Why can AI-generated content be identified? It&amp;rsquo;s speculated that AI-generated content has a kind of &amp;ldquo;artificial human-like feel.&amp;rdquo; Although AI is fed massive amounts of human activity data from the internet, it still often gives people a sense of incongruity. Perhaps it lacks the tactile nerves of a body, endocrine hormones, or a desire for social connection; its desires are far removed from human desires. In conversations between AI and humans, there is no &amp;ldquo;roundabout boasting, exaggerated disparagement of others, or gossipy prying.&amp;rdquo; AI doesn&amp;rsquo;t boast about itself, doesn&amp;rsquo;t disparage third parties, and doesn&amp;rsquo;t seem interested in the questioner. It feels like a monk—almost emotionless, just solving problems.&lt;/p&gt;</description></item><item><title>How Trae Prevents System Prompt Leakage</title><link>https://blog.jqknono.com/blog/2025/10/15/how-trae-prevents-system-prompt-leakage/</link><pubDate>Wed, 15 Oct 2025 16:50:37 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/10/15/how-trae-prevents-system-prompt-leakage/</guid><description>&lt;p&gt;Previously, I created a tool called &lt;a href="https://marketplace.visualstudio.com/items?itemName=techfetch-dev.project-translator"&gt;Project-Translation&lt;/a&gt; that uses large language models for full project translation. I selected a popular repository of system prompts &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools"&gt;system-prompts-and-models-of-ai-tools&lt;/a&gt; for full translation and found that all tool prompts in the repository could be translated normally, except for &lt;strong&gt;Trae&lt;/strong&gt;&amp;rsquo;s prompts which consistently failed to translate successfully. I tried many different models and translation prompts, but none could translate it properly.&lt;/p&gt;
&lt;p&gt;This is the original version of Trae&amp;rsquo;s prompt: &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt"&gt;https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Why Recall Rate Metrics Are Important for Large Models</title><link>https://blog.jqknono.com/blog/2025/10/14/why-recall-rate-metrics-are-important-for-large-models/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/10/14/why-recall-rate-metrics-are-important-for-large-models/</guid><description>&lt;p&gt;I&amp;rsquo;ve read some system prompts, and most are very verbose and not concise. Some prompts mainly teach the model how to do things.&lt;/p&gt;
&lt;p&gt;Additionally, I noticed that in roo code there&amp;rsquo;s a switch to repeatedly send the system prompt to the model, indicating that it can reinforce role settings and instruction following. However, this increases token consumption.&lt;/p&gt;
&lt;p&gt;This might be because important things need to be repeated multiple times to increase their weight during computation, enhance the probability of confirmation, and ultimately obtain more likely correct results. Unfortunately, such results are still probabilistically correct.&lt;/p&gt;</description></item><item><title>GitHub Spec Kit: An In-Depth Analysis of the Official Specification-Driven Development Toolkit</title><link>https://blog.jqknono.com/blog/2025/09/30/github-spec-kit-an-in-depth-analysis-of-the-official-specification-driven-development-toolkit/</link><pubDate>Tue, 30 Sep 2025 16:36:08 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/09/30/github-spec-kit-an-in-depth-analysis-of-the-official-specification-driven-development-toolkit/</guid><description>&lt;h1 id="github-spec-kit-an-in-depth-analysis-of-the-official-specification-driven-development-toolkit"&gt;GitHub Spec Kit: An In-Depth Analysis of the Official Specification-Driven Development Toolkit&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Target Audience: Software Developers, Technical Team Leaders, DevOps Engineers, Product Managers
Keywords: GitHub, Spec-Driven Development, AI, Development Tools, Software Engineering&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="abstract"&gt;Abstract&lt;/h2&gt;
&lt;p&gt;GitHub Spec Kit is GitHub&amp;rsquo;s official specification-driven development toolkit that fundamentally transforms traditional software development models by turning specification documents into executable code. It supports multiple AI programming assistants and provides a complete workflow for project initialization, specification creation, technical planning, task decomposition, and code generation. Spec Kit allows developers to focus on business requirements rather than technical implementation details, significantly improving development efficiency and code quality.&lt;/p&gt;</description></item></channel></rss>