<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>خواطر on jqknono Blogs</title><link>https://blog.jqknono.com/ar-ae/categories/%D8%AE%D9%88%D8%A7%D8%B7%D8%B1/</link><description>Recent content in خواطر on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>ar-ae</language><lastBuildDate>Wed, 11 Feb 2026 10:55:39 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/ar-ae/categories/%D8%AE%D9%88%D8%A7%D8%B7%D8%B1/index.xml" rel="self" type="application/rss+xml"/><item><title>return-to-gpt-non-codex</title><link>https://blog.jqknono.com/ar-ae/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/ar-ae/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;يبدو أن OpenAI حريصة جدًا على الترويج لنموذج Codex. فقبل صدور GPT-5.3، تم إصدار GPT-5.3-Codex أولاً. وبنفس السعر، يقدم Codex مخرجات أكثر نشاطًا، ووقت تنفيذ أقصر، واستهلاك أقل للذاكرة، مما يوفر هامش ربح أكبر.&lt;/p&gt;
&lt;p&gt;في الأسبوع الأول من إصدار GPT-5.3-Codex، كانت تجربتي جيدة جداً، وذلك يعود بشكل رئيسي إلى سرعته واستجابته الفورية. ولكن بحلول الأسبوع الثاني، تباطأ سرعته بوضوح. وفي الوقت نفسه، فإن دقة تفكيره ليست بجودة سلسلة GPT غير Codex. لذلك، ما زلت أوصي بسلسلة غير Codex، حيث تظل احتمالية القيام بالعمل بشكل صحيح من المحاولة الأولى هي الأعلى؛ فهو لن يقوم بأمور تتجاوز الوصف، لكنه ينفذ ما تم وصفه بدون أخطاء (bugs).&lt;/p&gt;</description></item></channel></rss>