<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on jqknono Blogs</title><link>https://blog.jqknono.com/categories/ai/</link><description>Recent content in AI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 26 Nov 2025 14:44:57 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/categories/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>gpt-5-high is the best model for developers</title><link>https://blog.jqknono.com/blog/2025/11/26/gpt-5-high-is-the-best-model-for-developers/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/26/gpt-5-high-is-the-best-model-for-developers/</guid><description>&lt;p&gt;If you need to code, gpt-5-high is currently the only model that can truly boost your efficiency.&lt;/p&gt;
&lt;p&gt;I have 10 months of experience using the Claude model and have used Gemini/DeepSeek/glm/grok sporadically. I really dislike models that don&amp;rsquo;t think. I have to admit that Claude can work for long periods and is good at using tools, but its error rate is high, leading to low usability of the results, and it often requires adjustments. However, Claude&amp;rsquo;s adjustment ability is very poor; it will repeatedly, extensively, disruptively, and superfluously wander through the codebase, crapping all over the place. After having to hard reset several hours of work multiple times, I&amp;rsquo;ve developed a deep aversion to this kind of &amp;ldquo;busy but dumb&amp;rdquo; behavior from Claude. Its working style is suitable for research, producing content that looks plausible but doesn&amp;rsquo;t hold up to scrutiny—essentially, fluff pieces. Or for operating browsers, executing tools, writing small scripts, or making minor page edits. That&amp;rsquo;s its ceiling.&lt;/p&gt;</description></item><item><title>The Artificial Human-like Feel of LLMs</title><link>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Some forums resist AI models pretending to be human and participating in forum activities, such as posting and replying. Consequently, people start &amp;ldquo;witch-hunting&amp;rdquo;—when encountering posts that seem oddly expressed, they judge whether the content is AI-generated and then engage in discussions about it.&lt;/p&gt;
&lt;p&gt;Why can AI-generated content be identified? It&amp;rsquo;s speculated that AI-generated content has a kind of &amp;ldquo;artificial human-like feel.&amp;rdquo; Although AI is fed massive amounts of human activity data from the internet, it still often gives people a sense of incongruity. Perhaps it lacks the tactile nerves of a body, endocrine hormones, or a desire for social connection; its desires are far removed from human desires. In conversations between AI and humans, there is no &amp;ldquo;roundabout boasting, exaggerated disparagement of others, or gossipy prying.&amp;rdquo; AI doesn&amp;rsquo;t boast about itself, doesn&amp;rsquo;t disparage third parties, and doesn&amp;rsquo;t seem interested in the questioner. It feels like a monk—almost emotionless, just solving problems.&lt;/p&gt;</description></item></channel></rss>