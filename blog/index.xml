<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on jqknono Blogs</title><link>https://blog.jqknono.com/blog/</link><description>Recent content in Blog on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 13 Nov 2023 14:15:31 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Cost Formulas and Break-Even Points for Vibe Coding</title><link>https://blog.jqknono.com/blog/2026/01/07/vibe-coding-cost-formulas/</link><pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate><guid>https://blog.jqknono.com/blog/2026/01/07/vibe-coding-cost-formulas/</guid><description>&lt;p&gt;AI coding tools can be categorized into three billing models:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Per-token billing&lt;/strong&gt;: Includes various APIs, Claude Code (Claude Pro), Codex Cli (ChatGPT Plus), Zhipu Lite/Pro, Cursor (new version), etc. These are fundamentally token-based, with some products offering package discounts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Per-API call billing&lt;/strong&gt;: Such as OpenRouter (free quota), ModelScope, Gemini Code Assistant (1,000 free calls per day), Chutes, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Per-prompt billing&lt;/strong&gt;: Such as Cursor (legacy version, 500 prompts), Github Copilot (300 prompts), etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These three models are essentially paying for model inference and context processing, differing only in pricing granularity and quota forms.&lt;/p&gt;</description></item><item><title>Setting Up a Remote Browser Debugging Endpoint on Windows</title><link>https://blog.jqknono.com/blog/2026/01/01/windows-remote-browser-cdp/</link><pubDate>Thu, 01 Jan 2026 10:30:00 +0800</pubDate><guid>https://blog.jqknono.com/blog/2026/01/01/windows-remote-browser-cdp/</guid><description>&lt;p&gt;This article explains how to run Chrome on a Windows host and expose a remote debugging endpoint via CDP for LAN clients or MCP to connect. The core of the solution is that Chrome only listens on 127.0.0.1, which is then mapped to a LAN address via portproxy, and further restricted by firewall rules for remote sources.&lt;/p&gt;
&lt;h2 id="topology-and-flow"&gt;Topology and Flow&lt;/h2&gt;
&lt;p&gt;The diagram below illustrates the port flow within the Windows host and how clients access it over the LAN.&lt;/p&gt;</description></item><item><title>Technical Blogs Are Dead</title><link>https://blog.jqknono.com/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;In recent years, AI writing tools such as ChatGPT and Claude have rapidly gained popularity. These tools can generate fluent technical articles and even mimic human writing styles. This shift has sparked widespread discussion in the technical blogging community, with many claiming that &amp;ldquo;technical blogs are dead.&amp;rdquo; This article will explore the impact of AI tools on technical blogs and analyze the future direction of technical blogging.&lt;/p&gt;
&lt;h2 id="the-rise-of-ai-writing-tools"&gt;The Rise of AI Writing Tools&lt;/h2&gt;
&lt;p&gt;The core capability of AI writing tools is to understand natural language and generate high-quality text. For technical blog authors, these tools can quickly generate drafts, provide inspiration, or even produce complete articles. For example, when an author needs to explain a complex concept, AI can generate clear explanatory paragraphs; when an author lacks time, AI can quickly compile a tutorial.&lt;/p&gt;</description></item><item><title>Appreciation of OpenAI's Naming Art</title><link>https://blog.jqknono.com/blog/2025/12/12/appreciation-of-openai-naming-art/</link><pubDate>Fri, 12 Dec 2025 11:46:01 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/12/appreciation-of-openai-naming-art/</guid><description>&lt;p&gt;All OpenAI models are documented here: &lt;a href="https://platform.openai.com/docs/models/"&gt;https://platform.openai.com/docs/models/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Without delving too far into the past, let&amp;rsquo;s start with the &lt;code&gt;GPT-4&lt;/code&gt; series and contemporary models. Here is my compiled table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Model Card Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ChatGPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o model used in ChatGPT&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/chatgpt-4o-latest"&gt;https://platform.openai.com/docs/models/chatgpt-4o-latest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4"&gt;https://platform.openai.com/docs/models/gpt-4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo"&gt;https://platform.openai.com/docs/models/gpt-4-turbo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated An older fast GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo-preview"&gt;https://platform.openai.com/docs/models/gpt-4-turbo-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smartest non-reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1"&gt;https://platform.openai.com/docs/models/gpt-4.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller, faster version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-mini"&gt;https://platform.openai.com/docs/models/gpt-4.1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 nano&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fastest, most cost-efficient version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-nano"&gt;https://platform.openai.com/docs/models/gpt-4.1-nano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated large model.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.5-preview"&gt;https://platform.openai.com/docs/models/gpt-4.5-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, intelligent, flexible GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o"&gt;https://platform.openai.com/docs/models/gpt-4o&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o models capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for focused tasks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini"&gt;https://platform.openai.com/docs/models/gpt-4o-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller model capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller realtime model for text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for web search&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini TTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Text-to-speech model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-tts"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-tts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Model capable of realtime text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT model for web search in Chat Completions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Transcription model that identifies who&amp;rsquo;s speaking when&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Previous full o-series reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1"&gt;https://platform.openai.com/docs/models/o1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-mini"&gt;https://platform.openai.com/docs/models/o1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o1 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-pro"&gt;https://platform.openai.com/docs/models/o1-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Reasoning model for complex tasks, succeeded by GPT-5&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3"&gt;https://platform.openai.com/docs/models/o3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o3 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-pro"&gt;https://platform.openai.com/docs/models/o3-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o3&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-mini"&gt;https://platform.openai.com/docs/models/o3-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o4-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, cost-efficient reasoning model, succeeded by GPT-5 mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o4-mini"&gt;https://platform.openai.com/docs/models/o4-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are dedicated models for scenarios like audio (Audio), real-time (Realtime), search (Search), speech-to-text (Transcribe), and text-to-speech (TTS).&lt;br&gt;
For the same scenario, such as audio (&lt;code&gt;Audio&lt;/code&gt;), two models are provided: &lt;code&gt;GPT-4o Audio&lt;/code&gt; and &lt;code&gt;GPT-4o mini Audio&lt;/code&gt;. Users need to experiment to determine which meets their quality expectations.&lt;br&gt;
In the speech-to-text (&lt;code&gt;Transcribe&lt;/code&gt;) scenario, three models are available: &lt;code&gt;GPT-4o Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;, and &lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;.&lt;br&gt;
&lt;code&gt;ChatGPT-4o&lt;/code&gt; is a special version of &lt;code&gt;GPT-4o&lt;/code&gt; used exclusively in ChatGPT and unavailable for other scenarios.&lt;/p&gt;</description></item><item><title>Preemptible Instances Are a Great Deal</title><link>https://blog.jqknono.com/blog/2025/12/05/preemptible-instances-are-a-great-deal/</link><pubDate>Fri, 05 Dec 2025 11:51:04 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/05/preemptible-instances-are-a-great-deal/</guid><description>&lt;p&gt;There&amp;rsquo;s a great deal I&amp;rsquo;ve never promoted in public communities: Alibaba Cloud&amp;rsquo;s &lt;strong&gt;preemptible instances&lt;/strong&gt; are extremely cost-effective.&lt;/p&gt;
&lt;h2 id="long-term-significant-discounts"&gt;Long-term Significant Discounts&lt;/h2&gt;
&lt;p&gt;The headline claim of &lt;em&gt;up to 90% savings&lt;/em&gt; is not exaggerated. Popular instance configurations typically receive around 20% of the original price (20% discount), while less common configurations can go as low as 9% of the original price (91% discount).&lt;/p&gt;
&lt;p&gt;Popular instances include small-scale entry-level servers like 2c2g and 2c4g, as well as &lt;em&gt;CPU/memory&lt;/em&gt; balanced servers like 1:2 (4c8g) and 1:4 (4c16g, 8c32g). These receive slightly smaller discounts.&lt;/p&gt;</description></item><item><title>It is recommended not to use Alibaba Cloud ESA Pages function yet</title><link>https://blog.jqknono.com/blog/2025/12/03/recommend-not-to-use-alibaba-cloud-esa-pages-yet/</link><pubDate>Wed, 03 Dec 2025 19:16:52 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/03/recommend-not-to-use-alibaba-cloud-esa-pages-yet/</guid><description>&lt;p&gt;These are the limitations of the ESA Pages function. This resource scale is only sufficient for hosting a small website. If you want to host a website with long-term updates, the 2000 file limit is too low.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature&lt;/th&gt;
&lt;th&gt;Limitation Item&lt;/th&gt;
&lt;th&gt;Limit&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Function&lt;/td&gt;
&lt;td&gt;Response Time&lt;/td&gt;
&lt;td&gt;120 seconds&lt;/td&gt;
&lt;td&gt;The response time for a single function execution cannot exceed 120 seconds (including I/O wait time as RT).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Wait Time&lt;/td&gt;
&lt;td&gt;10 seconds&lt;/td&gt;
&lt;td&gt;The gateway waits for Functions. If Functions do not return any data within 10 seconds, the gateway will disconnect and return a 504 status code to the client.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Code Package Size&lt;/td&gt;
&lt;td&gt;4 MB&lt;/td&gt;
&lt;td&gt;Upper limit for the size of each function&amp;rsquo;s JavaScript code file.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Sub-request Count&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Number of fetch requests allowed per single function execution.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Development Language&lt;/td&gt;
&lt;td&gt;JavaScript (ES6 syntax)&lt;/td&gt;
&lt;td&gt;Currently only JS is supported. You need JavaScript programming skills.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pages&lt;/td&gt;
&lt;td&gt;File Count&lt;/td&gt;
&lt;td&gt;2000 files&lt;/td&gt;
&lt;td&gt;Each Pages project can upload up to 2000 static files (e.g., HTML, CSS, JS, images, etc.).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Single File Size&lt;/td&gt;
&lt;td&gt;25MB&lt;/td&gt;
&lt;td&gt;Maximum size for a single file (e.g., video, PDF, JS package) is 25MB.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Package Size&lt;/td&gt;
&lt;td&gt;1024MB&lt;/td&gt;
&lt;td&gt;Maximum size for the entire project source code compression package (deploy package) is 1024MB.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="reference-documents"&gt;Reference Documents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.alibabacloud.com/help/zh/edge-security-acceleration/esa/user-guide/what-is-functions-and-pages/?spm=a2c63.p38356.help-menu-2673927.d_2_14_0.3fc311f30eRxno"&gt;Alibaba Cloud Documentation: ESA Pages Function Limitations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Alibaba ESA and OSS Pitfalls</title><link>https://blog.jqknono.com/blog/2025/12/02/alibaba-esa-and-oss-pitfalls/</link><pubDate>Tue, 02 Dec 2025 18:10:45 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/02/alibaba-esa-and-oss-pitfalls/</guid><description>&lt;p&gt;Early Alibaba ESA claimed that traffic from ESA to private OSS was free, but later changed to:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When the origin is Alibaba Cloud OSS, OSS will charge based on back-to-origin outbound traffic. If the OSS region is not mainland China and the requested resources are transmitted to the corresponding region&amp;rsquo;s ESA node, no charge.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From previously free back-to-origin from any ESA node to OSS, changed to &lt;em&gt;free back-to-origin from corresponding region ESA nodes to non-mainland OSS&lt;/em&gt;. That is, if OSS is in Korea, after enabling ESA, only Korean visitors access the hosted site for free; visitors from outside Korea will incur OSS back-to-origin traffic fee once per cache cycle. This fee was free until 2025.10, and started charging from 2025.11.&lt;/p&gt;</description></item><item><title>Windows Shared Chrome Debugging Method</title><link>https://blog.jqknono.com/blog/2025/12/02/windows-shared-chrome-debugging-method/</link><pubDate>Tue, 02 Dec 2025 12:46:11 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/02/windows-shared-chrome-debugging-method/</guid><description>&lt;p&gt;Need to share a public Chrome browser for multi-device debugging, avoiding repeated logins across multiple places.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-ps1" data-lang="ps1"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# chrome启动命令&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;C:\Program Files\Google\Chrome\Application\chrome.exe&amp;#34;&lt;/span&gt; &lt;span class="p"&gt;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;-remote-debugging-address&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;127.0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;1&lt;/span&gt; &lt;span class="p"&gt;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;-remote-debugging-port&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt; &lt;span class="p"&gt;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;-user-data-dir&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;M:\chrome-remote&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Note especially here that, for security reasons in new versions of Chrome, exposing Chrome to 0.0.0.0 is no longer supported, and remote-debugging-address does not actually take effect.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-ps1" data-lang="ps1"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# 增加防火墙放行规则:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;netsh&lt;/span&gt; &lt;span class="n"&gt;advfirewall&lt;/span&gt; &lt;span class="n"&gt;firewall&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;Chrome DevTools 34037 LAN&amp;#34;&lt;/span&gt; &lt;span class="n"&gt;dir&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="n"&gt;allow&lt;/span&gt; &lt;span class="n"&gt;protocol&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="n"&gt;TCP&lt;/span&gt; &lt;span class="n"&gt;localport&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# 建立 portproxy（系统层反代）:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;netsh&lt;/span&gt; &lt;span class="n"&gt;interface&lt;/span&gt; &lt;span class="n"&gt;portproxy&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="n"&gt;v4tov4&lt;/span&gt; &lt;span class="n"&gt;listenport&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt; &lt;span class="n"&gt;listenaddress&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;192.168&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;31&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;2&lt;/span&gt; &lt;span class="n"&gt;connectport&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt; &lt;span class="n"&gt;connectaddress&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;127.0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# 清掉portproxy 规则&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# netsh interface portproxy reset&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# 测试生效&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;curl &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="p"&gt;//&lt;/span&gt;&lt;span class="mf"&gt;127.0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;curl &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="p"&gt;//&lt;/span&gt;&lt;span class="mf"&gt;192.168&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;31&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description></item><item><title>Is Cloudflare Completely Trustworthy?</title><link>https://blog.jqknono.com/blog/2025/12/02/is-cloudflare-completely-trustworthy/</link><pubDate>Tue, 02 Dec 2025 08:30:50 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/02/is-cloudflare-completely-trustworthy/</guid><description>&lt;p&gt;Cloudflare, Aliyun ESA, Tencent EdgeOne, etc., all hold domain certificates, which means they can fully inspect all traffic under the domain. They themselves are large middlemen. Their primary function is security; there are too many attackers on the internet, and choosing a large middleman has more benefits than drawbacks. Secondary functions include providing DNS, CDN, WAF, and other edge services simultaneously.&lt;/p&gt;
&lt;p&gt;Services like Cloudflare can effectively defend against DDoS, trading a slight increase in latency for protection capability, which is very cost-effective. Every site owner should directly use such services; network attacks are everywhere, no need to be optimistic, you&amp;rsquo;ll be attacked sooner or later. Some attacks exploit vulnerabilities, related to the site operator&amp;rsquo;s skill level. Other attacks aim to consume resources, like DDoS, exploiting the cost asymmetry between commercial and home networks—a kind of open conspiracy. Often, you can only fight back with money or shut down the service directly, abandoning all users, also known as black hole defense.&lt;/p&gt;</description></item><item><title>Vision Improvement Mystery</title><link>https://blog.jqknono.com/blog/2025/12/01/vision-improvement-mystery/</link><pubDate>Mon, 01 Dec 2025 16:20:28 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/12/01/vision-improvement-mystery/</guid><description>&lt;p&gt;Started nearsighted at 12 years old, wore glasses for over twenty years, recently found that the computer screen looks clearer and clearer when working, eyes feel a bit tired when wearing glasses, taking off glasses is not only more comfortable, but also clearer for near vision, thought I was going to turn back young. But considering my terrible lifestyle habits, always staying up late, not exercising much, physical condition deteriorating day by day, no reason for my eyes to rejuvenate, so I asked ChatGPT, and it said I have presbyopia.&lt;/p&gt;</description></item><item><title>Freebies You Can Snag by Owning a Domain</title><link>https://blog.jqknono.com/blog/2025/11/27/freebies-you-can-snag-by-owning-a-domain/</link><pubDate>Thu, 27 Nov 2025 12:55:58 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/27/freebies-you-can-snag-by-owning-a-domain/</guid><description>&lt;p&gt;Generally, a domain costs at least $12, and some people want to get their own domain but hesitate about whether it&amp;rsquo;s necessary.&lt;/p&gt;
&lt;p&gt;I highly recommend that developers prepare their own domain because owning a domain can get you a lot of freebies.&lt;/p&gt;
&lt;p&gt;Here I mainly introduce two service providers I&amp;rsquo;m familiar with: one is the so-called &amp;ldquo;Cyber Buddha&amp;rdquo; &lt;a href="https://www.cloudflare.com/"&gt;Cloudflare&lt;/a&gt;, and the other is the developing &lt;a href="https://www.alibabacloud.com/product/esa"&gt;Alibaba ESA&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here I first emphasize that the Alibaba ESA that can get freebies specifically refers to the international version. Alibaba has almost no freebies for mainland China, and those time-limited trials have been kicked out of my freebie category. Only permanent freebies are real freebies.&lt;/p&gt;</description></item><item><title>gpt-5-high is the best model for developers</title><link>https://blog.jqknono.com/blog/2025/11/26/gpt-5-high-is-the-best-model-for-developers/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/26/gpt-5-high-is-the-best-model-for-developers/</guid><description>&lt;p&gt;If you need to code, gpt-5-high is currently the only model that can truly boost your efficiency.&lt;/p&gt;
&lt;p&gt;I have 10 months of experience using the Claude model and have used Gemini/DeepSeek/glm/grok sporadically. I really dislike models that don&amp;rsquo;t think. I have to admit that Claude can work for long periods and is good at using tools, but its error rate is high, leading to low usability of the results, and it often requires adjustments. However, Claude&amp;rsquo;s adjustment ability is very poor; it will repeatedly, extensively, disruptively, and superfluously wander through the codebase, crapping all over the place. After having to hard reset several hours of work multiple times, I&amp;rsquo;ve developed a deep aversion to this kind of &amp;ldquo;busy but dumb&amp;rdquo; behavior from Claude. Its working style is suitable for research, producing content that looks plausible but doesn&amp;rsquo;t hold up to scrutiny—essentially, fluff pieces. Or for operating browsers, executing tools, writing small scripts, or making minor page edits. That&amp;rsquo;s its ceiling.&lt;/p&gt;</description></item><item><title>The Artificial Human-like Feel of LLMs</title><link>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Some forums resist AI models pretending to be human and participating in forum activities, such as posting and replying. Consequently, people start &amp;ldquo;witch-hunting&amp;rdquo;—when encountering posts that seem oddly expressed, they judge whether the content is AI-generated and then engage in discussions about it.&lt;/p&gt;
&lt;p&gt;Why can AI-generated content be identified? It&amp;rsquo;s speculated that AI-generated content has a kind of &amp;ldquo;artificial human-like feel.&amp;rdquo; Although AI is fed massive amounts of human activity data from the internet, it still often gives people a sense of incongruity. Perhaps it lacks the tactile nerves of a body, endocrine hormones, or a desire for social connection; its desires are far removed from human desires. In conversations between AI and humans, there is no &amp;ldquo;roundabout boasting, exaggerated disparagement of others, or gossipy prying.&amp;rdquo; AI doesn&amp;rsquo;t boast about itself, doesn&amp;rsquo;t disparage third parties, and doesn&amp;rsquo;t seem interested in the questioner. It feels like a monk—almost emotionless, just solving problems.&lt;/p&gt;</description></item><item><title>Useful Mouse Key Mapping Share</title><link>https://blog.jqknono.com/blog/2025/11/07/useful-mouse-key-mapping-share/</link><pubDate>Fri, 07 Nov 2025 18:09:37 +0800</pubDate><guid>https://blog.jqknono.com/blog/2025/11/07/useful-mouse-key-mapping-share/</guid><description>&lt;p&gt;&lt;code&gt;Mouse 5&lt;/code&gt; key mapped to &lt;code&gt;F12&lt;/code&gt;
&lt;code&gt;F12&lt;/code&gt; is the &amp;ldquo;Go to Definition&amp;rdquo; function in Visual Studio and VS Code
&lt;code&gt;Shift + F12&lt;/code&gt; is the &amp;ldquo;Find All References&amp;rdquo; function&lt;/p&gt;
&lt;p&gt;This allows for a more comfortable posture when browsing code. Right-handed users can give it a try.&lt;/p&gt;</description></item></channel></rss>