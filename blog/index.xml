<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on jqknono Blogs</title><link>https://blog.jqknono.com/blog/</link><description>Recent content in Blog on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>https://blog.jqknono.com (jqknono)</managingEditor><webMaster>https://blog.jqknono.com (jqknono)</webMaster><lastBuildDate>Mon, 13 Nov 2023 14:15:31 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Project Translator VSCode Extension for Project Multilingual Localization</title><link>https://blog.jqknono.com/blog/2026/02/26/project-translator-vscode-extension/</link><pubDate>Thu, 26 Feb 2026 14:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2026/02/26/project-translator-vscode-extension/</guid><description>Project Translator is a powerful VSCode extension that leverages AI to achieve project-level multilingual automatic translation, efficiently completing document localization while maintaining code structure integrity.</description></item><item><title>GPT-5.3-Codex First Impressions: From Surprise to Rational Assessment</title><link>https://blog.jqknono.com/blog/2026/02/17/gpt-53-codex-experience/</link><pubDate>Tue, 17 Feb 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2026/02/17/gpt-53-codex-experience/</guid><description>&lt;p&gt;OpenAI, before the official release of GPT-5.3, has rolled out the specialized model GPT-5.3-Codex. From a business perspective, this decision is easy to understand. GPT-5.3-Codex is priced the same as the standard GPT-5.3, but its outputs are more proactive, execution time is shorter, and memory usage is lower, which translates to higher profit margins. For OpenAI, GPT-5.3-Codex is clearly a more cost-effective option.&lt;/p&gt;
&lt;p&gt;During the first week after GPT-5.3-Codex was released, the user experience was indeed impressive. The model&amp;rsquo;s response speed was noticeably better than previous versions, and code generation feedback was very prompt. In development scenarios that require rapid iteration and frequent interaction, this efficiency boost brings tangible productivity improvements. When multiple implementation options or quick idea validation are needed in a short time, Codex&amp;rsquo;s proactive output proves especially useful.&lt;/p&gt;</description></item><item><title>Comparative Technical Analysis of DoH and DoT</title><link>https://blog.jqknono.com/blog/2026/02/11/doh-vs-dot-comparison/</link><pubDate>Wed, 11 Feb 2026 00:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2026/02/11/doh-vs-dot-comparison/</guid><description>&lt;p&gt;DNS over HTTPS (DoH) and DNS over TLS (DoT) are two common encrypted DNS transport methods that implement secure transmission of DNS queries through different protocol stacks. The DoT standard is defined by &lt;a href="https://datatracker.ietf.org/doc/html/rfc7858"&gt;RFC 7858&lt;/a&gt;, while DoH is standardized by &lt;a href="https://datatracker.ietf.org/doc/html/rfc8484"&gt;DNS Queries over HTTPS (DoH)&lt;/a&gt;. Understanding the essential differences between these two technologies requires analysis starting from the network protocol hierarchy.&lt;/p&gt;
&lt;h2 id="network-protocol-hierarchy"&gt;Network Protocol Hierarchy&lt;/h2&gt;
&lt;p&gt;Modern network protocol stacks adopt a layered design, with each layer providing different functions. As an application layer protocol, DNS itself is not bound to a specific transport method and can run over various bearer protocols.&lt;/p&gt;</description></item><item><title>Debugging Record: OpenRouter gpt-oss-120b Model Does Not Support Chinese Requests</title><link>https://blog.jqknono.com/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;While using the free model API provided by &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, I encountered a confusing issue. With the exact same request structure, simply changing the language of the prompt resulted in completely different outcomes.&lt;/p&gt;
&lt;h2 id="problem-reproduction"&gt;Problem Reproduction&lt;/h2&gt;
&lt;p&gt;I used the &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; model for testing. The only difference between the two requests was the language of the prompt. The first request used a Chinese prompt:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This request always returned a 429 status code, indicating that the request rate was too high or the quota limit was exceeded. However, when I used an English prompt:&lt;/p&gt;</description></item><item><title>Summary of Free AI Icon Generators</title><link>https://blog.jqknono.com/blog/2026/02/02/free-ai-icon-generators/</link><pubDate>Mon, 02 Feb 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2026/02/02/free-ai-icon-generators/</guid><description>&lt;p&gt;With the development of artificial intelligence technology, designers and developers can now quickly generate various types of icons through simple text prompts. These free AI icon generators significantly lower the barrier to design, enabling users without professional design skills to create high-quality visual elements. The tools listed below all support generating images from text descriptions, with output formats usually being PNG or SVG, and some tools also offer style and color adjustment features.&lt;/p&gt;</description></item><item><title>Cost Formulas and Break-Even Points for Vibe Coding</title><link>https://blog.jqknono.com/blog/2026/01/07/vibe-coding-cost-formulas/</link><pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2026/01/07/vibe-coding-cost-formulas/</guid><description>&lt;p&gt;AI coding tools can be categorized into three billing models:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Per-token billing&lt;/strong&gt;: Includes various APIs, Claude Code (Claude Pro), Codex Cli (ChatGPT Plus), Zhipu Lite/Pro, Cursor (new version), etc. These are fundamentally token-based, with some products offering package discounts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Per-API call billing&lt;/strong&gt;: Such as OpenRouter (free quota), ModelScope, Gemini Code Assistant (1,000 free calls per day), Chutes, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Per-prompt billing&lt;/strong&gt;: Such as Cursor (legacy version, 500 prompts), Github Copilot (300 prompts), etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These three models are essentially paying for model inference and context processing, differing only in pricing granularity and quota forms.&lt;/p&gt;</description></item><item><title>Setting Up a Remote Browser Debugging Endpoint on Windows</title><link>https://blog.jqknono.com/blog/2026/01/01/windows-remote-browser-cdp/</link><pubDate>Thu, 01 Jan 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2026/01/01/windows-remote-browser-cdp/</guid><description>&lt;p&gt;This article explains how to run Chrome on a Windows host and expose a remote debugging endpoint via CDP for LAN clients or MCP to connect. The core of the solution is that Chrome only listens on 127.0.0.1, which is then mapped to a LAN address via portproxy, and further restricted by firewall rules for remote sources.&lt;/p&gt;
&lt;h2 id="topology-and-flow"&gt;Topology and Flow&lt;/h2&gt;
&lt;p&gt;The diagram below illustrates the port flow within the Windows host and how clients access it over the LAN.&lt;/p&gt;</description></item><item><title>Technical Blogs Are Dead</title><link>https://blog.jqknono.com/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;In recent years, AI writing tools such as ChatGPT and Claude have rapidly gained popularity. These tools can generate fluent technical articles and even mimic human writing styles. This shift has sparked widespread discussion in the technical blogging community, with many claiming that &amp;ldquo;technical blogs are dead.&amp;rdquo; This article will explore the impact of AI tools on technical blogs and analyze the future direction of technical blogging.&lt;/p&gt;
&lt;h2 id="the-rise-of-ai-writing-tools"&gt;The Rise of AI Writing Tools&lt;/h2&gt;
&lt;p&gt;The core capability of AI writing tools is to understand natural language and generate high-quality text. For technical blog authors, these tools can quickly generate drafts, provide inspiration, or even produce complete articles. For example, when an author needs to explain a complex concept, AI can generate clear explanatory paragraphs; when an author lacks time, AI can quickly compile a tutorial.&lt;/p&gt;</description></item><item><title>Appreciation of OpenAI's Naming Art</title><link>https://blog.jqknono.com/blog/2025/12/12/appreciation-of-openai-naming-art/</link><pubDate>Fri, 12 Dec 2025 11:46:01 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2025/12/12/appreciation-of-openai-naming-art/</guid><description>&lt;p&gt;All OpenAI models are documented here: &lt;a href="https://platform.openai.com/docs/models/"&gt;https://platform.openai.com/docs/models/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Without delving too far into the past, let&amp;rsquo;s start with the &lt;code&gt;GPT-4&lt;/code&gt; series and contemporary models. Here is my compiled table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Model Card Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ChatGPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o model used in ChatGPT&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/chatgpt-4o-latest"&gt;https://platform.openai.com/docs/models/chatgpt-4o-latest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4"&gt;https://platform.openai.com/docs/models/gpt-4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo"&gt;https://platform.openai.com/docs/models/gpt-4-turbo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated An older fast GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo-preview"&gt;https://platform.openai.com/docs/models/gpt-4-turbo-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smartest non-reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1"&gt;https://platform.openai.com/docs/models/gpt-4.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller, faster version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-mini"&gt;https://platform.openai.com/docs/models/gpt-4.1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 nano&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fastest, most cost-efficient version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-nano"&gt;https://platform.openai.com/docs/models/gpt-4.1-nano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated large model.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.5-preview"&gt;https://platform.openai.com/docs/models/gpt-4.5-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, intelligent, flexible GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o"&gt;https://platform.openai.com/docs/models/gpt-4o&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o models capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for focused tasks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini"&gt;https://platform.openai.com/docs/models/gpt-4o-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller model capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller realtime model for text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for web search&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini TTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Text-to-speech model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-tts"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-tts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Model capable of realtime text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT model for web search in Chat Completions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Transcription model that identifies who&amp;rsquo;s speaking when&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Previous full o-series reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1"&gt;https://platform.openai.com/docs/models/o1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-mini"&gt;https://platform.openai.com/docs/models/o1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o1 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-pro"&gt;https://platform.openai.com/docs/models/o1-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Reasoning model for complex tasks, succeeded by GPT-5&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3"&gt;https://platform.openai.com/docs/models/o3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o3 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-pro"&gt;https://platform.openai.com/docs/models/o3-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o3&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-mini"&gt;https://platform.openai.com/docs/models/o3-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o4-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, cost-efficient reasoning model, succeeded by GPT-5 mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o4-mini"&gt;https://platform.openai.com/docs/models/o4-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are dedicated models for scenarios like audio (Audio), real-time (Realtime), search (Search), speech-to-text (Transcribe), and text-to-speech (TTS).&lt;br&gt;
For the same scenario, such as audio (&lt;code&gt;Audio&lt;/code&gt;), two models are provided: &lt;code&gt;GPT-4o Audio&lt;/code&gt; and &lt;code&gt;GPT-4o mini Audio&lt;/code&gt;. Users need to experiment to determine which meets their quality expectations.&lt;br&gt;
In the speech-to-text (&lt;code&gt;Transcribe&lt;/code&gt;) scenario, three models are available: &lt;code&gt;GPT-4o Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;, and &lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;.&lt;br&gt;
&lt;code&gt;ChatGPT-4o&lt;/code&gt; is a special version of &lt;code&gt;GPT-4o&lt;/code&gt; used exclusively in ChatGPT and unavailable for other scenarios.&lt;/p&gt;</description></item><item><title>Preemptible Instances Are a Great Deal</title><link>https://blog.jqknono.com/blog/2025/12/05/preemptible-instances-are-a-great-deal/</link><pubDate>Fri, 05 Dec 2025 11:51:04 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/blog/2025/12/05/preemptible-instances-are-a-great-deal/</guid><description>&lt;p&gt;There&amp;rsquo;s a great deal I&amp;rsquo;ve never promoted in public communities: Alibaba Cloud&amp;rsquo;s &lt;strong&gt;preemptible instances&lt;/strong&gt; are extremely cost-effective.&lt;/p&gt;
&lt;h2 id="long-term-significant-discounts"&gt;Long-term Significant Discounts&lt;/h2&gt;
&lt;p&gt;The headline claim of &lt;em&gt;up to 90% savings&lt;/em&gt; is not exaggerated. Popular instance configurations typically receive around 20% of the original price (20% discount), while less common configurations can go as low as 9% of the original price (91% discount).&lt;/p&gt;
&lt;p&gt;Popular instances include small-scale entry-level servers like 2c2g and 2c4g, as well as &lt;em&gt;CPU/memory&lt;/em&gt; balanced servers like 1:2 (4c8g) and 1:4 (4c16g, 8c32g). These receive slightly smaller discounts.&lt;/p&gt;</description></item></channel></rss>