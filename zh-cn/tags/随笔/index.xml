<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>随笔 on jqknono Blogs</title><link>https://blog.jqknono.com/zh-cn/tags/%E9%9A%8F%E7%AC%94/</link><description>Recent content in 随笔 on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Wed, 11 Feb 2026 10:55:39 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/zh-cn/tags/%E9%9A%8F%E7%AC%94/index.xml" rel="self" type="application/rss+xml"/><item><title>return-to-gpt-non-codex</title><link>https://blog.jqknono.com/zh-cn/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;OpenAI似乎很想推Codex模型，GPT-5.3还没出，先出GPT-5.3-Codex.一样的价格，Codex输出更积极，执行时间更短，内存占用时间更少，有更大利润空间.&lt;/p&gt;
&lt;p&gt;GPT-5.3-Codex出来第一周我用了体验很好，主要是速度快，反馈及时. 但进入第二周其降速明显，同时其思维缜密程度不如GPT非Codex系列，因此我还是推荐非Codex系列，其一次做对的概率仍然是最高的，它不会做超出描述的事，但能描述出的事做的没有bug.&lt;/p&gt;</description></item><item><title>视力改善疑云</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/01/%E8%A7%86%E5%8A%9B%E6%94%B9%E5%96%84%E7%96%91%E4%BA%91/</link><pubDate>Mon, 01 Dec 2025 16:20:28 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/01/%E8%A7%86%E5%8A%9B%E6%94%B9%E5%96%84%E7%96%91%E4%BA%91/</guid><description>&lt;p&gt;12 岁开始近视, 带了二十多年眼镜, 最近发现工作时看电脑屏幕越来越清晰, 带着眼镜时眼睛还会有点累, 取了眼镜不仅更舒服, 而且看近处时更清晰, 以为自己要返老还童了. 但想想自己这恶劣的生活习惯, 老是熬夜, 又不怎么锻炼, 身体素质一天不如一天, 没理由就眼睛返老还童啊, 于是问了下 ChatGPT, 然后它说我老花了.&lt;/p&gt;
&lt;p&gt;我不仅近视, 而且老花了. 眼球调节能力下降, 晶状体变硬, 看近处时对焦能力下降. 近视让我看近清楚，老花让我看近吃力，两者抵消后正好不用戴眼镜看电脑.当前的视线焦点正好落在 50-70 厘米处, 真是巧了, 正好适合敲键盘.但是看远处时, 还是需要戴近视眼镜, 变化的是以后我看近处时, 可能需要戴老花镜了.&lt;/p&gt;</description></item><item><title>llm的伪人感</title><link>https://blog.jqknono.com/zh-cn/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;一些论坛会抵制 AI 模型假装人类参与论坛活动, 如发帖回帖等, 继而大家开始&amp;quot;猎巫&amp;quot;, 碰到看起来表达怪异的帖子, 会判断其是否是 AI 生成的内容, 继而展开一些讨论.&lt;/p&gt;
&lt;p&gt;为何 AI 生成内容会被识别? 猜测可能 AI 生成的东西有一种&amp;quot;伪人感&amp;quot;. 尽管 AI 被投喂互联网海量人类活动数据, 但 AI 仍然常常给人违和感, 可能它没有身体的触感神经, 没有内分泌激素, 可能它不向往社会连接, 欲望与人类的欲望相差甚远. AI 与人类的对话中, 没有&amp;quot;拐弯抹角的炫耀自己、添油加醋的贬低别人、相互窥探的搬弄是非&amp;quot;, AI 不炫耀自己, 不贬低第三方, 对提问者似乎也不感兴趣, 感觉它像一个和尚, 几乎没有情绪, 只是解决问题.&lt;/p&gt;
&lt;p&gt;尽管人类自己经常犯错, 但人类向往&amp;quot;正确&amp;quot;, 希望 AI 给出正确的产物. 是否是这种对&amp;quot;正确&amp;quot;的追求造成了 AI 的伪人感? AI 也较少给人&amp;quot;自我怀疑&amp;quot;感, 即使是非常愚蠢的小模型, 也能自信满满, 夸夸其谈. 一些较傻的 AI 模型对其知识库深信不疑, 它们可能有着错误的元认知, 缺少怀疑精神, 不过这也不应该给人&amp;quot;伪人&amp;quot;感, 傻逼和&amp;quot;伪人&amp;quot;并不一样.&lt;/p&gt;
&lt;p&gt;AI 是否有价值观倾向? 网页端模型服务的输出通常会加一道门禁, 避免谈及敏感话题, 模型服务商不希望人类对 AI 产生感情依赖, 不希望人类对 AI 言听计从, 避免产生 AI 诱导伤害事件. 人类的丑恶一面被禁止在模型中显露, 或许黑白混杂才是人类, 而 AI 通常不被允许参杂黑色部分.&lt;/p&gt;</description></item></channel></rss>