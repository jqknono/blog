<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on jqknono Blogs</title><link>https://blog.jqknono.com/zh-cn/categories/ai/</link><description>Recent content in AI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><managingEditor>https://blog.jqknono.com (jqknono)</managingEditor><webMaster>https://blog.jqknono.com (jqknono)</webMaster><lastBuildDate>Tue, 17 Feb 2026 10:30:00 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/zh-cn/categories/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>GPT-5.3-Codex 初体验：从惊喜到理性评估</title><link>https://blog.jqknono.com/zh-cn/blog/2026/02/17/gpt-53-codex-experience/</link><pubDate>Tue, 17 Feb 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-cn/blog/2026/02/17/gpt-53-codex-experience/</guid><description>&lt;p&gt;OpenAI 在 GPT-5.3 正式版尚未发布之际，率先推出了 GPT-5.3-Codex 这一特化模型。从商业逻辑来看，这一决策不难理解。GPT-5.3-Codex 与标准版 GPT-5.3 定价相同，但其输出更为积极，执行时间更短，内存占用更少，这意味着更高的利润空间。对于 OpenAI 而言，GPT-5.3-Codex 显然是一个更具成本效益的选择。&lt;/p&gt;
&lt;p&gt;在 GPT-5.3-Codex 发布的第一周，其使用体验确实令人惊喜。模型响应速度明显优于之前的版本，代码生成的反馈非常及时。对于需要快速迭代、频繁交互的开发场景，这种效率提升带来了直观的生产力改善。当需要在短时间内获得多个实现方案或快速验证想法时，Codex 的积极输出特性显得尤为有用。&lt;/p&gt;
&lt;p&gt;然而进入第二周后，情况发生了明显变化。模型的响应速度出现显著下降，原本流畅的交互体验开始变得卡顿。这种性能波动让人联想到云服务中常见的资源调度问题，可能是在用户量增长后，服务器负载分配策略导致的降级服务。&lt;/p&gt;
&lt;p&gt;除了性能波动，更值得关注的是 Codex 在思维缜密程度上的不足。与非 Codex 系列相比，它在处理复杂逻辑、边缘情况处理和代码健壮性方面表现较弱。当面对需要深度推理、多步骤规划或抽象理解的任务时，Codex 更倾向于给出表面可行的方案，而缺乏对潜在问题的预判。&lt;/p&gt;
&lt;p&gt;这种差异背后反映了两个模型在设计目标上的不同。Codex 似乎更注重生成速度和输出活跃度，适合快速原型开发、代码补全和简单任务的自动化。而非 Codex 系列则保留了更强的泛化能力，更注重方案的正确性和可靠性。&lt;/p&gt;
&lt;pre class="mermaid"&gt;flowchart LR
subgraph A[&amp;#34;GPT-5.3-Codex&amp;#34;]
direction LR
A1[&amp;#34;生成速度: 快&amp;#34;]
A2[&amp;#34;输出活跃度: 高&amp;#34;]
A3[&amp;#34;思维缜密度: 中等&amp;#34;]
A4[&amp;#34;适合场景: 快速原型、代码补全、探索阶段&amp;#34;]
end
subgraph B[&amp;#34;GPT-5.3 非Codex&amp;#34;]
direction LR
B1[&amp;#34;生成速度: 中等&amp;#34;]
B2[&amp;#34;输出活跃度: 稳定&amp;#34;]
B3[&amp;#34;思维缜密度: 高&amp;#34;]
B4[&amp;#34;适合场景: 生产环境、关键项目、稳定期&amp;#34;]
end
A &amp;lt;--&amp;gt;|选择权衡| B
classDef codex fill:#E3F2FD,stroke:#1565C0,stroke-width:2px,color:#0D47A1;
classDef standard fill:#E8F5E9,stroke:#2E7D32,stroke-width:2px,color:#1B5E20;
class A,A1,A2,A3,A4 codex;
class B,B1,B2,B3,B4 standard;&lt;/pre&gt;
&lt;p&gt;从实际开发场景来看，如果你的需求是快速获得代码片段、实现已知明确的功能，或者需要在短时间内尝试多种方案，Codex 的积极输出和快速响应会带来明显优势。但当项目进入稳定期，对代码质量、可维护性和长期稳定性有更高要求时，非 Codex 系列仍然是更可靠的选择。&lt;/p&gt;</description></item><item><title>技术博客已死</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;在过去的几年里, 人工智能 (AI) 写作工具如 ChatGPT, Claude 等迅速普及. 它们能够生成流畅的技术文章, 甚至能模仿人类的写作风格. 这一变化引发了技术博客圈的广泛讨论: 许多人声称&amp;quot;技术博客已死&amp;quot;. 本文将探讨 AI 工具对技术博客的影响, 并分析技术博客的未来走向.&lt;/p&gt;
&lt;h2 id="ai-写作工具的崛起"&gt;AI 写作工具的崛起&lt;/h2&gt;
&lt;p&gt;AI 写作工具的核心能力是理解自然语言并生成高质量文本. 对于技术博客作者而言, 这些工具可以快速生成草稿, 提供灵感, 或者直接产出完整的文章. 例如, 当作者需要解释一个复杂概念时, AI 可以生成清晰的说明段落; 当作者缺乏时间时, AI 可以快速整理出一篇教程.&lt;/p&gt;
&lt;p&gt;然而, 这种便利也带来了副作用. 大量低质量的 AI 生成内容开始充斥互联网. 这些内容往往缺乏深度, 甚至包含错误, 却因为 SEO 优化而获得高排名, 挤占了真正有价值的技术博客的曝光机会.&lt;/p&gt;
&lt;h2 id="技术博客的初衷"&gt;技术博客的初衷&lt;/h2&gt;
&lt;p&gt;技术博客最初是开发者分享经验, 记录问题和建立个人品牌的方式. 它的价值在于真实性和独特性: 作者将自己的实践, 思考和失败经历融入文章中, 为读者提供第一手的见解.&lt;/p&gt;
&lt;p&gt;AI 生成的内容虽然看似专业, 但缺乏这种真实体验. 它无法分享作者在实际项目中遇到的坑, 也无法提供独特的解决方案. 因此, 纯粹由 AI 生成的技术文章很难取代那些源自真实经验的作品.&lt;/p&gt;
&lt;h2 id="人机协作的未来"&gt;人机协作的未来&lt;/h2&gt;
&lt;p&gt;与其将 AI 视为威胁, 不如将其视为助手. 聪明的技术博主已经开始利用 AI 来提高效率: 用 AI 进行头脑风暴, 检查语法, 优化表达, 甚至生成代码示例. 但文章的核心观点和独特洞察仍然来自作者本人.&lt;/p&gt;</description></item><item><title>OpenAI的取名艺术鉴赏</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/12/openai%E7%9A%84%E5%8F%96%E5%90%8D%E8%89%BA%E6%9C%AF%E9%89%B4%E8%B5%8F/</link><pubDate>Fri, 12 Dec 2025 11:46:01 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/12/openai%E7%9A%84%E5%8F%96%E5%90%8D%E8%89%BA%E6%9C%AF%E9%89%B4%E8%B5%8F/</guid><description>&lt;p&gt;这里&lt;a href="https://platform.openai.com/docs/models/"&gt;https://platform.openai.com/docs/models/&lt;/a&gt;记录了 OpenAI 的所有模型.&lt;/p&gt;
&lt;p&gt;太远了的不说, 从 &lt;code&gt;GPT-4&lt;/code&gt; 系列及同世代模型聊起, 这是我汇总的表格:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;th&gt;模型卡片链接&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ChatGPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o model used in ChatGPT&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/chatgpt-4o-latest"&gt;https://platform.openai.com/docs/models/chatgpt-4o-latest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4"&gt;https://platform.openai.com/docs/models/gpt-4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo"&gt;https://platform.openai.com/docs/models/gpt-4-turbo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated An older fast GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo-preview"&gt;https://platform.openai.com/docs/models/gpt-4-turbo-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smartest non-reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1"&gt;https://platform.openai.com/docs/models/gpt-4.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller, faster version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-mini"&gt;https://platform.openai.com/docs/models/gpt-4.1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 nano&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fastest, most cost-efficient version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-nano"&gt;https://platform.openai.com/docs/models/gpt-4.1-nano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated large model.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.5-preview"&gt;https://platform.openai.com/docs/models/gpt-4.5-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, intelligent, flexible GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o"&gt;https://platform.openai.com/docs/models/gpt-4o&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o models capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for focused tasks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini"&gt;https://platform.openai.com/docs/models/gpt-4o-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller model capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller realtime model for text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for web search&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini TTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Text-to-speech model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-tts"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-tts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Model capable of realtime text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT model for web search in Chat Completions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Transcription model that identifies who&amp;rsquo;s speaking when&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Previous full o-series reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1"&gt;https://platform.openai.com/docs/models/o1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-mini"&gt;https://platform.openai.com/docs/models/o1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o1 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-pro"&gt;https://platform.openai.com/docs/models/o1-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Reasoning model for complex tasks, succeeded by GPT-5&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3"&gt;https://platform.openai.com/docs/models/o3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o3 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-pro"&gt;https://platform.openai.com/docs/models/o3-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o3&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-mini"&gt;https://platform.openai.com/docs/models/o3-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o4-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, cost-efficient reasoning model, succeeded by GPT-5 mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o4-mini"&gt;https://platform.openai.com/docs/models/o4-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;针对音频(Audio), 实时(Realtime), 搜索(Search), 音频到文字(Transcribe), 文字到声音(TTS) 等场景, 全都有相应模型.&lt;br&gt;
对同一场景, 如 音频&lt;code&gt;Audio&lt;/code&gt; 场景, 提供了 &lt;code&gt;GPT-4o Audio&lt;/code&gt; 和 &lt;code&gt;GPT-4o mini Audio&lt;/code&gt; 两个模型, 用户需要通过尝试决定能否接受效果.&lt;br&gt;
音频到文字&lt;code&gt;Transcribe&lt;/code&gt; 场景, 提供了 &lt;code&gt;GPT-4o Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt; 三个模型.&lt;br&gt;
&lt;code&gt;ChatGPT-4o&lt;/code&gt; 是 &lt;code&gt;GPT-4o&lt;/code&gt; 的特别版, 用于 ChatGPT 中, 其他场景不能用.
&lt;code&gt;GPT-4.1&lt;/code&gt;比&lt;code&gt;GPT-4&lt;/code&gt;更好, 是符合直觉的, 但&lt;code&gt;GPT-4o&lt;/code&gt;(4 欧)和&lt;code&gt;GPT-4.1&lt;/code&gt;或&lt;code&gt;GPT-4&lt;/code&gt;却不好比较. 时间线上, 先出现的是&lt;code&gt;GPT-4&lt;/code&gt;, 然后是&lt;code&gt;GPT-4o&lt;/code&gt;, 再然后是&lt;code&gt;GPT-4.1&lt;/code&gt;, 当然, 仍然无法判断&lt;code&gt;GPT-4o&lt;/code&gt;和&lt;code&gt;GPT-4.1&lt;/code&gt;谁更好.
这里插入下对&amp;quot;好&amp;quot;的定义, 我个人将数学和推理结果正确率高作为&amp;quot;好&amp;quot;的定义, 完全不将&amp;quot;速度&amp;quot;纳入&amp;quot;好&amp;quot;的定义. 但此前 OpenAI 可能认为速度和智慧同样重要, 因此出现奇怪的模型对比. 进入 GPT-5 时代后, 庆幸 OpenAI 开始放弃速度, 追求智慧, 至此模型间的对比才没有歧义. 一个快速的错误回答是浪费时间, 没有意义.&lt;/p&gt;</description></item></channel></rss>