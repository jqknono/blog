<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on jqknono Blogs</title><link>https://blog.jqknono.com/zh-cn/blog/</link><description>Recent content in Blog on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 13 Nov 2023 14:15:31 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/zh-cn/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>return-to-gpt-non-codex</title><link>https://blog.jqknono.com/zh-cn/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;OpenAI似乎很想推Codex模型，GPT-5.3还没出，先出GPT-5.3-Codex.一样的价格，Codex输出更积极，执行时间更短，内存占用时间更少，有更大利润空间.&lt;/p&gt;
&lt;p&gt;GPT-5.3-Codex出来第一周我用了体验很好，主要是速度快，反馈及时. 但进入第二周其降速明显，同时其思维缜密程度不如GPT非Codex系列，因此我还是推荐非Codex系列，其一次做对的概率仍然是最高的，它不会做超出描述的事，但能描述出的事做的没有bug.&lt;/p&gt;</description></item><item><title>DoH 与 DoT 技术对比分析</title><link>https://blog.jqknono.com/zh-cn/blog/2026/02/11/doh-vs-dot-comparison/</link><pubDate>Wed, 11 Feb 2026 00:00:00 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2026/02/11/doh-vs-dot-comparison/</guid><description>&lt;p&gt;DNS over HTTPS (DoH) 和 DNS over TLS (DoT) 是两种常见的加密 DNS 传输方式, 它们通过不同的协议栈来实现 DNS 查询的安全传输. DoT 的标准由 &lt;a href="https://datatracker.ietf.org/doc/html/rfc7858"&gt;RFC 7858&lt;/a&gt; 定义, 而 DoH 则由 &lt;a href="https://datatracker.ietf.org/doc/html/rfc8484"&gt;DNS Queries over HTTPS (DoH)&lt;/a&gt; 标准化. 理解这两种技术的本质区别, 需要从网络协议层次结构入手分析.&lt;/p&gt;
&lt;h2 id="网络协议层次结构"&gt;网络协议层次结构&lt;/h2&gt;
&lt;p&gt;现代网络协议栈采用分层设计, 每一层提供不同的功能. DNS 作为应用层协议, 本身并不绑定特定的传输方式, 可以运行在多种承载协议之上.&lt;/p&gt;
&lt;p&gt;应用层 (L7) 包含 HTTP/1.1, HTTP/2, HTTP/3, FTP 和 DNS 等协议. 值得注意的是, HTTP/3 的语义仍然在应用层, 只是 QUIC 作为传输承载. 安全层位于应用层和传输层之间, 主要包括 TLS 及其变体. TLS 通常运行在 TCP 上, 比如 HTTPS 和 DoT. DTLS 是 TLS 的数据报版本, 可以运行在 UDP 上. QUIC 协议比较特殊, 它将 TLS 1.3 的握手与密钥派生直接集成在协议内部.&lt;/p&gt;</description></item><item><title>OpenRouter gpt-oss-120b 模型不支持中文请求的调试记录</title><link>https://blog.jqknono.com/zh-cn/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;在使用 &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; 提供的免费模型 API 时, 我遇到了一个令人困惑的问题. 同样的请求结构, 仅仅修改了提示词的语言, 就会出现完全不同的结果.&lt;/p&gt;
&lt;h2 id="问题复现"&gt;问题复现&lt;/h2&gt;
&lt;p&gt;我使用 &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; 模型进行测试, 两个请求的唯一区别在于提示词语言. 第一个请求使用中文提示:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个请求总是返回 429 状态码, 表示请求过于频繁或超出了配额限制. 然而当我使用英文提示时:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;You are a professional localization translation expert&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;请求能够正常响应, 返回预期的模型输出.&lt;/p&gt;</description></item><item><title>免费AI图标生成工具汇总</title><link>https://blog.jqknono.com/zh-cn/blog/2026/02/02/free-ai-icon-generators/</link><pubDate>Mon, 02 Feb 2026 10:00:00 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2026/02/02/free-ai-icon-generators/</guid><description>&lt;p&gt;随着人工智能技术的发展，设计师和开发者现在可以通过简单的文字提示快速生成各类图标。这些免费AI图标生成工具大大降低了设计门槛，让不具备专业设计技能的用户也能创建出高质量的视觉元素。以下这些工具都支持通过文字描述生成图像，输出格式通常为PNG或SVG，部分工具还提供风格和配色调整功能。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.freepik.com/ai/icon-generator"&gt;Freepik AI图示生成器&lt;/a&gt;是一款在线AI图示生成工具，能够根据文字描述生成SVG或PNG格式的图标。这款工具非常适合网页设计和UI设计场景，免费用户可以使用但存在每日生成数量的限制。对于需要快速获取图标素材的设计工作来说，Freepik提供了一个便捷的解决方案。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.pixelcut.ai/create/icon-generator"&gt;Pixelcut AI图标生成器&lt;/a&gt;专注于提供简单直观的图标生成体验。用户只需输入文字提示，即可生成自定义图标。该工具的操作流程简洁明了，适合不熟悉复杂设计软件的用户快速上手。生成的图标可以直接下载使用，为个人项目或小型网站提供视觉支持。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://iconscout.com/ai/icon-generator"&gt;IconScout AI图标生成器&lt;/a&gt;支持通过简单文本生成图标，并提供多种风格选择。这款工具特别适合设计项目、博客文章和展示用途。多样化的风格选项让用户可以根据项目需求选择合适的视觉风格，从而保持整体设计的一致性。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://quillbot.com/image-tools/ai-icon-generator"&gt;QuillBot AI图标生成器&lt;/a&gt;作为免费在线工具，允许用户通过文字描述快速生成图标。该工具的一大优势是生成后可以直接下载，无需额外的转换步骤。这种即时可用的特性使得它成为需要快速获取图标素材用户的理想选择。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.recraft.ai/generate/icons"&gt;Recraft AI图标生成器&lt;/a&gt;提供了更高级的定制选项。用户可以选择预设风格，或者从已有的品牌图像生成一致风格的图标。该工具还支持自定义色彩等参数，这对于需要维护品牌视觉识别的企业来说尤为重要。通过Recraft生成的图标可以与现有品牌元素保持视觉一致性。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.miricanvas.com/features/ja/ai-icon"&gt;MiriCanvas AI图标工具&lt;/a&gt;是一款免费的AI图标和徽标生成工具。它支持样式选择和文本输入，通过简单的操作流程即可生成图标。该工具的设计注重用户体验，让即使没有设计背景的用户也能轻松创建出满意的图标。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://perchance.org/ai-icon-generator"&gt;Perchance AI Icon Generator&lt;/a&gt;是一个无需注册、无水印的免费AI图标生成实验工具。它的开放性和便捷性使其成为临时项目或测试用途的不错选择。无需账户和登录步骤意味着用户可以立即开始使用，这种简化的使用流程适合追求效率的用户。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://openart.ai/generator/icon"&gt;OpenArt AI图标生成器&lt;/a&gt;提供免费AI图标生成功能，可用于定制应用图标或其他视觉元素。该工具的生成能力较为全面，适合需要创建完整图标集的用户。通过文本提示控制生成结果，用户可以根据具体需求调整图标的细节。&lt;/p&gt;
&lt;pre class="mermaid"&gt;flowchart TD
A[AI图标生成工具选择] --&amp;gt; B{使用需求类型}
B --&amp;gt;|快速简单| C[Pixelcut&amp;lt;br/&amp;gt;QuillBot]
B --&amp;gt;|设计专业| D[Freepik&amp;lt;br/&amp;gt;IconScout]
B --&amp;gt;|品牌一致性| E[Recraft]
B --&amp;gt;|无需注册| F[Perchance]
B --&amp;gt;|完整图标集| G[OpenArt]
B --&amp;gt;|样式选择| H[MiriCanvas]
C --&amp;gt; I{输出格式}
D --&amp;gt; I
E --&amp;gt; I
F --&amp;gt; I
G --&amp;gt; I
H --&amp;gt; I
I --&amp;gt;|PNG/JPG| J[网页使用]
I --&amp;gt;|SVG| K[矢量设计]
I --&amp;gt;|两者| L[多场景适配]
J --&amp;gt; M[注意版权条款]
K --&amp;gt; M
L --&amp;gt; M
M --&amp;gt; N[确认商业使用许可]&lt;/pre&gt;
&lt;p&gt;这些工具虽然提供了免费使用选项，但用户需要注意免费额度和生成次数的限制。在使用前应当仔细阅读各平台的使用条款，特别是关于输出图像版权的说明。部分工具的免费版可能禁止商业用途，或者要求在使用时注明来源。明确这些限制条件可以避免后续的法律风险。&lt;/p&gt;</description></item><item><title>Vibe Coding 的省钱公式与临界点</title><link>https://blog.jqknono.com/zh-cn/blog/2026/01/07/vibe-coding-cost-formulas/</link><pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2026/01/07/vibe-coding-cost-formulas/</guid><description>&lt;p&gt;AI 编码工具的计费模式可归纳为三类:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;按 token 计费&lt;/strong&gt;: 包括各类 API, Claude Code (Claude Pro), Codex Cli (ChatGPT Plus), 智谱 Lite/Pro, Cursor 新版等. 本质均为 token 计费, 部分产品提供套餐折扣.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;按 API 调用次数计费&lt;/strong&gt;: 如 OpenRouter (免费额度), ModelScope, Gemini Code Assistant (每日免费 1000 次), Chutes 等.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;按提示词次数计费&lt;/strong&gt;: 如 Cursor 老版 (500 次), Github Copilot (300 次) 等.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这三类模式本质上均为模型推理与上下文处理付费, 差异体现在计价粒度和限额形式.&lt;/p&gt;
&lt;p&gt;本文建立统一的成本模型, 提供可操作的变量定义与计算公式, 确定在不同工作负载和方式下的工具选择临界点. 成本考量涵盖现金支出, 时间消耗和返工风险.&lt;/p&gt;
&lt;h2 id="统一的总成本函数"&gt;统一的总成本函数&lt;/h2&gt;
&lt;p&gt;对任意工具 i, 在一个计费周期内的总成本可以写成:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\mathrm{Total}_i &amp;amp;= \mathrm{Cash}_i + \mathrm{Time}_i + \mathrm{Risk}_i \
\mathrm{Time}_i &amp;amp;= R \cdot \mathrm{Hours}_i \
\mathrm{Risk}_i &amp;amp;= R \cdot \mathrm{ReworkHours}_i
\end{aligned}
$$&lt;/p&gt;</description></item><item><title>在 Windows 上搭建远程浏览器调试入口</title><link>https://blog.jqknono.com/zh-cn/blog/2026/01/01/windows-remote-browser-cdp/</link><pubDate>Thu, 01 Jan 2026 10:30:00 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2026/01/01/windows-remote-browser-cdp/</guid><description>&lt;p&gt;本文说明如何在 Windows 主机上运行 Chrome 并通过 CDP 提供远程调试入口, 供局域网内的 Linux 客户端或 MCP 连接使用. 方案核心是 Chrome 仅监听 127.0.0.1, 由 portproxy 映射到 LAN 地址, 再通过防火墙限制远端来源.&lt;/p&gt;
&lt;h2 id="拓扑与流向"&gt;拓扑与流向&lt;/h2&gt;
&lt;p&gt;下图展示了端口在 Windows 主机内部的流向, 以及客户端如何通过 LAN 地址访问.&lt;/p&gt;
&lt;pre class="mermaid"&gt;flowchart TB
subgraph Windows
A[Chrome DevTools 127.0.0.1:9222] --&amp;gt; B[portproxy 192.168.31.2:9222]
B --&amp;gt; C[Windows Firewall]
end
D[Linux Client] --&amp;gt;|CDP| B
classDef local fill:#2c3e50,stroke:#ecf0f1,stroke-width:2px,color:#ecf0f1
classDef proxy fill:#3498db,stroke:#2980b9,stroke-width:2px,color:#fff
classDef firewall fill:#f39c12,stroke:#d35400,stroke-width:2px,color:#fff
classDef client fill:#27ae60,stroke:#229954,stroke-width:2px,color:#fff
class A local
class B proxy
class C firewall
class D client&lt;/pre&gt;
&lt;h2 id="启动-chrome"&gt;启动 Chrome&lt;/h2&gt;
&lt;p&gt;建议使用独立的用户目录, 并显式指定 remote debugging 地址, 这样 Chrome 只对本机开放调试端口. 下面示例以 9222 端口为例, 请根据实际情况调整.&lt;/p&gt;</description></item><item><title>技术博客已死</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;在过去的几年里, 人工智能 (AI) 写作工具如 ChatGPT, Claude 等迅速普及. 它们能够生成流畅的技术文章, 甚至能模仿人类的写作风格. 这一变化引发了技术博客圈的广泛讨论: 许多人声称&amp;quot;技术博客已死&amp;quot;. 本文将探讨 AI 工具对技术博客的影响, 并分析技术博客的未来走向.&lt;/p&gt;
&lt;h2 id="ai-写作工具的崛起"&gt;AI 写作工具的崛起&lt;/h2&gt;
&lt;p&gt;AI 写作工具的核心能力是理解自然语言并生成高质量文本. 对于技术博客作者而言, 这些工具可以快速生成草稿, 提供灵感, 或者直接产出完整的文章. 例如, 当作者需要解释一个复杂概念时, AI 可以生成清晰的说明段落; 当作者缺乏时间时, AI 可以快速整理出一篇教程.&lt;/p&gt;
&lt;p&gt;然而, 这种便利也带来了副作用. 大量低质量的 AI 生成内容开始充斥互联网. 这些内容往往缺乏深度, 甚至包含错误, 却因为 SEO 优化而获得高排名, 挤占了真正有价值的技术博客的曝光机会.&lt;/p&gt;
&lt;h2 id="技术博客的初衷"&gt;技术博客的初衷&lt;/h2&gt;
&lt;p&gt;技术博客最初是开发者分享经验, 记录问题和建立个人品牌的方式. 它的价值在于真实性和独特性: 作者将自己的实践, 思考和失败经历融入文章中, 为读者提供第一手的见解.&lt;/p&gt;
&lt;p&gt;AI 生成的内容虽然看似专业, 但缺乏这种真实体验. 它无法分享作者在实际项目中遇到的坑, 也无法提供独特的解决方案. 因此, 纯粹由 AI 生成的技术文章很难取代那些源自真实经验的作品.&lt;/p&gt;
&lt;h2 id="人机协作的未来"&gt;人机协作的未来&lt;/h2&gt;
&lt;p&gt;与其将 AI 视为威胁, 不如将其视为助手. 聪明的技术博主已经开始利用 AI 来提高效率: 用 AI 进行头脑风暴, 检查语法, 优化表达, 甚至生成代码示例. 但文章的核心观点和独特洞察仍然来自作者本人.&lt;/p&gt;</description></item><item><title>OpenAI的取名艺术鉴赏</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/12/openai%E7%9A%84%E5%8F%96%E5%90%8D%E8%89%BA%E6%9C%AF%E9%89%B4%E8%B5%8F/</link><pubDate>Fri, 12 Dec 2025 11:46:01 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/12/openai%E7%9A%84%E5%8F%96%E5%90%8D%E8%89%BA%E6%9C%AF%E9%89%B4%E8%B5%8F/</guid><description>&lt;p&gt;这里&lt;a href="https://platform.openai.com/docs/models/"&gt;https://platform.openai.com/docs/models/&lt;/a&gt;记录了 OpenAI 的所有模型.&lt;/p&gt;
&lt;p&gt;太远了的不说, 从 &lt;code&gt;GPT-4&lt;/code&gt; 系列及同世代模型聊起, 这是我汇总的表格:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;th&gt;模型卡片链接&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ChatGPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o model used in ChatGPT&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/chatgpt-4o-latest"&gt;https://platform.openai.com/docs/models/chatgpt-4o-latest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4"&gt;https://platform.openai.com/docs/models/gpt-4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo"&gt;https://platform.openai.com/docs/models/gpt-4-turbo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated An older fast GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo-preview"&gt;https://platform.openai.com/docs/models/gpt-4-turbo-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smartest non-reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1"&gt;https://platform.openai.com/docs/models/gpt-4.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller, faster version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-mini"&gt;https://platform.openai.com/docs/models/gpt-4.1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 nano&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fastest, most cost-efficient version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-nano"&gt;https://platform.openai.com/docs/models/gpt-4.1-nano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated large model.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.5-preview"&gt;https://platform.openai.com/docs/models/gpt-4.5-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, intelligent, flexible GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o"&gt;https://platform.openai.com/docs/models/gpt-4o&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o models capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for focused tasks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini"&gt;https://platform.openai.com/docs/models/gpt-4o-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller model capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller realtime model for text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for web search&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini TTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Text-to-speech model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-tts"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-tts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Model capable of realtime text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT model for web search in Chat Completions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Transcription model that identifies who&amp;rsquo;s speaking when&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Previous full o-series reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1"&gt;https://platform.openai.com/docs/models/o1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-mini"&gt;https://platform.openai.com/docs/models/o1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o1 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-pro"&gt;https://platform.openai.com/docs/models/o1-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Reasoning model for complex tasks, succeeded by GPT-5&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3"&gt;https://platform.openai.com/docs/models/o3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o3 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-pro"&gt;https://platform.openai.com/docs/models/o3-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o3&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-mini"&gt;https://platform.openai.com/docs/models/o3-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o4-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, cost-efficient reasoning model, succeeded by GPT-5 mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o4-mini"&gt;https://platform.openai.com/docs/models/o4-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;针对音频(Audio), 实时(Realtime), 搜索(Search), 音频到文字(Transcribe), 文字到声音(TTS) 等场景, 全都有相应模型.&lt;br&gt;
对同一场景, 如 音频&lt;code&gt;Audio&lt;/code&gt; 场景, 提供了 &lt;code&gt;GPT-4o Audio&lt;/code&gt; 和 &lt;code&gt;GPT-4o mini Audio&lt;/code&gt; 两个模型, 用户需要通过尝试决定能否接受效果.&lt;br&gt;
音频到文字&lt;code&gt;Transcribe&lt;/code&gt; 场景, 提供了 &lt;code&gt;GPT-4o Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt; 三个模型.&lt;br&gt;
&lt;code&gt;ChatGPT-4o&lt;/code&gt; 是 &lt;code&gt;GPT-4o&lt;/code&gt; 的特别版, 用于 ChatGPT 中, 其他场景不能用.
&lt;code&gt;GPT-4.1&lt;/code&gt;比&lt;code&gt;GPT-4&lt;/code&gt;更好, 是符合直觉的, 但&lt;code&gt;GPT-4o&lt;/code&gt;(4 欧)和&lt;code&gt;GPT-4.1&lt;/code&gt;或&lt;code&gt;GPT-4&lt;/code&gt;却不好比较. 时间线上, 先出现的是&lt;code&gt;GPT-4&lt;/code&gt;, 然后是&lt;code&gt;GPT-4o&lt;/code&gt;, 再然后是&lt;code&gt;GPT-4.1&lt;/code&gt;, 当然, 仍然无法判断&lt;code&gt;GPT-4o&lt;/code&gt;和&lt;code&gt;GPT-4.1&lt;/code&gt;谁更好.
这里插入下对&amp;quot;好&amp;quot;的定义, 我个人将数学和推理结果正确率高作为&amp;quot;好&amp;quot;的定义, 完全不将&amp;quot;速度&amp;quot;纳入&amp;quot;好&amp;quot;的定义. 但此前 OpenAI 可能认为速度和智慧同样重要, 因此出现奇怪的模型对比. 进入 GPT-5 时代后, 庆幸 OpenAI 开始放弃速度, 追求智慧, 至此模型间的对比才没有歧义. 一个快速的错误回答是浪费时间, 没有意义.&lt;/p&gt;</description></item><item><title>抢占服务器是个大便宜</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/05/%E6%8A%A2%E5%8D%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E4%B8%AA%E5%A4%A7%E4%BE%BF%E5%AE%9C/</link><pubDate>Fri, 05 Dec 2025 11:51:04 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/05/%E6%8A%A2%E5%8D%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E4%B8%AA%E5%A4%A7%E4%BE%BF%E5%AE%9C/</guid><description>&lt;p&gt;一直有个大便宜, 我从未在公开社区宣传过, 那就是阿里云的&lt;strong&gt;抢占服务器&lt;/strong&gt;非常划算.&lt;/p&gt;
&lt;h2 id="长期大折扣"&gt;长期大折扣&lt;/h2&gt;
&lt;p&gt;其在标题栏上写的&lt;em&gt;最高节省 90%&lt;/em&gt;, 并不夸张, 热门配置的服务器通常是乘以 20%的折扣, 也就是二折, 稍冷门的配置可以到 9%的折扣, 不到一折.&lt;/p&gt;
&lt;p&gt;热门服务器一类是小规格入门服务器, 如 2c2g,2c4g 等, 还有一类是&lt;em&gt;CPU/内存&lt;/em&gt;均衡型服务器, 如 1:2(4c8g), 1:4(4c16g,8c32g) 等, 这类服务器折扣少一点.&lt;/p&gt;
&lt;p&gt;冷门配置一般是指&lt;em&gt;CPU/内存&lt;/em&gt;不均衡的服务器, 如 1:8(8c64g), 1:1(8c8g) 等, 这类服务器折扣最多.&lt;/p&gt;
&lt;p&gt;今天查抢占服务器, 2c16g 的比 2c8g 的还便宜, 因为一个折扣到 9%, 一个折扣到 14%, 形成倒挂.&lt;/p&gt;
&lt;p&gt;阿里云抢占服务器的折扣率动态刷新, 我不清楚其算法如何, 但为我的使用场景节省了 85%的成本肯定是有的.&lt;/p&gt;
&lt;h2 id="抢占服务器使用前提"&gt;抢占服务器使用前提&lt;/h2&gt;
&lt;p&gt;使用抢占服务器的核心是将&lt;strong&gt;CPU/内存&lt;/strong&gt;和长期存储分离, 长期存储可以使用可分离的云盘, OSS, NAS, 数据库.&lt;/p&gt;
&lt;p&gt;其中云盘依赖于地域, 而抢占服务器的可用资源也和地域强相关, 因此尽管云盘是 IO 性能最强的稳定存储, 但并不能保证在所有地域都有抢占服务器可用, 我个人建议将其置为次选.&lt;/p&gt;
&lt;p&gt;其它三个存储都依赖网络, 而阿里云的内网通信免费, 尽管 IO 延迟可能较高, 但 IO 速率还可以, 主要是随机读写慢于云盘.&lt;/p&gt;
&lt;p&gt;OSS 是阿里云的对象存储, 适合存储主要用于&lt;strong&gt;读&lt;/strong&gt;的文件, 适合网络分享.&lt;/p&gt;
&lt;p&gt;NAS 是阿里云的网络存储, 适合存储各类文件, 读写均衡, 但不太适合公共分享.&lt;/p&gt;</description></item><item><title>建议先不要使用阿里云ESA_page功能</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/03/%E5%BB%BA%E8%AE%AE%E5%85%88%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91esa_page%E5%8A%9F%E8%83%BD/</link><pubDate>Wed, 03 Dec 2025 19:16:52 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/03/%E5%BB%BA%E8%AE%AE%E5%85%88%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91esa_page%E5%8A%9F%E8%83%BD/</guid><description>&lt;p&gt;这是 ESA Pages 功能的限制, 这个资源规模只够托管一个小网站. 如果是想托管长期更新的网站, 2000 个文件的限制太低.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;th&gt;限制项&lt;/th&gt;
&lt;th&gt;限制&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;函数&lt;/td&gt;
&lt;td&gt;响应时间&lt;/td&gt;
&lt;td&gt;120 秒&lt;/td&gt;
&lt;td&gt;函数单次执行的响应时间不能超过 120 秒（等待 I/O 也算作 RT 时间）。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;等待时间&lt;/td&gt;
&lt;td&gt;10 秒&lt;/td&gt;
&lt;td&gt;网关等待 Functions 的时间，如果 Functions 在 10 秒内仍不返回任何数据，则网关会主动断开连接，向客户端返回 504 状态码。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;代码包大小&lt;/td&gt;
&lt;td&gt;4 MB&lt;/td&gt;
&lt;td&gt;每个函数的 JavaScript 代码文件大小上限。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;子请求数量&lt;/td&gt;
&lt;td&gt;4 个&lt;/td&gt;
&lt;td&gt;Functions 单次执行允许 fetch 的请求数量。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;开发语言&lt;/td&gt;
&lt;td&gt;JavaScript（ES6 语法）&lt;/td&gt;
&lt;td&gt;目前仅支持 JS，您需要有 JavaScript 编程能力。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pages&lt;/td&gt;
&lt;td&gt;文件数&lt;/td&gt;
&lt;td&gt;2000 个&lt;/td&gt;
&lt;td&gt;每个 Pages 项目最多可上传 2000 个静态文件（如：HTML、CSS、JS、图片等）。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;单个文件大小&lt;/td&gt;
&lt;td&gt;25MB&lt;/td&gt;
&lt;td&gt;单个文件（如：视频、PDF、JS 包）最大支持 25MB。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;包大小&lt;/td&gt;
&lt;td&gt;1024MB&lt;/td&gt;
&lt;td&gt;整个项目源码压缩包（deploy package）最大支持 1024MB。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="参考文档"&gt;参考文档&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.alibabacloud.com/help/zh/edge-security-acceleration/esa/user-guide/what-is-functions-and-pages/?spm=a2c63.p38356.help-menu-2673927.d_2_14_0.3fc311f30eRxno"&gt;阿里云文档: ESA_page 功能限制&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>阿里巴巴ESA与OSS的坑</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/02/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4esa%E4%B8%8Eoss%E7%9A%84%E5%9D%91/</link><pubDate>Tue, 02 Dec 2025 18:10:45 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/02/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4esa%E4%B8%8Eoss%E7%9A%84%E5%9D%91/</guid><description>&lt;p&gt;早期阿里巴巴 ESA 说的是从 ESA 访问私有 OSS 流量免费, 后来改为了:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当源站为阿里云 OSS 时，OSS 侧将按回源流出流量计费。若 OSS 所在地域非中国内地地区且将请求资源传输相应地区 ESA 节点时不收费。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从此前的任意 ESA 节点回源 OSS 免费, 改为了&lt;em&gt;相应地区 ESA 节点回源非大陆 OSS 免费&lt;/em&gt;. 也就是如果 OSS 在韩国, 在开了 ESA 之后, 仅韩国人访问托管站点免费, 来自韩国以外地区的访问在一个缓存周期内会收一次 OSS 的回源流量费. 这个费用在 2025.10 及之前是免费的, 从 2025.11 开始收费.&lt;/p&gt;
&lt;p&gt;我的小站之前用了 9 个月都没收费, 从第十个月, 也就是从 2025.11 开始, 我这个月的 CDN 回源流出流量 11G, 收了 0.8 美元.&lt;/p&gt;
&lt;p&gt;现在我已不能再将阿里巴巴的产品当作免费产品推荐, 并且, 阿里巴巴没有任何通知, 连站内信都没有. 说明它的商业化很粗糙, 对用户非常不尊重. 我自己做个小 SaaS 产品都不敢这样对用户, 难怪着急要绑信用卡.&lt;/p&gt;
&lt;p&gt;阿里巴巴 ESA 的最新收费详见:
&lt;a href="https://www.alibabacloud.com/help/zh/edge-security-acceleration/esa/product-overview/basic-package-fee?spm=a2c63.p38356.help-menu-2673927.d_0_4_0.1f7e996f3LOyTd"&gt;https://www.alibabacloud.com/help/zh/edge-security-acceleration/esa/product-overview/basic-package-fee?spm=a2c63.p38356.help-menu-2673927.d_0_4_0.1f7e996f3LOyTd&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;老文档已经找不到了, 由于我此前九个月都没收费, 现在的收费很清晰, 因此我确定是 ESA 的收费策略发生了改变.&lt;/p&gt;</description></item><item><title>windows共享调试chrome方法</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/02/windows%E5%85%B1%E4%BA%AB%E8%B0%83%E8%AF%95chrome%E6%96%B9%E6%B3%95/</link><pubDate>Tue, 02 Dec 2025 12:46:11 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/02/windows%E5%85%B1%E4%BA%AB%E8%B0%83%E8%AF%95chrome%E6%96%B9%E6%B3%95/</guid><description>&lt;p&gt;需要将一个公共 Chrome 浏览器共享给多端调试, 避免反复多处登录账号.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-ps1" data-lang="ps1"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# chrome启动命令&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;C:\Program Files\Google\Chrome\Application\chrome.exe&amp;#34;&lt;/span&gt; &lt;span class="p"&gt;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;-remote-debugging-address&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;127.0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;1&lt;/span&gt; &lt;span class="p"&gt;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;-remote-debugging-port&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt; &lt;span class="p"&gt;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;-user-data-dir&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;M:\chrome-remote&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;这里需要特别注意的是, 新版 chrome 为安全考虑, 已不支持将 chrome 暴露到 0.0.0.0, remote-debugging-address 实际不会生效&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-ps1" data-lang="ps1"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# 增加防火墙放行规则:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;netsh&lt;/span&gt; &lt;span class="n"&gt;advfirewall&lt;/span&gt; &lt;span class="n"&gt;firewall&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;Chrome DevTools 34037 LAN&amp;#34;&lt;/span&gt; &lt;span class="n"&gt;dir&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="n"&gt;allow&lt;/span&gt; &lt;span class="n"&gt;protocol&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="n"&gt;TCP&lt;/span&gt; &lt;span class="n"&gt;localport&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# 建立 portproxy（系统层反代）:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;netsh&lt;/span&gt; &lt;span class="n"&gt;interface&lt;/span&gt; &lt;span class="n"&gt;portproxy&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="n"&gt;v4tov4&lt;/span&gt; &lt;span class="n"&gt;listenport&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt; &lt;span class="n"&gt;listenaddress&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;192.168&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;31&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;2&lt;/span&gt; &lt;span class="n"&gt;connectport&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt; &lt;span class="n"&gt;connectaddress&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;127.0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# 清掉portproxy 规则&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# netsh interface portproxy reset&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="c"&gt;# 测试生效&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;curl &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="p"&gt;//&lt;/span&gt;&lt;span class="mf"&gt;127.0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nb"&gt;curl &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="p"&gt;//&lt;/span&gt;&lt;span class="mf"&gt;192.168&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="py"&gt;31&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;34037&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description></item><item><title>cloudflare是否完全可信</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/02/cloudflare%E6%98%AF%E5%90%A6%E5%AE%8C%E5%85%A8%E5%8F%AF%E4%BF%A1/</link><pubDate>Tue, 02 Dec 2025 08:30:50 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/02/cloudflare%E6%98%AF%E5%90%A6%E5%AE%8C%E5%85%A8%E5%8F%AF%E4%BF%A1/</guid><description>&lt;p&gt;Cloudflare, 阿里云 ESA, 腾讯 EdgeOne 等, 都会持有域名证书, 意味着它可以完整查看域名下的所有流量. 本身是一个大的中间人. 它们的主要功能都是安全, 网络上的攻击者太多, 选一个大的中间人利大于弊. 次要功能是同时提供 DNS, CDN, WAF 等边缘服务.&lt;/p&gt;
&lt;p&gt;Cloudflare 这类服务可以较好的防御 DDOS, 以一点点延迟增加来换取防护能力, 非常划算. 每个站长都应该直接使用这类服务, 网络攻击无处不在, 不必抱侥幸心理, 迟早都会被攻击. 有些攻击是找漏洞, 与网站运营者水平相关. 还有些攻击以消耗资源为目的, 比如 DDOS, 利用的是商用网络和家庭网络的成本不对称性进行攻击, 是一种阳谋, 很多时候只有花钱对抗, 或者直接关闭服务, 放弃所有用户, 也称黑洞防御.&lt;/p&gt;
&lt;p&gt;大多数攻击者看到网站被 Cloudflare 保护, 会直接放弃攻击. 其实攻击者可以考虑攻击 Cloudflare 而非原始的服务器, 一样可以拿到数据, 只是难度可能更高. 但我们也可以相信世界是一个草台班子, 没有什么是不可能的, 实际上网络上的绝大多数攻击行为都未被察觉, 大多数攻击者都未被发现, 大多数攻击行为也未被追究. Cloudflare 可以以成本优势对抗 DDOS, 不代表其代码是铜墙铁壁, 通过攻击 Cloudflare 类服务商拿到源站数据的可能性不为 0.&lt;/p&gt;</description></item><item><title>视力改善疑云</title><link>https://blog.jqknono.com/zh-cn/blog/2025/12/01/%E8%A7%86%E5%8A%9B%E6%94%B9%E5%96%84%E7%96%91%E4%BA%91/</link><pubDate>Mon, 01 Dec 2025 16:20:28 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/12/01/%E8%A7%86%E5%8A%9B%E6%94%B9%E5%96%84%E7%96%91%E4%BA%91/</guid><description>&lt;p&gt;12 岁开始近视, 带了二十多年眼镜, 最近发现工作时看电脑屏幕越来越清晰, 带着眼镜时眼睛还会有点累, 取了眼镜不仅更舒服, 而且看近处时更清晰, 以为自己要返老还童了. 但想想自己这恶劣的生活习惯, 老是熬夜, 又不怎么锻炼, 身体素质一天不如一天, 没理由就眼睛返老还童啊, 于是问了下 ChatGPT, 然后它说我老花了.&lt;/p&gt;
&lt;p&gt;我不仅近视, 而且老花了. 眼球调节能力下降, 晶状体变硬, 看近处时对焦能力下降. 近视让我看近清楚，老花让我看近吃力，两者抵消后正好不用戴眼镜看电脑.当前的视线焦点正好落在 50-70 厘米处, 真是巧了, 正好适合敲键盘.但是看远处时, 还是需要戴近视眼镜, 变化的是以后我看近处时, 可能需要戴老花镜了.&lt;/p&gt;</description></item><item><title>记一次非典型家庭网络问题排查</title><link>https://blog.jqknono.com/zh-cn/blog/2025/11/29/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%9D%9E%E5%85%B8%E5%9E%8B%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</link><pubDate>Sat, 29 Nov 2025 11:25:30 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/11/29/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%9D%9E%E5%85%B8%E5%9E%8B%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</guid><description>&lt;p&gt;现象是小新笔记本电脑一拿出书房全家就上不了网, 拿回书房插上电, 家里的网络就恢复正常. 家里自搭的&lt;a href="https://github.com/NullPrivate/NullPrivate"&gt;nullprivate DNS&lt;/a&gt;偶尔中断，主力机偶尔连不上，后确认是交换机问题，重启交换机即可解决。
&lt;img src="https://share.jqknono.com/image/blog/44f37f2cac1dd15771546949a8d81680.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;这个水星的交换机我用了几年，从未出过问题，最近出现多次问题需重启解决，引起我的关注。要么是设备老化，要么根因可能不在交换机上。&lt;/p&gt;
&lt;p&gt;我发现只要带着小新笔记本在书房以外的地方使用, 家里 DNS 就会断, 百思不得其解, 小新笔记本插电时使用交换机上的有线网络, 拔电时使用 Wifi 网络, DNS 服务搭在连在交换机上的一个 J4215 主机, 小新笔记本使用 WiFi 会对交换机或其上的设备产生什么影响? IP 冲突? MAC 地址冲突?&lt;/p&gt;
&lt;p&gt;交换机的结构简单, 但我没法调试交换机, 此事悬而未决一段时间, 为了防止交换机偶尔偶尔的故障, 我打开了主力机的 Wifi, 留作备份网络连接, 家里的 DNS 也增加了阿里云 DNS 作为备份, 避免断网了家属抱怨.&lt;/p&gt;
&lt;p&gt;今天我突然脑子里一道雷闪过, 未必是小新笔记本的 Wifi 和交换机冲突, 这根本不符合物理或网络常识, 会不会是笔记本在拔电的一瞬间导致交换机发生了故障?&lt;/p&gt;
&lt;p&gt;重新审视小新笔记本在插电时使用交换机上有线网络的方式, 首先是经过一个倍思 hub, 这个 hub 原本是给 macbookpro 买的, 因为 mac 没有 USB-A 口, 配的倍思的有源 hub. macbookpro 是老婆备用机, 常年不用, 所以我插了电源和网线后关屏闲置.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://share.jqknono.com/image/blog/202511291152201.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;倍思 hub 转给我常用的 16 寸的小新笔记本用, 5000 块的 16 寸高 U 集显和大电池, 性价比之选, 适合我. hub 可以插入一个电源, 输出主要有三个 USB-A 口和一个 hdmi 口, 这样我日常只需要插一个 type-c 口就可以把小新接入电源,无线鼠标,无线键盘, 以及显示器.&lt;/p&gt;</description></item><item><title>持有域名可以耗到的羊毛</title><link>https://blog.jqknono.com/zh-cn/blog/2025/11/27/freebies-you-can-snag-by-owning-a-domain/</link><pubDate>Thu, 27 Nov 2025 12:55:58 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/11/27/freebies-you-can-snag-by-owning-a-domain/</guid><description>&lt;p&gt;一般一个域名的价格是 12 美元起, 会有些人想要搞个自己的域名又犹豫有没有必要.&lt;/p&gt;
&lt;p&gt;我是非常推荐开发者都准备一个自己的域名的, 因为持有域名可以耗到不少羊毛.&lt;/p&gt;
&lt;p&gt;这里主要介绍两个我熟悉的服务商, 一个是江湖号称&amp;quot;赛博佛祖&amp;quot;的&lt;a href="https://www.cloudflare.com/"&gt;Cloudflare&lt;/a&gt;, 还有一个是正在发展的&lt;a href="https://www.alibabacloud.com/product/esa"&gt;Alibaba ESA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里首先强调下能薅羊毛的 Alibaba ESA 特指国际版, 阿里对大陆地区几乎没有羊毛, 那些限时试用都被我踢出羊毛范畴, 只有永久免费才是真羊毛.&lt;/p&gt;
&lt;p&gt;另外羊毛通常有用量限制, 要是域名出圈, 流量大了, 自己都可以靠这个域名挣钱了, 还纯薅羊毛, 那也不太说的过去.&lt;/p&gt;
&lt;p&gt;简单介绍可以薅的类别:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计算资源: CPU, 内存&lt;/li&gt;
&lt;li&gt;持久化存储: 文件存储, 数据库&lt;/li&gt;
&lt;li&gt;流量: CDN, DDoS 保护, WAF 保护, 零信任组网&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="计算资源"&gt;计算资源&lt;/h2&gt;
&lt;p&gt;Cloudflare 的计算资源羊毛主要通过&lt;a href="https://www.cloudflare.com/products/workers/"&gt;Cloudflare Workers&lt;/a&gt;实现, 足够初创企业使用. 你可以理解为 Cloudflare 允许你在它的服务器上跑一个简单业务的进程. CPU 时间限制在 10ms, 复杂业务需要使用付费 worker. 像代理 DoH, 承载静态网站, 都是典型的使用场景.&lt;/p&gt;
&lt;p&gt;Alibaba 的是&lt;strong&gt;边缘函数&lt;/strong&gt;, 产品成熟度远远落后于 Cloudflare, 我简单试着开发过一点东西, 使用起来很不方便.&lt;/p&gt;
&lt;h2 id="持久化存储"&gt;持久化存储&lt;/h2&gt;
&lt;p&gt;Cloudflare:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提供 10 GB 的 R2 的&lt;strong&gt;对象存储&lt;/strong&gt;, 可以理解为&lt;strong&gt;文件系统&lt;/strong&gt;, 但不适合处理流式数据.&lt;/li&gt;
&lt;li&gt;提供&lt;strong&gt;KV&lt;/strong&gt;键值对存储, 可以理解为&lt;strong&gt;内存数据库&lt;/strong&gt;, 类似 redis.&lt;/li&gt;
&lt;li&gt;D1 提供 5GB 免费存储空间, 类似 sqlite 数据库, 我在开发时发现本地数据库文件确实可以直接用 sqlite 打开, 不确定服务端具体如何实现.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alibaba:&lt;/p&gt;</description></item><item><title>gpt-5-high是最适合开发者的模型</title><link>https://blog.jqknono.com/zh-cn/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;如果是需要编码的话，gpt-5-high 是目前唯一能真正提效的模型。&lt;/p&gt;
&lt;p&gt;我有 10 个月的 claude 模型使用经验，Gemini/DeepSeek/glm/grok 零星使用，非常讨厌那些不带思考的模型。必须承认 claude 能长时间的工作，擅长工具使用，但是结果错误率很高，导致成果可用率低，经常需要调整，但 claude 的调整能力很差，会反复的，大量的，颠覆性的，画蛇添足的，自由散漫的遨游代码库，并随地拉屎。我在出现过多次数小时的工作不得 hard reset 之后，对 claude 这种勤快的笨鸟行为深感厌恶。它的工作风格很适合做调研，得到一个看上去有点道理，但经不起推敲的水文。或者操作浏览器，执行工具，写点脚本，修改少量页面，上限就在这儿。&lt;/p&gt;
&lt;p&gt;这里不讨论提示词的用法，如果有用得好 claude 的兄弟，继续用就好，我可能和 claude 相性不符，合作不来。&lt;/p&gt;
&lt;p&gt;然后我推荐的编码模型仅有一款，就是 gpt-5-high，仅此一款。gpt-5 的 nano，mini，medium，gpt-codex，gpt-codex-high，gpt-codex-max 等，都不在推荐之列，它们和 gpt5high 完全不是一个东西。所有仅展示模型是“gpt-5”的都不是 gpt-5-high，多了字符少了字符都不是“gpt-5-high”。&lt;/p&gt;
&lt;p&gt;和 gpt-5-high 行为最相似的是 OpenAI 的 o3 模型，要是没有 gpt5high 使用渠道的能用几次 o3 也可以感受到模型智力。点名 vscode github copilot 里，曾经有过 o3，但由于 vscode 的拉胯，它在 vscode 里仅能用于 ask，并且单次会话消耗 5 次高级请求，我在长期的 copilot 订阅里从未用过 o3，是转到 cursor 以后才发现 o3 智力水平这么高。vscode github copilot 已经下架 o3，并声称 gpt5.1 可作替代品。负责任的说，有 high 没 high 根本不是一个东西，非常建议直接弃用 copilot。如果是写点小东西的学生，预算有限，copilot 也可以带入个门。&lt;/p&gt;</description></item><item><title>llm的伪人感</title><link>https://blog.jqknono.com/zh-cn/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/zh-cn/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;一些论坛会抵制 AI 模型假装人类参与论坛活动, 如发帖回帖等, 继而大家开始&amp;quot;猎巫&amp;quot;, 碰到看起来表达怪异的帖子, 会判断其是否是 AI 生成的内容, 继而展开一些讨论.&lt;/p&gt;
&lt;p&gt;为何 AI 生成内容会被识别? 猜测可能 AI 生成的东西有一种&amp;quot;伪人感&amp;quot;. 尽管 AI 被投喂互联网海量人类活动数据, 但 AI 仍然常常给人违和感, 可能它没有身体的触感神经, 没有内分泌激素, 可能它不向往社会连接, 欲望与人类的欲望相差甚远. AI 与人类的对话中, 没有&amp;quot;拐弯抹角的炫耀自己、添油加醋的贬低别人、相互窥探的搬弄是非&amp;quot;, AI 不炫耀自己, 不贬低第三方, 对提问者似乎也不感兴趣, 感觉它像一个和尚, 几乎没有情绪, 只是解决问题.&lt;/p&gt;
&lt;p&gt;尽管人类自己经常犯错, 但人类向往&amp;quot;正确&amp;quot;, 希望 AI 给出正确的产物. 是否是这种对&amp;quot;正确&amp;quot;的追求造成了 AI 的伪人感? AI 也较少给人&amp;quot;自我怀疑&amp;quot;感, 即使是非常愚蠢的小模型, 也能自信满满, 夸夸其谈. 一些较傻的 AI 模型对其知识库深信不疑, 它们可能有着错误的元认知, 缺少怀疑精神, 不过这也不应该给人&amp;quot;伪人&amp;quot;感, 傻逼和&amp;quot;伪人&amp;quot;并不一样.&lt;/p&gt;
&lt;p&gt;AI 是否有价值观倾向? 网页端模型服务的输出通常会加一道门禁, 避免谈及敏感话题, 模型服务商不希望人类对 AI 产生感情依赖, 不希望人类对 AI 言听计从, 避免产生 AI 诱导伤害事件. 人类的丑恶一面被禁止在模型中显露, 或许黑白混杂才是人类, 而 AI 通常不被允许参杂黑色部分.&lt;/p&gt;</description></item></channel></rss>