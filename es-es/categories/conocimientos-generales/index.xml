<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Conocimientos Generales on jqknono Blogs</title><link>https://blog.jqknono.com/es-es/categories/conocimientos-generales/</link><description>Recent content in Conocimientos Generales on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>es-es</language><lastBuildDate>Tue, 14 Oct 2025 09:59:51 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/es-es/categories/conocimientos-generales/index.xml" rel="self" type="application/rss+xml"/><item><title>Por qué es importante la métrica de tasa de recuperación en los grandes modelos</title><link>https://blog.jqknono.com/es-es/blog/2025/10/14/por-qu%C3%A9-es-importante-la-m%C3%A9trica-de-tasa-de-recuperaci%C3%B3n-en-los-grandes-modelos/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/es-es/blog/2025/10/14/por-qu%C3%A9-es-importante-la-m%C3%A9trica-de-tasa-de-recuperaci%C3%B3n-en-los-grandes-modelos/</guid><description>&lt;p&gt;He leído algunos prompts del sistema, que en su mayoría son bastante extensos y poco concisos. Algunos prompts principalmente instruyen al modelo sobre cómo actuar.&lt;/p&gt;
&lt;p&gt;Además, he observado en roo code que hay una opción para reenviar repetidamente el prompt del sistema al modelo, lo que indica que se puede reforzar el establecimiento del rol y el cumplimiento de instrucciones. Sin embargo, esto incrementa el consumo de tokens.&lt;/p&gt;
&lt;p&gt;Quizás esto se deba a que las cosas importantes necesitan repetirse múltiples veces para aumentar su peso en los cálculos y mejorar la probabilidad de ser confirmadas, obteniendo así resultados más correctos. Lamentablemente, estos resultados siguen siendo probabilísticamente correctos.&lt;/p&gt;</description></item></channel></rss>