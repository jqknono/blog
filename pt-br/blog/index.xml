<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on jqknono Blogs</title><link>https://blog.jqknono.com/pt-br/blog/</link><description>Recent content in Blog on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>pt-br</language><managingEditor>https://blog.jqknono.com (jqknono)</managingEditor><webMaster>https://blog.jqknono.com (jqknono)</webMaster><lastBuildDate>Mon, 13 Nov 2023 14:15:31 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/pt-br/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Extensão Project Translator para VSCode Implementa Localização Multilíngue de Projetos</title><link>https://blog.jqknono.com/pt-br/blog/2026/02/26/project-translator-vscode-extension/</link><pubDate>Thu, 26 Feb 2026 14:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2026/02/26/project-translator-vscode-extension/</guid><description>Project Translator é uma extensão poderosa para VSCode que, baseada em IA, realiza tradução automática em nível de projeto, mantendo a integridade da estrutura do código enquanto conclui eficientemente a localização de documentos.</description></item><item><title>GPT-5.3-Codex Experiência Inicial: Do Encanto à Avaliação Racional</title><link>https://blog.jqknono.com/pt-br/blog/2026/02/17/gpt-53-codex-experience/</link><pubDate>Tue, 17 Feb 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2026/02/17/gpt-53-codex-experience/</guid><description>&lt;p&gt;OpenAI, antes do lançamento oficial da versão completa do GPT-5.3, lançou primeiro o modelo especializado GPT-5.3-Codex. Do ponto de vista comercial, essa decisão é fácil de entender. O GPT-5.3-Codex tem o mesmo preço da versão padrão do GPT-5.3, mas sua saída é mais proativa, o tempo de execução é mais curto e o consumo de memória é menor, o que significa uma margem de lucro maior. Para a OpenAI, o GPT-5.3-Codex é claramente uma escolha mais custo‑efetiva.&lt;/p&gt;</description></item><item><title>Análise Comparativa das Tecnologias DoH e DoT</title><link>https://blog.jqknono.com/pt-br/blog/2026/02/11/doh-vs-dot-comparison/</link><pubDate>Wed, 11 Feb 2026 00:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2026/02/11/doh-vs-dot-comparison/</guid><description>&lt;p&gt;DNS over HTTPS (DoH) e DNS over TLS (DoT) são duas formas comuns de transmissão de DNS criptografada; elas implementam a transmissão segura de consultas DNS através de diferentes pilhas de protocolos. O padrão DoT é definido pelo &lt;a href="https://datatracker.ietf.org/doc/html/rfc7858"&gt;RFC 7858&lt;/a&gt;, enquanto o DoH é padronizado pelo &lt;a href="https://datatracker.ietf.org/doc/html/rfc8484"&gt;DNS Queries over HTTPS (DoH)&lt;/a&gt;. Para compreender as diferenças essenciais entre essas duas tecnologias, é necessário analisar a partir da estrutura em camadas do protocolo de rede.&lt;/p&gt;</description></item><item><title>Registro de Depuração: O modelo OpenRouter gpt-oss-120b não suporta solicitações em chinês</title><link>https://blog.jqknono.com/pt-br/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;Ao usar a API de modelo gratuito fornecida pela &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, encontrei um problema confuso. Com a mesma estrutura de solicitação, apenas alterando o idioma do prompt, resultados completamente diferentes ocorrem.&lt;/p&gt;
&lt;h2 id="reprodução-do-problema"&gt;Reprodução do Problema&lt;/h2&gt;
&lt;p&gt;Usei o modelo &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; para testes. A única diferença entre as duas solicitações era o idioma do prompt. A primeira solicitação usava um prompt em chinês:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Esta solicitação sempre retornava o código de status 429, indicando que as solicitações eram frequentes demais ou excediam o limite de cota. No entanto, quando usei um prompt em inglês:&lt;/p&gt;</description></item><item><title>Resumo de Ferramentas Gratuitas de Geração de Ícones por IA</title><link>https://blog.jqknono.com/pt-br/blog/2026/02/02/free-ai-icon-generators/</link><pubDate>Mon, 02 Feb 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2026/02/02/free-ai-icon-generators/</guid><description>&lt;p&gt;Com o desenvolvimento da tecnologia de inteligência artificial, designers e desenvolvedores podem agora gerar rapidamente vários tipos de ícones através de simples comandos de texto. Essas ferramentas gratuitas de geração de ícones por IA reduziram drasticamente a barreira de entrada para o design, permitindo que usuários sem habilidades profissionais de design também criem elementos visuais de alta qualidade. Todas as ferramentas a seguir suportam a geração de imagens a partir de descrições de texto, com formatos de saída geralmente em PNG ou SVG, e algumas ferramentas também oferecem recursos de ajuste de estilo e paleta de cores.&lt;/p&gt;</description></item><item><title>Fórmulas de Economia e Pontos Críticos do Vibe Coding</title><link>https://blog.jqknono.com/pt-br/blog/2026/01/07/vibe-coding-cost-formulas/</link><pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2026/01/07/vibe-coding-cost-formulas/</guid><description>&lt;p&gt;Os modelos de cobrança das ferramentas de codificação com IA podem ser resumidos em três categorias:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Cobrança por token&lt;/strong&gt;: Inclui várias APIs, Claude Code (Claude Pro), Codex Cli (ChatGPT Plus), Zhipu Lite/Pro, nova versão do Cursor, etc. Essencialmente baseados em token, com alguns produtos oferecendo descontos em pacotes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cobrança por número de chamadas de API&lt;/strong&gt;: Como OpenRouter (cota gratuita), ModelScope, Gemini Code Assistant (1000 vezes gratuitas por dia), Chutes, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cobrança por número de prompts&lt;/strong&gt;: Como versão antiga do Cursor (500 vezes), Github Copilot (300 vezes), etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Esses três modelos são essencialmente pagos pela inferência do modelo e processamento de contexto, com diferenças refletidas na granularidade de precificação e na forma dos limites.&lt;/p&gt;</description></item><item><title>Configurando um ponto de depuração de navegador remoto no Windows</title><link>https://blog.jqknono.com/pt-br/blog/2026/01/01/windows-remote-browser-cdp/</link><pubDate>Thu, 01 Jan 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2026/01/01/windows-remote-browser-cdp/</guid><description>&lt;p&gt;Este artigo descreve como executar o Chrome em um host Windows e fornecer um ponto de depuração remota via CDP para clientes Linux na LAN ou conexão MCP. O núcleo da solução é que o Chrome só escuta 127.0.0.1, mapeado para o endereço LAN pelo portproxy, e então restringido por firewall para origem remota.&lt;/p&gt;
&lt;h2 id="topologia-e-fluxo"&gt;Topologia e fluxo&lt;/h2&gt;
&lt;p&gt;O diagrama abaixo mostra o fluxo de porta dentro do host Windows e como o cliente acessa via endereço LAN.&lt;/p&gt;</description></item><item><title>Blogs técnicos estão mortos</title><link>https://blog.jqknono.com/pt-br/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;Nos últimos anos, as ferramentas de escrita por IA (Inteligência Artificial), como ChatGPT, Claude, etc., se popularizaram rapidamente. Elas conseguem gerar artigos técnicos fluidos e até imitar o estilo de escrita humano. Essa mudança gerou ampla discussão no círculo de blogs técnicos: muitas pessoas afirmam que &amp;ldquo;os blogs técnicos estão mortos&amp;rdquo;. Este artigo explorará o impacto das ferramentas de IA nos blogs técnicos e analisará o futuro dos blogs técnicos.&lt;/p&gt;</description></item><item><title>A Arte da Nomeação da OpenAI</title><link>https://blog.jqknono.com/pt-br/blog/2025/12/12/a-arte-da-nomeacao-da-openai/</link><pubDate>Fri, 12 Dec 2025 11:46:01 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2025/12/12/a-arte-da-nomeacao-da-openai/</guid><description>&lt;p&gt;Aqui &lt;a href="https://platform.openai.com/docs/models/"&gt;https://platform.openai.com/docs/models/&lt;/a&gt; estão registrados todos os modelos da OpenAI.&lt;/p&gt;
&lt;p&gt;Não falaremos dos mais antigos, vamos começar pela série &lt;code&gt;GPT-4&lt;/code&gt; e modelos da mesma geração. Esta é a tabela que compilei:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Nome&lt;/th&gt;
&lt;th&gt;Descrição&lt;/th&gt;
&lt;th&gt;Link do Modelo&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ChatGPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo GPT-4o usado no ChatGPT&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/chatgpt-4o-latest"&gt;https://platform.openai.com/docs/models/chatgpt-4o-latest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo GPT antigo de alta inteligência&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4"&gt;https://platform.openai.com/docs/models/gpt-4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo GPT antigo de alta inteligência&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo"&gt;https://platform.openai.com/docs/models/gpt-4-turbo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;(Depreciado) Modelo GPT antigo rápido&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo-preview"&gt;https://platform.openai.com/docs/models/gpt-4-turbo-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo mais inteligente sem raciocínio&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1"&gt;https://platform.openai.com/docs/models/gpt-4.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Versão menor e mais rápida do GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-mini"&gt;https://platform.openai.com/docs/models/gpt-4.1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 nano&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Versão mais rápida e eficiente do GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-nano"&gt;https://platform.openai.com/docs/models/gpt-4.1-nano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;(Depreciado) Modelo grande antigo&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.5-preview"&gt;https://platform.openai.com/docs/models/gpt-4.5-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo GPT rápido, inteligente e flexível&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o"&gt;https://platform.openai.com/docs/models/gpt-4o&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelos GPT-4o capazes de entradas/saídas de áudio&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo pequeno rápido e acessível para tarefas específicas&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini"&gt;https://platform.openai.com/docs/models/gpt-4o-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo menor capaz de entradas/saídas de áudio&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo menor em tempo real para texto/áudio&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo pequeno rápido para busca na web&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo voz-para-texto baseado no GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini TTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo texto-para-voz baseado no GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-tts"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-tts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo para entradas/saídas de texto/áudio em tempo real&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo GPT para busca web no Chat Completions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo voz-para-texto baseado no GPT-4o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo de transcrição que identifica falantes&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo anterior completo de raciocínio série-o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1"&gt;https://platform.openai.com/docs/models/o1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Alternativa pequena ao o1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-mini"&gt;https://platform.openai.com/docs/models/o1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Versão do o1 com mais recursos para melhores respostas&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-pro"&gt;https://platform.openai.com/docs/models/o1-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo de raciocínio para tarefas complexas (sucedido por GPT-5)&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3"&gt;https://platform.openai.com/docs/models/o3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Versão do o3 com mais recursos para melhores respostas&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-pro"&gt;https://platform.openai.com/docs/models/o3-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Alternativa pequena ao o3&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-mini"&gt;https://platform.openai.com/docs/models/o3-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o4-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelo de raciocínio rápido e eficiente (sucedido por GPT-5 mini)&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o4-mini"&gt;https://platform.openai.com/docs/models/o4-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Para cenários como áudio (Audio), tempo real (Realtime), busca (Search), áudio para texto (Transcribe), texto para voz (TTS), há modelos correspondentes.&lt;br&gt;
Para o mesmo cenário, como áudio &lt;code&gt;Audio&lt;/code&gt;, são oferecidos dois modelos: &lt;code&gt;GPT-4o Audio&lt;/code&gt; e &lt;code&gt;GPT-4o mini Audio&lt;/code&gt;, onde os usuários precisam testar para decidir se aceitam os resultados.&lt;br&gt;
No cenário áudio-para-texto &lt;code&gt;Transcribe&lt;/code&gt;, são oferecidos três modelos: &lt;code&gt;GPT-4o Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;.&lt;br&gt;
&lt;code&gt;ChatGPT-4o&lt;/code&gt; é uma versão especial do &lt;code&gt;GPT-4o&lt;/code&gt; usada no ChatGPT, não disponível em outros cenários.&lt;br&gt;
&lt;code&gt;GPT-4.1&lt;/code&gt; é melhor que &lt;code&gt;GPT-4&lt;/code&gt;, o que é intuitivo, mas &lt;code&gt;GPT-4o&lt;/code&gt; (4 &amp;ldquo;o&amp;rdquo;) e &lt;code&gt;GPT-4.1&lt;/code&gt; ou &lt;code&gt;GPT-4&lt;/code&gt; não são facilmente comparáveis. Cronologicamente, primeiro surgiu &lt;code&gt;GPT-4&lt;/code&gt;, depois &lt;code&gt;GPT-4o&lt;/code&gt;, e então &lt;code&gt;GPT-4.1&lt;/code&gt;, mas ainda não é claro qual é melhor entre &lt;code&gt;GPT-4o&lt;/code&gt; e &lt;code&gt;GPT-4.1&lt;/code&gt;.&lt;br&gt;
Aqui defino &amp;ldquo;melhor&amp;rdquo; como alta taxa de acerto em matemática e raciocínio, ignorando completamente a &amp;ldquo;velocidade&amp;rdquo;. Antes, a OpenAI talvez considerasse velocidade e inteligência igualmente importantes, levando a comparações estranhas entre modelos. Na era GPT-5, felizmente a OpenAI começou a priorizar inteligência sobre velocidade, eliminando ambiguidades nas comparações. Uma resposta rápida mas errada é perda de tempo sem sentido.&lt;/p&gt;</description></item><item><title>Servidores Spot são uma grande oportunidade</title><link>https://blog.jqknono.com/pt-br/blog/2025/12/05/%E6%8A%A2%E5%8D%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E4%B8%AA%E5%A4%A7%E4%BE%BF%E5%AE%9C/</link><pubDate>Fri, 05 Dec 2025 11:51:04 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/pt-br/blog/2025/12/05/%E6%8A%A2%E5%8D%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E4%B8%AA%E5%A4%A7%E4%BE%BF%E5%AE%9C/</guid><description>&lt;p&gt;Sempre houve uma grande oportunidade que nunca divulguei publicamente na comunidade, que é a de que os &lt;strong&gt;servidores spot&lt;/strong&gt; da Alibaba Cloud são extremamente vantajosos.&lt;/p&gt;
&lt;h2 id="descontos-de-longo-prazo"&gt;Descontos de longo prazo&lt;/h2&gt;
&lt;p&gt;O título &amp;ldquo;economize até 90%&amp;rdquo; não é exagero, os servidores com configurações populares geralmente recebem um desconto de 20%, ou seja, 20% do preço original, e configurações menos populares podem chegar a 9% de desconto, menos de 10% do preço original.&lt;/p&gt;</description></item></channel></rss>