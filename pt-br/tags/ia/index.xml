<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>IA on jqknono Blogs</title><link>https://blog.jqknono.com/pt-br/tags/ia/</link><description>Recent content in IA on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>pt-br</language><lastBuildDate>Tue, 23 Dec 2025 17:05:13 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/pt-br/tags/ia/index.xml" rel="self" type="application/rss+xml"/><item><title>Blogs técnicos estão mortos</title><link>https://blog.jqknono.com/pt-br/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><guid>https://blog.jqknono.com/pt-br/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;Nos últimos anos, as ferramentas de escrita por IA (Inteligência Artificial), como ChatGPT, Claude, etc., se popularizaram rapidamente. Elas conseguem gerar artigos técnicos fluidos e até imitar o estilo de escrita humano. Essa mudança gerou ampla discussão no círculo de blogs técnicos: muitas pessoas afirmam que &amp;ldquo;os blogs técnicos estão mortos&amp;rdquo;. Este artigo explorará o impacto das ferramentas de IA nos blogs técnicos e analisará o futuro dos blogs técnicos.&lt;/p&gt;</description></item><item><title>gpt-5-high é o modelo mais adequado para desenvolvedores</title><link>https://blog.jqknono.com/pt-br/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/pt-br/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;Se precisar codificar, o gpt-5-high é atualmente o único modelo que realmente aumenta a produtividade.&lt;/p&gt;
&lt;p&gt;Tenho 10 meses de experiência usando o modelo Claude, uso ocasionalmente Gemini/DeepSeek/glm/grok, e detesto profundamente aqueles modelos que não pensam. Devo admitir que o Claude consegue trabalhar por longos períodos e é bom no uso de ferramentas, mas tem uma alta taxa de erros nos resultados, o que faz com que a taxa de utilização dos resultados seja baixa, exigindo frequentes ajustes. No entanto, a capacidade de ajuste do Claude é muito ruim, ele tende a fazer alterações repetitivas, em grande quantidade, radicais, desnecessárias e desorganizadas no código, e ainda deixa &amp;ldquo;cocôs&amp;rdquo; espalhados por todo o repositório. Após várias experiências de horas de trabalho sendo obrigado a fazer hard reset, sinto profunda aversão ao comportamento desse &amp;ldquo;pássaro diligente mas burro&amp;rdquo;. O estilo de trabalho dele é adequado para pesquisas, obtendo textos que parecem ter algum sentido, mas não resistem a uma análise mais profunda. Ou então, operar navegadores, executar ferramentas, escrever scripts e fazer pequenas alterações em páginas, esse é o limite.&lt;/p&gt;</description></item><item><title>Sensação de falsidade humana da LLM</title><link>https://blog.jqknono.com/pt-br/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/pt-br/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Algumas comunidades online resistem a modelos de IA que fingem ser humanos e participam de atividades, como postar e responder. Isso gera uma caça às bruxas, onde mensagens estranhas são suspeitas de serem geradas por IA, gerando discussões.&lt;/p&gt;
&lt;p&gt;Por que o conteúdo gerado por IA é identificado? Suspeito que seja devido a uma &amp;ldquo;sensação de falsidade humana&amp;rdquo;. Embora a IA seja alimentada por dados massivos de atividades humanas na internet, ainda assim costuma causar estranheza. Talvez por não ter sensações táteis, sem glândulas endócrinas, sem desejo de conexão social, seus desejos são muito diferentes dos humanos. No diálogo com humanos, a IA não possui &amp;ldquo;ostentação indireta, desvalorização exagerada de terceiros, fofocas de investigação mútua&amp;rdquo;, não se exibe, não difama terceiros, aparentemente não se interessa pelo interlocutor, parece um monge, quase sem emoções, apenas resolve problemas.&lt;/p&gt;</description></item><item><title>Como o Trae impede o vazamento de prompts do sistema</title><link>https://blog.jqknono.com/pt-br/blog/2025/10/15/como-o-trae-impede-o-vazamento-de-prompts-do-sistema/</link><pubDate>Wed, 15 Oct 2025 16:50:37 +0800</pubDate><guid>https://blog.jqknono.com/pt-br/blog/2025/10/15/como-o-trae-impede-o-vazamento-de-prompts-do-sistema/</guid><description>&lt;p&gt;Antes, criei uma ferramenta que utiliza grandes modelos para traduzir projetos inteiros: &lt;a href="https://marketplace.visualstudio.com/items?itemName=techfetch-dev.project-translator"&gt;Project-Translation&lt;/a&gt;. Escolhi um repositório popular que compila prompts do sistema &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools"&gt;system-prompts-and-models-of-ai-tools&lt;/a&gt; para tradução completa. Descobri que todos os prompts de ferramentas neste repositório podem ser traduzidos normalmente, exceto os prompts do &lt;strong&gt;Trae&lt;/strong&gt;, que nunca conseguem ser traduzidos com sucesso. Mesmo trocando de modelo e alterando prompts de tradução, não é possível obter uma tradução normal.&lt;/p&gt;
&lt;p&gt;Aqui está a versão original do prompt do Trae: &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt"&gt;https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Por que a métrica de taxa de recall é importante para grandes modelos</title><link>https://blog.jqknono.com/pt-br/blog/2025/10/14/por-que-a-m%C3%A9trica-de-taxa-de-recall-%C3%A9-importante-para-grandes-modelos/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/pt-br/blog/2025/10/14/por-que-a-m%C3%A9trica-de-taxa-de-recall-%C3%A9-importante-para-grandes-modelos/</guid><description>&lt;p&gt;Lendo alguns prompts de sistema, basicamente são todos muito extensos, expressões não refinadas. Alguns prompts principalmente ensinam o modelo a fazer as coisas.&lt;/p&gt;
&lt;p&gt;Além disso, notei que o roo code tem um interruptor para reenviar repetidamente o prompt do sistema para o modelo, o que indica que é possível reforçar a definição de papéis e a obediência a instruções. No entanto, isso aumenta o consumo de tokens.&lt;/p&gt;
&lt;p&gt;Talvez seja porque as coisas importantes precisam ser repetidas várias vezes para aumentar o peso nos cálculos, melhorar a probabilidade de serem confirmadas e, finalmente, obter resultados mais corretos. Infelizmente, esses resultados ainda são probabilisticamente corretos.&lt;/p&gt;</description></item></channel></rss>