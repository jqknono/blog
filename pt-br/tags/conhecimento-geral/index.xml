<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Conhecimento Geral on jqknono Blogs</title><link>https://blog.jqknono.com/pt-br/tags/conhecimento-geral/</link><description>Recent content in Conhecimento Geral on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>pt-br</language><lastBuildDate>Tue, 14 Oct 2025 09:59:51 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/pt-br/tags/conhecimento-geral/index.xml" rel="self" type="application/rss+xml"/><item><title>Por que a métrica de taxa de recall é importante para grandes modelos</title><link>https://blog.jqknono.com/pt-br/blog/2025/10/14/por-que-a-m%C3%A9trica-de-taxa-de-recall-%C3%A9-importante-para-grandes-modelos/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/pt-br/blog/2025/10/14/por-que-a-m%C3%A9trica-de-taxa-de-recall-%C3%A9-importante-para-grandes-modelos/</guid><description>&lt;p&gt;Lendo alguns prompts de sistema, basicamente são todos muito extensos, expressões não refinadas. Alguns prompts principalmente ensinam o modelo a fazer as coisas.&lt;/p&gt;
&lt;p&gt;Além disso, notei que o roo code tem um interruptor para reenviar repetidamente o prompt do sistema para o modelo, o que indica que é possível reforçar a definição de papéis e a obediência a instruções. No entanto, isso aumenta o consumo de tokens.&lt;/p&gt;
&lt;p&gt;Talvez seja porque as coisas importantes precisam ser repetidas várias vezes para aumentar o peso nos cálculos, melhorar a probabilidade de serem confirmadas e, finalmente, obter resultados mais corretos. Infelizmente, esses resultados ainda são probabilisticamente corretos.&lt;/p&gt;</description></item></channel></rss>