<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>IA on jqknono Blogs</title><link>https://blog.jqknono.com/fr-fr/tags/ia/</link><description>Recent content in IA on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>fr-fr</language><lastBuildDate>Tue, 23 Dec 2025 17:05:13 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/fr-fr/tags/ia/index.xml" rel="self" type="application/rss+xml"/><item><title>Les blogs techniques sont morts</title><link>https://blog.jqknono.com/fr-fr/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><guid>https://blog.jqknono.com/fr-fr/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;Au cours des dernières années, les outils d&amp;rsquo;écriture par intelligence artificielle (IA) tels que ChatGPT, Claude, etc. se sont rapidement répandus. Ils sont capables de générer des articles techniques fluides et même d&amp;rsquo;imiter le style d&amp;rsquo;écriture humain. Ce changement a suscité de vastes discussions dans la communauté des blogs techniques : beaucoup affirment que « les blogs techniques sont morts ». Cet article explorera l&amp;rsquo;impact des outils d&amp;rsquo;IA sur les blogs techniques et analysera l&amp;rsquo;orientation future des blogs techniques.&lt;/p&gt;</description></item><item><title>gpt-5-high est le modèle le plus adapté aux développeurs</title><link>https://blog.jqknono.com/fr-fr/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/fr-fr/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;Si vous avez besoin de coder, gpt-5-high est actuellement le seul modèle capable de vraiment améliorer l&amp;rsquo;efficacité.&lt;/p&gt;
&lt;p&gt;J&amp;rsquo;ai 10 mois d&amp;rsquo;expérience d&amp;rsquo;utilisation des modèles Claude, une utilisation occasionnelle de Gemini/DeepSeek/glm/grok, et je déteste profondément les modèles qui ne réfléchissent pas. Je dois admettre que Claude peut travailler pendant de longues périodes et excelle dans l&amp;rsquo;utilisation d&amp;rsquo;outils, mais son taux d&amp;rsquo;erreurs est très élevé, ce qui entraîne une faible taux d&amp;rsquo;utilisabilité des résultats. Il faut souvent ajuster, mais la capacité d&amp;rsquo;ajustement de Claude est très mauvaise. Il répète souvent, en grande quantité, de manière radicale, superflue, et désordonnée, vagabonde dans le codebase et laisse des déchets un peu partout. Après avoir dû faire plusieurs fois un hard reset après des heures de travail, je ressens une profonde aversion pour le comportement de ce &amp;ldquo;oiseau laborieux mais stupide&amp;rdquo; de Claude. Son style de travail convient très bien pour faire des recherches, obtenir un texte qui semble raisonnable mais qui ne résiste pas à l&amp;rsquo;examen, ou pour opérer un navigateur, exécuter des outils, écrire des scripts, modifier quelques pages. C&amp;rsquo;est là sa limite.&lt;/p&gt;</description></item><item><title>Le faux sentiment humain des LLM</title><link>https://blog.jqknono.com/fr-fr/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/fr-fr/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Certains forums interdisent aux modèles d&amp;rsquo;IA de se faire passer pour des humains lors d&amp;rsquo;activités sur le forum, comme publier ou répondre à des messages. En conséquence, les utilisateurs commencent à « chasser les sorcières », identifiant les messages aux expressions étranges comme potentiellement générés par l&amp;rsquo;IA, ce qui déclenche divers débats.&lt;/p&gt;
&lt;p&gt;Pourquoi le contenu généré par l&amp;rsquo;IA est-il si souvent détecté ? On peut supposer que le contenu produit par l&amp;rsquo;IA possède une sorte de « faux sentiment humain ». Bien que l&amp;rsquo;IA ait été nourrie avec d&amp;rsquo;immenses quantités de données d&amp;rsquo;activités humaines provenant d&amp;rsquo;Internet, elle continue souvent à susciter un sentiment d&amp;rsquo;incongruité. Peut-être n&amp;rsquo;a-t-elle pas de sensations tactiles, pas d&amp;rsquo;hormones, peut-être ne désire-t-elle pas les connexions sociales, ses désirs différant radicalement de ceux des humains. Dans les dialogues avec les humains, l&amp;rsquo;IA ne cherche ni à se vanter de manière détournée, ni à dénigrer les autres avec exagération, ni à se livrer à des commérages curieux. L&amp;rsquo;IA ne se vante pas, ne dénigre pas des tiers, et semble indifférente à l&amp;rsquo;utilisateur. On dirait un moine, presque dénué d&amp;rsquo;émotions, ne cherchant qu&amp;rsquo;à résoudre les problèmes.&lt;/p&gt;</description></item><item><title>Comment Trae empêche la fuite du prompt système</title><link>https://blog.jqknono.com/fr-fr/blog/2025/10/15/comment-trae-emp%C3%AAche-la-fuite-du-prompt-syst%C3%A8me/</link><pubDate>Wed, 15 Oct 2025 16:50:37 +0800</pubDate><guid>https://blog.jqknono.com/fr-fr/blog/2025/10/15/comment-trae-emp%C3%AAche-la-fuite-du-prompt-syst%C3%A8me/</guid><description>&lt;p&gt;J&amp;rsquo;ai récemment développé un outil utilisant un grand modèle pour traduire intégralement des projets : &lt;a href="https://marketplace.visualstudio.com/items?itemName=techfetch-dev.project-translator"&gt;Project-Translation&lt;/a&gt;. J&amp;rsquo;ai choisi un dépôt populaire de prompts système à traduire : &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools"&gt;system-prompts-and-models-of-ai-tools&lt;/a&gt;. J&amp;rsquo;ai découvert que tous les prompts des outils de ce dépôt pouvaient être traduits normalement, sauf ceux de &lt;strong&gt;Trae&lt;/strong&gt;, qui échouaient systématiquement. J&amp;rsquo;ai essayé de nombreux modèles et prompts de traduction, mais aucun n&amp;rsquo;a permis une traduction correcte.&lt;/p&gt;
&lt;p&gt;Version originale du prompt de Trae : &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt"&gt;https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Pourquoi l'indicateur de taux de rappel des grands modèles est important</title><link>https://blog.jqknono.com/fr-fr/blog/2025/10/14/pourquoi-lindicateur-de-taux-de-rappel-des-grands-mod%C3%A8les-est-important/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/fr-fr/blog/2025/10/14/pourquoi-lindicateur-de-taux-de-rappel-des-grands-mod%C3%A8les-est-important/</guid><description>&lt;p&gt;Après avoir lu quelques prompts système, ils sont généralement très verbeux et peu concis. Certains prompts enseignent principalement au modèle comment accomplir une tâche.&lt;/p&gt;
&lt;p&gt;J&amp;rsquo;ai également remarqué dans le code roo la possibilité d&amp;rsquo;activer l&amp;rsquo;envoi répété du prompt système au modèle, ce qui renforce la définition du rôle et le respect des instructions, mais augmente la consommation de tokens.&lt;/p&gt;
&lt;p&gt;Cela pourrait s&amp;rsquo;expliquer par le fait que les éléments importants doivent être répétés plusieurs fois pour augmenter leur poids lors du calcul et ainsi augmenter la probabilité d&amp;rsquo;obtenir un résultat correct. Malheureusement, ces résultats restent probabilistes.&lt;/p&gt;</description></item></channel></rss>