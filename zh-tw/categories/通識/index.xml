<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>通識 on jqknono Blogs</title><link>https://blog.jqknono.com/zh-tw/categories/%E9%80%9A%E8%AD%98/</link><description>Recent content in 通識 on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><lastBuildDate>Tue, 14 Oct 2025 09:59:51 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/zh-tw/categories/%E9%80%9A%E8%AD%98/index.xml" rel="self" type="application/rss+xml"/><item><title>為何大模型的召回率指標重要</title><link>https://blog.jqknono.com/zh-tw/blog/2025/10/14/%E7%82%BA%E4%BD%95%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%8C%87%E6%A8%99%E9%87%8D%E8%A6%81/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/zh-tw/blog/2025/10/14/%E7%82%BA%E4%BD%95%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%8C%87%E6%A8%99%E9%87%8D%E8%A6%81/</guid><description>&lt;p&gt;讀了一些系統提示詞, 基本都非常冗長, 表達不精煉. 一些提示詞主要是教模型做事.&lt;/p&gt;
&lt;p&gt;另外看到 roo code 裡有重複將系統提示詞發送到模型的開關, 說明是可以強化角色設定, 和指令遵循. 但會增加 token 消耗.&lt;/p&gt;
&lt;p&gt;可能是因为重要的東西需要重復多次, 以提升在計算時的權重, 提升被確認的概率, 最終得到更有可能正確的結果. 可惜的是, 這樣的結果仍然是概率性正確.&lt;/p&gt;
&lt;p&gt;長時間用過 claude 模型和 gpt5high 的可能有感觸, gpt5high 儘管很慢, 但是正確率非常高.&lt;/p&gt;
&lt;p&gt;是否可能和 gpt5 的召回率达到 100%有关.&lt;/p&gt;
&lt;p&gt;我在使用 AGENTS.md 指揮 gpt5 幹活時發現, 只需要非常簡練, 精煉的話, 即可以指揮 codex cli 幹活.
而使用 claude code 時, 常常需要將 CLAUDE.md 寫的非常&amp;quot;囉嗦&amp;quot;, 即使這樣, claude 也會忽略一些明確要求的注意事項. 改善方式也並不一定要重復說一個要求, 使用不同的詞彙如&amp;quot;必須&amp;quot;, &amp;ldquo;重要&amp;quot;等字詞, 使用括號, markdown 的加粗(**), 都可以加強遵循性.&lt;/p&gt;
&lt;p&gt;也就是說, 使用 claude 模型時, 對提示詞的要求較高, 細微詞彙變化即會影響模型表現.
而使用 gpt5 時, 對提示詞的要求不高, 只要精煉的表達不存在邏輯矛盾之處, codex cli 就可以做的很好. 如果存在邏輯矛盾之處, gpt5 會指出來.&lt;/p&gt;</description></item></channel></rss>