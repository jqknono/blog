<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>博客 on jqknono Blogs</title><link>https://blog.jqknono.com/zh-tw/blog/</link><description>Recent content in 博客 on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><managingEditor>https://blog.jqknono.com (jqknono)</managingEditor><webMaster>https://blog.jqknono.com (jqknono)</webMaster><lastBuildDate>Mon, 13 Nov 2023 14:15:31 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/zh-tw/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Project Translator VSCode 擴展實現專案多語言本地化</title><link>https://blog.jqknono.com/zh-tw/blog/2026/02/26/project-translator-vscode-extension/</link><pubDate>Thu, 26 Feb 2026 14:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2026/02/26/project-translator-vscode-extension/</guid><description>Project Translator 是一款功能強大的 VSCode 擴展，能夠基於 AI 實現專案級別的多語言自動翻譯，保持程式碼結構完整性的同時高效完成文件本地化。</description></item><item><title>GPT-5.3-Codex 初體驗：從驚喜到理性評估</title><link>https://blog.jqknono.com/zh-tw/blog/2026/02/17/gpt-53-codex-experience/</link><pubDate>Tue, 17 Feb 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2026/02/17/gpt-53-codex-experience/</guid><description>&lt;p&gt;OpenAI 在 GPT-5.3 正式版尚未發布之際，率先推出了 GPT-5.3-Codex 這一特化模型。從商業邏輯來看，這一決策不難理解。GPT-5.3-Codex 與標準版 GPT-5.3 定價相同，但其輸出更為積極，執行時間更短，記憶體佔用更少，這意味著更高的利潤空間。對於 OpenAI 而言，GPT-5.3-Codex 顯然是一個更具成本效益的選擇。&lt;/p&gt;
&lt;p&gt;在 GPT-5.3-Codex 發布的第一週，其使用體驗確實令人驚喜。模型回應速度明顯優於之前的版本，程式碼生成的回饋非常即時。對於需要快速迭代、頻繁互動的開發場景，這種效率提升帶來了直觀的生產力改善。當需要在短時間內獲得多個實現方案或快速驗證想法時，Codex 的積極輸出特性顯得尤為有用。&lt;/p&gt;
&lt;p&gt;然而進入第二週後，情況發生了明顯變化。模型的回應速度出現顯著下降，原本流暢的互動體驗開始變得卡頓。這種性能波動讓人聯想到雲服務中常見的資源調度問題，可能是在使用者量增長後，伺服器負載分配策略導致的降級服務。&lt;/p&gt;
&lt;p&gt;除了性能波動，更值得關注的是 Codex 在思維縝密程度上的不足。與非 Codex 系列相比，它在處理複雜邏輯、邊緣情況處理和程式碼健壯性方面表現較弱。當面對需要深度推理、多步驟規劃或抽象理解的任務時，Codex 更傾向於給出表面可行的方案，而缺乏對潛在問題的預判。&lt;/p&gt;
&lt;p&gt;這種差異背後反映了兩個模型在設計目標上的不同。Codex 似乎更注重生成速度和輸出活躍度，適合快速原型開發、程式碼補全和簡單任務的自動化。而非 Codex 系列則保留了更強的泛化能力，更注重方案的正確性和可靠性。&lt;/p&gt;
&lt;pre class="mermaid"&gt;flowchart LR
subgraph A[&amp;#34;GPT-5.3-Codex&amp;#34;]
direction LR
A1[&amp;#34;生成速度: 快&amp;#34;]
A2[&amp;#34;輸出活躍度: 高&amp;#34;]
A3[&amp;#34;思維縝密度: 中等&amp;#34;]
A4[&amp;#34;適合場景: 快速原型、程式碼補全、探索階段&amp;#34;]
end
subgraph B[&amp;#34;GPT-5.3 非Codex&amp;#34;]
direction LR
B1[&amp;#34;生成速度: 中等&amp;#34;]
B2[&amp;#34;輸出活躍度: 穩定&amp;#34;]
B3[&amp;#34;思維縝密度: 高&amp;#34;]
B4[&amp;#34;適合場景: 生產環境、關鍵專案、穩定期&amp;#34;]
end
A &amp;lt;--&amp;gt;|選擇權衡| B
classDef codex fill:#E3F2FD,stroke:#1565C0,stroke-width:2px,color:#0D47A1;
classDef standard fill:#E8F5E9,stroke:#2E7D32,stroke-width:2px,color:#1B5E20;
class A,A1,A2,A3,A4 codex;
class B,B1,B2,B3,B4 standard;&lt;/pre&gt;
&lt;p&gt;從實際開發場景來看，如果你的需求是快速獲得程式碼片段、實現已知明確的功能，或者需要在短時間內嘗試多種方案，Codex 的積極輸出和快速回應會帶來明顯優勢。但當專案進入穩定期，對程式碼品質、可維護性和長期穩定性有更高要求時，非 Codex 系列仍然是更可靠的選擇。&lt;/p&gt;</description></item><item><title>DoH 與 DoT 技術對比分析</title><link>https://blog.jqknono.com/zh-tw/blog/2026/02/11/doh-vs-dot-comparison/</link><pubDate>Wed, 11 Feb 2026 00:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2026/02/11/doh-vs-dot-comparison/</guid><description>&lt;p&gt;DNS over HTTPS (DoH) 和 DNS over TLS (DoT) 是兩種常見的加密 DNS 傳輸方式，它們透過不同的協定堆疊來實現 DNS 查詢的安全傳輸。DoT 的標準由 &lt;a href="https://datatracker.ietf.org/doc/html/rfc7858"&gt;RFC 7858&lt;/a&gt; 定義，而 DoH 則由 &lt;a href="https://datatracker.ietf.org/doc/html/rfc8484"&gt;DNS Queries over HTTPS (DoH)&lt;/a&gt; 標準化。理解這兩種技術的本質區別，需要從網路協定層次結構入手分析。&lt;/p&gt;
&lt;h2 id="網路協定層次結構"&gt;網路協定層次結構&lt;/h2&gt;
&lt;p&gt;現代網路協定堆疊採用分層設計，每一層提供不同的功能。DNS 作為應用層協定，本身並不綁定特定的傳輸方式，可以執行在多種承載協定之上。&lt;/p&gt;
&lt;p&gt;應用層 (L7) 包含 HTTP/1.1, HTTP/2, HTTP/3, FTP 和 DNS 等協定。值得注意的是，HTTP/3 的語意仍然在應用層，只是 QUIC 作為傳輸承載。安全層位於應用層和傳輸層之間，主要包括 TLS 及其變體。TLS 通常執行在 TCP 上，比如 HTTPS 和 DoT。DTLS 是 TLS 的資料報版本，可以執行在 UDP 上。QUIC 協定比較特殊，它將 TLS 1.3 的交握與金鑰衍生直接整合在協定內部。&lt;/p&gt;
&lt;p&gt;QUIC 可以被視作 L4.5 層協定，它基於 UDP 擴展，提供了傳統傳輸層的能力。傳輸層 (L4) 包含 TCP, UDP 和 QUIC。雖然從工程實作角度 QUIC 基於 UDP，但它自帶可靠性、擁塞控制、多工和加密交握等功能，因此在工程上被當作獨立的傳輸層協定。網路層 (L3) 使用 IP 協定 (IPv4/IPv6) 負責封包的路由與轉送。資料連結層 (L2) 包括乙太網路和 Wi-Fi (802.11) 等技術。&lt;/p&gt;</description></item><item><title>OpenRouter gpt-oss-120b 模型不支援中文請求的除錯記錄</title><link>https://blog.jqknono.com/zh-tw/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;在使用 &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; 提供的免費模型 API 時，我遇到了一個令人困惑的問題。同樣的請求結構，僅僅修改了提示詞的語言，就會出現完全不同的結果。&lt;/p&gt;
&lt;h2 id="問題復現"&gt;問題復現&lt;/h2&gt;
&lt;p&gt;我使用 &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; 模型進行測試，兩個請求的唯一區別在於提示詞語言。第一個請求使用中文提示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一個專業的本地化翻譯專家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;這個請求總是返回 429 狀態碼，表示請求過於頻繁或超出了配額限制。然而當我使用英文提示時：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;You are a professional localization translation expert&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;請求能夠正常回應，返回預期的模型輸出。&lt;/p&gt;</description></item><item><title>免費AI圖示生成工具彙總</title><link>https://blog.jqknono.com/zh-tw/blog/2026/02/02/free-ai-icon-generators/</link><pubDate>Mon, 02 Feb 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2026/02/02/free-ai-icon-generators/</guid><description>&lt;p&gt;隨著人工智慧技術的發展，設計師和開發者現在可以透過簡單的文字提示快速生成各類圖示。這些免費AI圖示生成工具大大降低了設計門檻，讓不具備專業設計技能的使用者也能創建出高品質的視覺元素。以下這些工具都支援透過文字描述生成圖像，輸出格式通常為PNG或SVG，部分工具還提供風格和配色調整功能。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.freepik.com/ai/icon-generator"&gt;Freepik AI圖示生成器&lt;/a&gt;是一款線上AI圖示生成工具，能夠根據文字描述生成SVG或PNG格式的圖示。這款工具非常適合網頁設計和UI設計場景，免費用戶可以使用但存在每日生成數量的限制。對於需要快速獲取圖示素材的設計工作來說，Freepik提供了一個便捷的解決方案。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.pixelcut.ai/create/icon-generator"&gt;Pixelcut AI圖示生成器&lt;/a&gt;專注於提供簡單直觀的圖示生成體驗。使用者只需輸入文字提示，即可生成自訂圖示。該工具的操作流程簡潔明瞭，適合不熟悉複雜設計軟體的使用者快速上手。生成的圖示可以直接下載使用，為個人專案或小型網站提供視覺支援。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://iconscout.com/ai/icon-generator"&gt;IconScout AI圖示生成器&lt;/a&gt;支援透過簡單文字生成圖示，並提供多種風格選擇。這款工具特別適合設計專案、部落格文章和展示用途。多樣化的風格選項讓使用者可以根據專案需求選擇合適的視覺風格，從而保持整體設計的一致性。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://quillbot.com/image-tools/ai-icon-generator"&gt;QuillBot AI圖示生成器&lt;/a&gt;作為免費線上工具，允許使用者透過文字描述快速生成圖示。該工具的一大優勢是生成後可以直接下載，無需額外的轉換步驟。這種即可使用的特性使得它成為需要快速獲取圖示素材使用者的理想選擇。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.recraft.ai/generate/icons"&gt;Recraft AI圖示生成器&lt;/a&gt;提供了更高級的客製化選項。使用者可以選擇預設風格，或者從已有的品牌圖像生成一致風格的圖示。該工具還支援自訂色彩等參數，這對於需要維護品牌視覺識別的企業來說尤為重要。透過Recraft生成的圖示可以與現有品牌元素保持視覺一致性。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.miricanvas.com/features/ja/ai-icon"&gt;MiriCanvas AI圖示工具&lt;/a&gt;是一款免費的AI圖示和標誌生成工具。它支援樣式選擇和文字輸入，透過簡單的操作流程即可生成圖示。該工具的設計注重使用者體驗，讓即使沒有設計背景的使用者也能輕鬆創建出滿意的圖示。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://perchance.org/ai-icon-generator"&gt;Perchance AI Icon Generator&lt;/a&gt;是一個無需註冊、無浮水印的免費AI圖示生成實驗工具。它的開放性和便捷性使其成為臨時專案或測試用途的不錯選擇。無需帳戶和登入步驟意味著使用者可以立即開始使用，這種簡化的使用流程適合追求效率的使用者。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://openart.ai/generator/icon"&gt;OpenArt AI圖示生成器&lt;/a&gt;提供免費AI圖示生成功能，可用於客製化應用程式圖示或其他視覺元素。該工具的生成能力較為全面，適合需要建立完整圖示集的使用者。透過文字提示控制生成結果，使用者可以根據具體需求調整圖示的細節。&lt;/p&gt;
&lt;pre class="mermaid"&gt;flowchart TD
A[AI圖示生成工具選擇] --&amp;gt; B{使用需求類型}
B --&amp;gt;|快速簡單| C[Pixelcut&amp;lt;br/&amp;gt;QuillBot]
B --&amp;gt;|設計專業| D[Freepik&amp;lt;br/&amp;gt;IconScout]
B --&amp;gt;|品牌一致性| E[Recraft]
B --&amp;gt;|無需註冊| F[Perchance]
B --&amp;gt;|完整圖示集| G[OpenArt]
B --&amp;gt;|樣式選擇| H[MiriCanvas]
C --&amp;gt; I{輸出格式}
D --&amp;gt; I
E --&amp;gt; I
F --&amp;gt; I
G --&amp;gt; I
H --&amp;gt; I
I --&amp;gt;|PNG/JPG| J[網頁使用]
I --&amp;gt;|SVG| K[向量設計]
I --&amp;gt;|兩者| L[多場景適配]
J --&amp;gt; M[注意版權條款]
K --&amp;gt; M
L --&amp;gt; M
M --&amp;gt; N[確認商業使用許可]&lt;/pre&gt;
&lt;p&gt;這些工具雖然提供了免費使用選項，但使用者需要注意免費額度和生成次數的限制。在使用前應當仔細閱讀各平台的使用條款，特別是關於輸出圖像版權的說明。部分工具的免費版可能禁止商業用途，或者要求在使用時註明來源。明確這些限制條件可以避免後續的法律風險。&lt;/p&gt;</description></item><item><title>Vibe Coding 的省錢公式與臨界點</title><link>https://blog.jqknono.com/zh-tw/blog/2026/01/07/vibe-coding-cost-formulas/</link><pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2026/01/07/vibe-coding-cost-formulas/</guid><description>&lt;p&gt;AI 編碼工具的計費模式可歸納為三類:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;按 token 計費&lt;/strong&gt;: 包括各類 API, Claude Code (Claude Pro), Codex Cli (ChatGPT Plus), 智譜 Lite/Pro, Cursor 新版等. 本質均為 token 計費, 部分產品提供套餐折扣.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;按 API 調用次數計費&lt;/strong&gt;: 如 OpenRouter (免費額度), ModelScope, Gemini Code Assistant (每日免費 1000 次), Chutes 等.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;按提示詞次數計費&lt;/strong&gt;: 如 Cursor 老版 (500 次), Github Copilot (300 次) 等.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這三類模式本質上均為模型推理與上下文處理付費, 差異體現在計價粒度和限額形式.&lt;/p&gt;
&lt;p&gt;本文建立統一的成本模型, 提供可操作的變量定義與計算公式, 確定在不同工作負載和方式下的工具選擇臨界點. 成本考量涵蓋現金支出, 時間消耗和返工風險.&lt;/p&gt;
&lt;h2 id="統一的總成本函數"&gt;統一的總成本函數&lt;/h2&gt;
&lt;p&gt;對任意工具 i, 在一個計費週期內的總成本可以寫成:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\mathrm{Total}_i &amp;amp;= \mathrm{Cash}_i + \mathrm{Time}_i + \mathrm{Risk}_i \
\mathrm{Time}_i &amp;amp;= R \cdot \mathrm{Hours}_i \
\mathrm{Risk}_i &amp;amp;= R \cdot \mathrm{ReworkHours}_i
\end{aligned}
$$&lt;/p&gt;</description></item><item><title>在 Windows 上搭建遠端瀏覽器調試入口</title><link>https://blog.jqknono.com/zh-tw/blog/2026/01/01/windows-remote-browser-cdp/</link><pubDate>Thu, 01 Jan 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2026/01/01/windows-remote-browser-cdp/</guid><description>&lt;p&gt;本文說明如何在 Windows 主機上運行 Chrome 並透過 CDP 提供遠端調試入口, 供局域網內的 Linux 客戶端或 MCP 連接使用. 方案核心是 Chrome 僅監聽 127.0.0.1, 由 portproxy 映射到 LAN 地址, 再透過防火牆限制遠端來源.&lt;/p&gt;
&lt;h2 id="拓撲與流向"&gt;拓撲與流向&lt;/h2&gt;
&lt;p&gt;下圖展示了端口在 Windows 主機內部的流向, 以及客戶端如何透過 LAN 地址訪問.&lt;/p&gt;
&lt;pre class="mermaid"&gt;flowchart TB
subgraph Windows
A[Chrome DevTools 127.0.0.1:9222] --&amp;gt; B[portproxy 192.168.31.2:9222]
B --&amp;gt; C[Windows Firewall]
end
D[Linux Client] --&amp;gt;|CDP| B
classDef local fill:#2c3e50,stroke:#ecf0f1,stroke-width:2px,color:#ecf0f1
classDef proxy fill:#3498db,stroke:#2980b9,stroke-width:2px,color:#fff
classDef firewall fill:#f39c12,stroke:#d35400,stroke-width:2px,color:#fff
classDef client fill:#27ae60,stroke:#229954,stroke-width:2px,color:#fff
class A local
class B proxy
class C firewall
class D client&lt;/pre&gt;
&lt;h2 id="啟動-chrome"&gt;啟動 Chrome&lt;/h2&gt;
&lt;p&gt;建議使用獨立的用戶目錄, 並顯式指定 remote debugging 地址, 這樣 Chrome 只對本機開放調試端口. 下面示例以 9222 端口為例, 請根據實際情況調整.&lt;/p&gt;</description></item><item><title>技術部落格已死</title><link>https://blog.jqknono.com/zh-tw/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;在過去幾年裡，人工智慧 (AI) 寫作工具如 ChatGPT、Claude 等迅速普及。它們能夠生成流暢的技術文章，甚至能模仿人類的寫作風格。這一變化引發了技術部落格圈的廣泛討論：許多人聲稱「技術部落格已死」。本文將探討 AI 工具對技術部落格的影響，並分析技術部落格的未來走向。&lt;/p&gt;
&lt;h2 id="ai-寫作工具的崛起"&gt;AI 寫作工具的崛起&lt;/h2&gt;
&lt;p&gt;AI 寫作工具的核心能力是理解自然語言並生成高品質文本。對於技術部落格作者而言，這些工具可以快速生成草稿、提供靈感，或者直接產出完整的文章。例如，當作者需要解釋一個複雜概念時，AI 可以生成清晰的說明段落；當作者缺乏時間時，AI 可以快速整理出一篇教程。&lt;/p&gt;
&lt;p&gt;然而，這種便利也帶來了副作用。大量低品質的 AI 生成內容開始充斥網際網路。這些內容往往缺乏深度，甚至包含錯誤，卻因為 SEO 優化而獲得高排名，擠壓了真正有價值的技術部落格的曝光機會。&lt;/p&gt;
&lt;h2 id="技術部落格的初衷"&gt;技術部落格的初衷&lt;/h2&gt;
&lt;p&gt;技術部落格最初是開發者分享經驗、記錄問題和建立個人品牌的方式。它的價值在於真實性和獨特性：作者將自己的實踐、思考和失敗經歷融入文章中，為讀者提供第一手的見解。&lt;/p&gt;
&lt;p&gt;AI 生成的內容雖然看似專業，但缺乏這種真實體驗。它無法分享作者在實際專案中遇到的坑，也無法提供獨特的解決方案。因此，純粹由 AI 生成的技術文章很難取代那些源自真實經驗的作品。&lt;/p&gt;
&lt;h2 id="人機協作的未來"&gt;人機協作的未來&lt;/h2&gt;
&lt;p&gt;與其將 AI 視為威脅，不如將其視為助手。聰明的技術部落客已經開始利用 AI 來提高效率：用 AI 進行頭腦風暴、檢查語法、優化表達，甚至生成程式碼範例。但文章的核心觀點和獨特洞察仍然來自作者本人。&lt;/p&gt;
&lt;p&gt;這種協作模式可以讓作者更專注於創造性工作，而將重複性任務交給 AI。最終產出的文章既保留了作者的個人色彩，又具備更高的可讀性和準確性。&lt;/p&gt;
&lt;h2 id="技術部落格的轉型"&gt;技術部落格的轉型&lt;/h2&gt;
&lt;p&gt;面對 AI 的衝擊，技術部落格需要轉型。未來的技術部落格可能會更加注重深度分析、獨家觀點和互動性。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;深度長文&lt;/strong&gt;：深入探討某個技術領域，提供 AI 難以複製的專業見解。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;專案日誌&lt;/strong&gt;：記錄真實的開發過程，分享成功與失敗的經驗。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;影音/播客&lt;/strong&gt;：多媒體形式能更好地傳達情感和細節。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;社群互動&lt;/strong&gt;：透過評論區、論壇等方式與讀者直接交流，建構知識共同體。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些形式都依賴於人類的創造力和經驗，是 AI 目前無法完全替代的。&lt;/p&gt;
&lt;h2 id="結論"&gt;結論&lt;/h2&gt;
&lt;p&gt;「技術部落格已死」或許是一種誇張的說法。AI 確實改變了技術寫作的格局，但同時也為作者提供了新的工具。那些能夠適應變化、將 AI 作為輔助而非替代的部落客，不僅不會消失，反而會產出更優質的內容。技術部落格不會死，它只會以更豐富的形式繼續存在。&lt;/p&gt;</description></item><item><title>OpenAI的取名藝術鑑賞</title><link>https://blog.jqknono.com/zh-tw/blog/2025/12/12/openai%E7%9A%84%E5%8F%96%E5%90%8D%E8%97%9D%E8%A1%93%E9%91%91%E8%B3%9E/</link><pubDate>Fri, 12 Dec 2025 11:46:01 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2025/12/12/openai%E7%9A%84%E5%8F%96%E5%90%8D%E8%97%9D%E8%A1%93%E9%91%91%E8%B3%9E/</guid><description>&lt;p&gt;這裡&lt;a href="https://platform.openai.com/docs/models/"&gt;https://platform.openai.com/docs/models/&lt;/a&gt;記錄了 OpenAI 的所有模型。&lt;/p&gt;
&lt;p&gt;太遠了的不說，從 &lt;code&gt;GPT-4&lt;/code&gt; 系列及同世代模型聊起，這是我彙總的表格：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名稱&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;th&gt;模型卡片連結&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ChatGPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o model used in ChatGPT&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/chatgpt-4o-latest"&gt;https://platform.openai.com/docs/models/chatgpt-4o-latest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4"&gt;https://platform.openai.com/docs/models/gpt-4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An older high-intelligence GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo"&gt;https://platform.openai.com/docs/models/gpt-4-turbo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated An older fast GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo-preview"&gt;https://platform.openai.com/docs/models/gpt-4-turbo-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smartest non-reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1"&gt;https://platform.openai.com/docs/models/gpt-4.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller, faster version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-mini"&gt;https://platform.openai.com/docs/models/gpt-4.1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 nano&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fastest, most cost-efficient version of GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-nano"&gt;https://platform.openai.com/docs/models/gpt-4.1-nano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecated large model.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.5-preview"&gt;https://platform.openai.com/docs/models/gpt-4.5-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, intelligent, flexible GPT model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o"&gt;https://platform.openai.com/docs/models/gpt-4o&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT-4o models capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for focused tasks&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini"&gt;https://platform.openai.com/docs/models/gpt-4o-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller model capable of audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Smaller realtime model for text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, affordable small model for web search&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini TTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Text-to-speech model powered by GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-tts"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-tts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Model capable of realtime text and audio inputs and outputs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;GPT model for web search in Chat Completions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Speech-to-text model powered by GPT-4o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Transcription model that identifies who&amp;rsquo;s speaking when&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Previous full o-series reasoning model&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1"&gt;https://platform.openai.com/docs/models/o1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-mini"&gt;https://platform.openai.com/docs/models/o1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o1 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-pro"&gt;https://platform.openai.com/docs/models/o1-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Reasoning model for complex tasks, succeeded by GPT-5&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3"&gt;https://platform.openai.com/docs/models/o3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Version of o3 with more compute for better responses&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-pro"&gt;https://platform.openai.com/docs/models/o3-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A small model alternative to o3&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-mini"&gt;https://platform.openai.com/docs/models/o3-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o4-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fast, cost-efficient reasoning model, succeeded by GPT-5 mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o4-mini"&gt;https://platform.openai.com/docs/models/o4-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;針對音頻(Audio)、實時(Realtime)、搜尋(Search)、音頻轉文字(Transcribe)、文字轉語音(TTS) 等場景，全都有相應模型。&lt;br&gt;
對同一場景，如音頻&lt;code&gt;Audio&lt;/code&gt;場景，提供了 &lt;code&gt;GPT-4o Audio&lt;/code&gt; 和 &lt;code&gt;GPT-4o mini Audio&lt;/code&gt; 兩個模型，用戶需要透過嘗試決定能否接受效果。&lt;br&gt;
音頻轉文字&lt;code&gt;Transcribe&lt;/code&gt;場景，提供了 &lt;code&gt;GPT-4o Transcribe&lt;/code&gt;、&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;、&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt; 三個模型。&lt;br&gt;
&lt;code&gt;ChatGPT-4o&lt;/code&gt; 是 &lt;code&gt;GPT-4o&lt;/code&gt; 的特別版，用於 ChatGPT 中，其他場景不能用。&lt;br&gt;
&lt;code&gt;GPT-4.1&lt;/code&gt;比&lt;code&gt;GPT-4&lt;/code&gt;更好，是符合直覺的，但&lt;code&gt;GPT-4o&lt;/code&gt;(4 歐)和&lt;code&gt;GPT-4.1&lt;/code&gt;或&lt;code&gt;GPT-4&lt;/code&gt;卻不好比較。時間線上，先出現的是&lt;code&gt;GPT-4&lt;/code&gt;，然後是&lt;code&gt;GPT-4o&lt;/code&gt;，再然後是&lt;code&gt;GPT-4.1&lt;/code&gt;，當然，仍然無法判斷&lt;code&gt;GPT-4o&lt;/code&gt;和&lt;code&gt;GPT-4.1&lt;/code&gt;誰更好。&lt;br&gt;
這裡插入下對「好」的定義，我個人將數學和推理結果正確率高作為「好」的定義，完全不將「速度」納入「好」的定義。但此前 OpenAI 可能認為速度和智慧同樣重要，因此出現奇怪的模型對比。進入 GPT-5 時代後，慶幸 OpenAI 開始放棄速度，追求智慧，至此模型間的對比才沒有歧義。一個快速的錯誤回答是浪費時間，沒有意義。&lt;/p&gt;</description></item><item><title>抢占服务器是个大便宜</title><link>https://blog.jqknono.com/zh-tw/blog/2025/12/05/%E6%8A%A2%E5%8D%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E4%B8%AA%E5%A4%A7%E4%BE%BF%E5%AE%9C/</link><pubDate>Fri, 05 Dec 2025 11:51:04 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/zh-tw/blog/2025/12/05/%E6%8A%A2%E5%8D%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E4%B8%AA%E5%A4%A7%E4%BE%BF%E5%AE%9C/</guid><description>&lt;p&gt;一直有个大便宜, 我从未在公开社区宣传过, 那就是阿里云的&lt;strong&gt;抢占服务器&lt;/strong&gt;非常划算.&lt;/p&gt;
&lt;h2 id="长期大折扣"&gt;长期大折扣&lt;/h2&gt;
&lt;p&gt;其在标题栏上写的&lt;em&gt;最高节省 90%&lt;/em&gt;, 并不夸张, 热门配置的服务器通常是乘以 20%的折扣, 也就是二折, 稍冷门的配置可以到 9%的折扣, 不到一折.&lt;/p&gt;
&lt;p&gt;热门服务器一类是小规格入门服务器, 如 2c2g,2c4g 等, 还有一类是&lt;em&gt;CPU/内存&lt;/em&gt;均衡型服务器, 如 1:2(4c8g), 1:4(4c16g,8c32g) 等, 这类服务器折扣少一点.&lt;/p&gt;
&lt;p&gt;冷门配置一般是指&lt;em&gt;CPU/内存&lt;/em&gt;不均衡的服务器, 如 1:8(8c64g), 1:1(8c8g) 等, 这类服务器折扣最多.&lt;/p&gt;
&lt;p&gt;今天查抢占服务器, 2c16g 的比 2c8g 的还便宜, 因为一个折扣到 9%, 一个折扣到 14%, 形成倒挂.&lt;/p&gt;
&lt;p&gt;阿里云抢占服务器的折扣率动态刷新, 我不清楚其算法如何, 但为我的使用场景节省了 85%的成本肯定是有的.&lt;/p&gt;
&lt;h2 id="抢占服务器使用前提"&gt;抢占服务器使用前提&lt;/h2&gt;
&lt;p&gt;使用抢占服务器的核心是将&lt;strong&gt;CPU/内存&lt;/strong&gt;和长期存储分离, 长期存储可以使用可分离的云盘, OSS, NAS, 数据库.&lt;/p&gt;
&lt;p&gt;其中云盘依赖于地域, 而抢占服务器的可用资源也和地域强相关, 因此尽管云盘是 IO 性能最强的稳定存储, 但并不能保证在所有地域都有抢占服务器可用, 我个人建议将其置为次选.&lt;/p&gt;
&lt;p&gt;其它三个存储都依赖网络, 而阿里云的内网通信免费, 尽管 IO 延迟可能较高, 但 IO 速率还可以, 主要是随机读写慢于云盘.&lt;/p&gt;
&lt;p&gt;OSS 是阿里云的对象存储, 适合存储主要用于&lt;strong&gt;读&lt;/strong&gt;的文件, 适合网络分享.&lt;/p&gt;
&lt;p&gt;NAS 是阿里云的网络存储, 适合存储各类文件, 读写均衡, 但不太适合公共分享.&lt;/p&gt;</description></item></channel></rss>