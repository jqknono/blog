<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Allgemein on jqknono Blogs</title><link>https://blog.jqknono.com/de-de/categories/allgemein/</link><description>Recent content in Allgemein on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>de-de</language><lastBuildDate>Tue, 14 Oct 2025 09:59:51 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/de-de/categories/allgemein/index.xml" rel="self" type="application/rss+xml"/><item><title>Warum Metriken zur Rückrufrate bei großen Modellen wichtig sind</title><link>https://blog.jqknono.com/de-de/blog/2025/10/14/warum-metriken-zur-r%C3%BCckrufrate-bei-gro%C3%9Fen-modellen-wichtig-sind/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2025/10/14/warum-metriken-zur-r%C3%BCckrufrate-bei-gro%C3%9Fen-modellen-wichtig-sind/</guid><description>&lt;p&gt;Nachdem ich einige System-Prompt gelesen habe, stelle ich fest, dass sie meist sehr langatmig und nicht präzise formuliert sind. Einige Prompts dienen hauptsächlich dazu, dem Modell beizubringen, wie man etwas macht.&lt;/p&gt;
&lt;p&gt;Außerdem habe ich gesehen, dass roo code einen Schalter enthält, um System-Prompts mehrfach an das Modell zu senden, was bedeutet, dass man Rollen und Befehle stärker verankern kann. Allerdings erhöht dies den Tokenverbrauch.&lt;/p&gt;
&lt;p&gt;Vielleicht liegt es daran, dass wichtige Dinge mehrfach wiederholt werden müssen, um ihr Gewicht in der Berechnung zu erhöhen und die Wahrscheinlichkeit zu steigern, dass sie korrekt erkannt werden, was letztlich zu wahrscheinlicher richtigen Ergebnissen führt. Leider sind diese Ergebnisse dennoch nur wahrscheinlich korrekt.&lt;/p&gt;</description></item></channel></rss>