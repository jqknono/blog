<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gedanken on jqknono Blogs</title><link>https://blog.jqknono.com/de-de/categories/gedanken/</link><description>Recent content in Gedanken on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>de-de</language><lastBuildDate>Wed, 11 Feb 2026 10:55:39 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/de-de/categories/gedanken/index.xml" rel="self" type="application/rss+xml"/><item><title>Rückkehr zu GPT Non-Codex</title><link>https://blog.jqknono.com/de-de/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;OpenAI scheint die Codex-Modelle wirklich stark pushen zu wollen. GPT-5.3 ist noch nicht draußen, aber zuerst kam GPT-5.3-Codex. Zum gleichen Preis ist Codex aktiver bei der Ausgabe, hat eine kürzere Ausführungszeit, eine geringere Speicherbelegungsdauer und bietet einen größeren Gewinnspielraum.&lt;/p&gt;
&lt;p&gt;In der ersten Woche nach der Veröffentlichung von GPT-5.3-Codex war meine Erfahrung sehr gut, hauptsächlich wegen der Geschwindigkeit und der zeitnahen Rückmeldung. Aber in der zweiten Woche verlangsamte es sich deutlich, und gleichzeitig ist seine Denkgenauigkeit nicht so gut wie die der GPT-Non-Codex-Serie. Daher empfehle ich weiterhin die Non-Codex-Serie. Die Wahrscheinlichkeit, dass sie beim ersten Mal richtig liegt, ist nach wie vor am höchsten. Sie tut nichts, was über die Beschreibung hinausgeht, aber das, was beschrieben werden kann, führt sie ohne Fehler aus.&lt;/p&gt;</description></item></channel></rss>