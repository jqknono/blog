<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2026 on jqknono Blogs</title><link>https://blog.jqknono.com/de-de/tags/2026/</link><description>Recent content in 2026 on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>de-de</language><lastBuildDate>Wed, 11 Feb 2026 10:55:39 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/de-de/tags/2026/index.xml" rel="self" type="application/rss+xml"/><item><title>Rückkehr zu GPT Non-Codex</title><link>https://blog.jqknono.com/de-de/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;OpenAI scheint die Codex-Modelle wirklich stark pushen zu wollen. GPT-5.3 ist noch nicht draußen, aber zuerst kam GPT-5.3-Codex. Zum gleichen Preis ist Codex aktiver bei der Ausgabe, hat eine kürzere Ausführungszeit, eine geringere Speicherbelegungsdauer und bietet einen größeren Gewinnspielraum.&lt;/p&gt;
&lt;p&gt;In der ersten Woche nach der Veröffentlichung von GPT-5.3-Codex war meine Erfahrung sehr gut, hauptsächlich wegen der Geschwindigkeit und der zeitnahen Rückmeldung. Aber in der zweiten Woche verlangsamte es sich deutlich, und gleichzeitig ist seine Denkgenauigkeit nicht so gut wie die der GPT-Non-Codex-Serie. Daher empfehle ich weiterhin die Non-Codex-Serie. Die Wahrscheinlichkeit, dass sie beim ersten Mal richtig liegt, ist nach wie vor am höchsten. Sie tut nichts, was über die Beschreibung hinausgeht, aber das, was beschrieben werden kann, führt sie ohne Fehler aus.&lt;/p&gt;</description></item><item><title>Debugging-Protokoll: Das OpenRouter gpt-oss-120b-Modell unterstützt keine chinesischen Anfragen</title><link>https://blog.jqknono.com/de-de/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;Bei der Verwendung der kostenlosen Modell-API von &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; bin ich auf ein verwirrendes Problem gestoßen. Bei derselben Anfragestruktur führte die Änderung der Sprache des Prompts zu völlig unterschiedlichen Ergebnissen.&lt;/p&gt;
&lt;h2 id="problemreproduktion"&gt;Problemreproduktion&lt;/h2&gt;
&lt;p&gt;Ich habe das Modell &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; getestet, wobei der einzige Unterschied zwischen den beiden Anfragen in der Sprache des Prompts lag. Die erste Anfrage verwendete einen chinesischen Prompt:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Diese Anfrage gab immer den Statuscode 429 zurück, was bedeutet, dass die Anfrage zu häufig war oder das Kontingent überschritten wurde. Als ich jedoch einen englischen Prompt verwendete:&lt;/p&gt;</description></item></channel></rss>