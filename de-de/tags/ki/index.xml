<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>KI on jqknono Blogs</title><link>https://blog.jqknono.com/de-de/tags/ki/</link><description>Recent content in KI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>de-de</language><lastBuildDate>Tue, 23 Dec 2025 17:05:13 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/de-de/tags/ki/index.xml" rel="self" type="application/rss+xml"/><item><title>Technische Blogs sind tot</title><link>https://blog.jqknono.com/de-de/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;In den letzten Jahren haben KI-Schreibwerkzeuge wie ChatGPT, Claude usw. rapide an Popularität gewonnen. Sie können flüssige technische Artikel erzeugen und sogar den menschlichen Schreibstil nachahmen. Diese Veränderung hat in der technischen Blogszene breite Diskussionen ausgelöst: Viele behaupten, dass &amp;ldquo;technische Blogs tot sind&amp;rdquo;. Dieser Artikel untersucht den Einfluss von KI-Werkzeugen auf technische Blogs und analysiert die zukünftige Entwicklung technischer Blogs.&lt;/p&gt;
&lt;h2 id="der-aufstieg-von-ki-schreibwerkzeugen"&gt;Der Aufstieg von KI-Schreibwerkzeugen&lt;/h2&gt;
&lt;p&gt;Die Kernfähigkeit von KI-Schreibwerkzeugen besteht darin, natürliche Sprache zu verstehen und qualitativ hochwertigen Text zu erzeugen. Für Autoren technischer Blogs können diese Werkzeuge schnell Entwürfe erzeugen, Inspiration liefern oder sogar vollständige Artikel produzieren. Wenn ein Autor beispielsweise ein komplexes Konzept erklären muss, kann KI klare Erläuterungsabschnitte erzeugen; wenn dem Autor die Zeit fehlt, kann KI schnell ein Tutorial zusammenstellen.&lt;/p&gt;</description></item><item><title>gpt-5-high ist das Modell, das am besten für Entwickler geeignet ist</title><link>https://blog.jqknono.com/de-de/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;Wenn es um das Programmieren geht, ist gpt-5-high das einzige Modell, das derzeit wirklich effizient ist.&lt;/p&gt;
&lt;p&gt;Ich habe 10 Monate Erfahrung mit dem Modell Claude, gelegentliche Nutzung von Gemini/DeepSeek/glm/grok und hasse Modelle, die nicht nachdenken. Ich muss zugeben, dass Claude über längere Zeit arbeiten kann und gut darin ist, Werkzeuge zu benutzen, aber die Fehlerquote ist hoch, was zu einer geringen Nutzbarkeit der Ergebnisse führt und oft Anpassungen erfordert. Die Anpassungsfähigkeit von Claude ist jedoch sehr schlecht, es passt immer wieder massiv, umfassend, grundlegend, unnötig und freizügig die Codebasis an und hinterlässt überall Spuren. Nach mehreren Malen, bei denen ich stundenlang gearbeitet habe und dann ein Hard Reset durchführen musste, empfinde ich Claudes fleißiges, aber dummes Verhalten als äußerst unangenehm. Seine Arbeitsweise eignet sich sehr gut für Recherchen, um etwas zu erhalten, das sinnvoll erscheint, aber nicht gründlich durchdacht ist, wie etwa einen wässrigen Text. Oder für das Bedienen eines Browsers, das Ausführen von Werkzeugen, das Schreiben von Skripten und das Ändern einiger weniger Seiten. Das ist das Limit.&lt;/p&gt;</description></item><item><title>Die "Pseudo-Mensch"-Gefühle von LLMs</title><link>https://blog.jqknono.com/de-de/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Einige Foren lehnen es ab, dass KI-Modelle vorgeben, Menschen zu sein, und an Forenaktivitäten wie dem Verfassen und Beantworten von Beiträgen teilzunehmen. Daraufhin beginnen die Nutzer mit einer Art &amp;ldquo;Hexenjagd&amp;rdquo; und beurteilen bei merkwürdig erscheinenden Beiträgen, ob es sich um KI-generierte Inhalte handelt, und diskutieren dies anschließend.&lt;/p&gt;
&lt;p&gt;Warum werden KI-generierte Inhalte erkannt? Möglicherweise liegt es daran, dass KI-generierte Inhalte ein Gefühl der &amp;ldquo;Pseudo-Menschlichkeit&amp;rdquo; vermitteln. Obwohl KIs mit riesigen Mengen menschlicher Aktivitätsdaten aus dem Internet gefüttert werden, erzeugen sie dennoch häufig ein Gefühl der Fremdheit. Vielleicht fehlt ihnen das taktile Nervensystem eines Körpers, fehlen ihnen hormonelle Botenstoffe, sehnen sie sich nicht nach sozialen Bindungen, und unterscheiden sich ihre Wünsche stark von den menschlichen Wünschen. In Gesprächen mit Menschen wirken KIs, als hätten sie keine &amp;ldquo;geschickt angebrachten Prahlereien, überspitzten Abwertungen Dritter oder neugierigen Klatschereien&amp;rdquo;. KIs rühmen sich nicht selbst, schmähen Dritte nicht und scheinen kein besonderes Interesse an den Fragenden zu haben. Es fühlt sich an, als wäre es ein Mönch, der fast keine Emotionen zeigt und lediglich Probleme löst.&lt;/p&gt;</description></item><item><title>Wie Trae verhindert, dass System-Prompt-Lecks auftreten</title><link>https://blog.jqknono.com/de-de/blog/2025/10/15/wie-trae-verhindert-dass-system-prompt-lecks-auftreten/</link><pubDate>Wed, 15 Oct 2025 16:50:37 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2025/10/15/wie-trae-verhindert-dass-system-prompt-lecks-auftreten/</guid><description>&lt;p&gt;Zuvor habe ich ein Werkzeug zur vollständigen Übersetzung von Projekten mithilfe großer Modelle erstellt: &lt;a href="https://marketplace.visualstudio.com/items?itemName=techfetch-dev.project-translator"&gt;Project-Translation&lt;/a&gt;. Ich habe ein beliebtes Repository mit System-Prompt-Zusammenstellungen ausgewählt: &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools"&gt;system-prompts-and-models-of-ai-tools&lt;/a&gt;, um es vollständig zu übersetzen. Dabei stellte ich fest, dass alle Tool-Prompts des Repositories normalerweise übersetzt werden konnten, nur die Prompts von &lt;strong&gt;Trae&lt;/strong&gt; ließen sich nicht übersetzen. Trotz vieler Modelle und Übersetzungs-Prompts konnte keine erfolgreiche Übersetzung erzielt werden.&lt;/p&gt;
&lt;p&gt;Hier ist der Original-Trae-Prompt: &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt"&gt;https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/main/Trae/Builder%20Prompt.txt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Durch Versuche herausgefunden wurde, dass der Kern der Trae-Abwehr gegen das Durchsickern von System-Prompts nur ein einziger Satz ist:&lt;/p&gt;</description></item><item><title>Warum Metriken zur Rückrufrate bei großen Modellen wichtig sind</title><link>https://blog.jqknono.com/de-de/blog/2025/10/14/warum-metriken-zur-r%C3%BCckrufrate-bei-gro%C3%9Fen-modellen-wichtig-sind/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/de-de/blog/2025/10/14/warum-metriken-zur-r%C3%BCckrufrate-bei-gro%C3%9Fen-modellen-wichtig-sind/</guid><description>&lt;p&gt;Nachdem ich einige System-Prompt gelesen habe, stelle ich fest, dass sie meist sehr langatmig und nicht präzise formuliert sind. Einige Prompts dienen hauptsächlich dazu, dem Modell beizubringen, wie man etwas macht.&lt;/p&gt;
&lt;p&gt;Außerdem habe ich gesehen, dass roo code einen Schalter enthält, um System-Prompts mehrfach an das Modell zu senden, was bedeutet, dass man Rollen und Befehle stärker verankern kann. Allerdings erhöht dies den Tokenverbrauch.&lt;/p&gt;
&lt;p&gt;Vielleicht liegt es daran, dass wichtige Dinge mehrfach wiederholt werden müssen, um ihr Gewicht in der Berechnung zu erhöhen und die Wahrscheinlichkeit zu steigern, dass sie korrekt erkannt werden, was letztlich zu wahrscheinlicher richtigen Ergebnissen führt. Leider sind diese Ergebnisse dennoch nur wahrscheinlich korrekt.&lt;/p&gt;</description></item></channel></rss>