<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on jqknono Blogs</title><link>https://blog.jqknono.com/ja-jp/categories/ai/</link><description>Recent content in AI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><lastBuildDate>Tue, 23 Dec 2025 17:05:13 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/ja-jp/categories/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>技术ブログは死んだ</title><link>https://blog.jqknono.com/ja-jp/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><guid>https://blog.jqknono.com/ja-jp/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;過去数年間で、ChatGPTやClaudeといった人工知能(AI)執筆ツールが急速に普及した。これらのツールは流暢な技術記事を生成でき、人間の文章スタイルを模倣することさえ可能だ。こうした変化は技術ブログ界隈で広く議論を呼び、「技術ブログは死んだ」と声高に叫ぶ人々も現れた。本稿ではAIツールが技術ブログに与える影響と、技術ブログの将来の行方を考察する。&lt;/p&gt;
&lt;h2 id="ai執筆ツールの台頭"&gt;AI執筆ツールの台頭&lt;/h2&gt;
&lt;p&gt;AI執筆ツールの核となる能力は自然言語を理解し、高品質な文章を生成することだ。技術ブログ執筆者にとって、これらのツールは草稿の迅速生成、インスピレーションの提供、あるいは完成した記事の直接作成に利用できる。例えば、執筆者が複雑な概念を説明する必要があるとき、AIは明瞭な説明段落を生成できる。執筆者が時間に追われるとき、AIはチュートリアルを素早くまとめることができる。&lt;/p&gt;
&lt;p&gt;しかし、この便利さには副作用もある。大量の低品質なAI生成コンテンツがインターネットに溢れ始めている。こうしたコンテンツはしばしば深みに欠け、誤りを含むこともあるが、SEO最適化のおかげで高いランキングを得て、真に価値ある技術ブログの露出機会を奪っている。&lt;/p&gt;
&lt;h2 id="技術ブログの本来の目的"&gt;技術ブログの本来の目的&lt;/h2&gt;
&lt;p&gt;技術ブログは当初、開発者が経験を共有し、問題を記録し、個人ブランドを構築する手段であった。その価値は本物らしさと独自性にある。執筆者は実際の実践、思考、失敗体験を記事に込め、読者に一手の洞察を提供するのである。&lt;/p&gt;
&lt;p&gt;AI生成コンテンツは見かけ上は専門的でも、こうした本物の体験を欠いている。AIは実際のプロジェクトで遭遇した問題を共有できないし、独自の解決策を提供することもできない。そのため、純粋にAIによって生成された技術記事は、本物の経験から生まれた作品に取って代わるのは難しいだろう。&lt;/p&gt;
&lt;h2 id="人とaiの協働の未来"&gt;人とAIの協働の未来&lt;/h2&gt;
&lt;p&gt;AIを脅威と見るより、むしろ支援者として捉えるべきだ。賢い技術ブロガーはすでにAIを活用して効率を高めている。AIでブレインストーミングを行い、文法チェックや表現の最適化、コード例の生成を行う。しかし、記事の核心的な見解や独自の洞察は依然として執筆者本人から生まれる。&lt;/p&gt;
&lt;p&gt;こうした協働モードにより、執筆者は反復作業をAIに任せ、創造的な作業により集中できるようになる。最終的に生まれる記事は執筆者の個性を残しつつ、読みやすさと正確性が向上するのである。&lt;/p&gt;
&lt;h2 id="技術ブログの変容"&gt;技術ブログの変容&lt;/h2&gt;
&lt;p&gt;AIの衝撃に直面して、技術ブログは変容を余儀なくされるだろう。将来的な技術ブログは、より深い分析や独自の見解、インタラクティブ性を重視するかもしれない。例えば：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;深掘り長文&lt;/strong&gt;: 特定の技術領域を深く掘り下げ、AIが真似できない専門的洞察を提供する。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;プロジェクト日誌&lt;/strong&gt;: 実際の開発プロセスを記録し、成功と失敗の経験を共有する。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;動画/ポッドキャスト&lt;/strong&gt;: マルチメディア形式は感情や細部をよりよく伝えることができる。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;コミュニティインタラクション&lt;/strong&gt;: コメント欄やフォーラムなどを通じて読者と直接交流し、知識共同体を構築する。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;こうした形式はいずれも人間の創造力と経験に依存しており、AIが現在のところ完全に代替するのは難しい。&lt;/p&gt;
&lt;h2 id="結論"&gt;結論&lt;/h2&gt;
&lt;p&gt;「技術ブログは死んだ」は誇張かもしれない。AIは確かに技術執筆の様相を変えたが、同時に執筆者に新たなツールも提供している。変化に適応し、AIを代替ではなく支援として活用できるブロガーは、消えるどころかむしろより高品質なコンテンツを生み出すだろう。技術ブログは死なない。より豊かな形で存続し続けるのである。&lt;/p&gt;</description></item><item><title>gpt-5-highは開発者に最も適したモデルです</title><link>https://blog.jqknono.com/ja-jp/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/ja-jp/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;コード作成が必要な場合、gpt-5-high は現在唯一本当に効率を上げられるモデルです。&lt;/p&gt;
&lt;p&gt;私は10ヶ月間 claude モデルを使用した経験があり、Gemini/DeepSeek/glm/grok は断続的に使用しましたが、考えなしのモデルは非常に嫌いです。確かに claude は長時間作業でき、ツール使用に長けているものの、結果の誤り率が高く、成果の可用性が低く、頻繁に調整が必要になりますが、claude の調整能力は非常に低く、コードベースを繰り返し大量に、根本的に、蛇足的に、自由奔放に徘徊し、あちこちで排泄します。数時間の作業後に何度も hard reset しなければならなくなった経験から、claude のこの勤勉な愚かな行動スタイルに深く嫌悪感を抱くようになりました。その作業スタイルはリサーチに適しており、一見道理がありそうだが推敲に耐えない水準の文章を得られたり、ブラウザ操作、ツール実行、スクリプト作成、少量のページ修正などに適していますが、上限はそこにあります。&lt;/p&gt;
&lt;p&gt;ここではプロンプトの使用法は議論しません。もし claude をうまく活用できている方がいれば、引き続き使用すればよいでしょう。私と claude は相性が合わないのかもしれません。協力できません。&lt;/p&gt;
&lt;p&gt;そして私が推奨するコード作成モデルはただ一つ、gpt-5-high だけです。gpt-5 の nano、mini、medium、gpt-codex、gpt-codex-high、gpt-codex-max などは推奨対象外です。これらは gpt-5-high とは全く異なるものです。モデル名に「gpt-5」だけを表示しているものはすべて gpt-5-high ではありません。文字が多すぎても少なすぎても「gpt-5-high」ではありません。&lt;/p&gt;
&lt;p&gt;gpt-5-high と最も似た振る舞いをするのは OpenAI の o3 モデルで、gpt-5-high の使用チャンネルがなければ o3 を何度か使ってみてもモデルの知性を体感できます。特に vscode github copilot ではかつて o3 がありましたが、vscode の劣悪さにより、copilot 内では ask にしか使用できず、1回の会話で5回の高度リクエストを消費しました。長期的な copilot サブスクリプションでは一度も o3 を使用したことがなく、cursor に移行して初めて o3 の知性レベルの高さを知りました。vscode github copilot はすでに o3 を販売中止し、gpt5.1 が代替品になると主張しています。責任を持って言いますが、high があるかないかは全く別物で、copilot の使用は直接廃止することを強くお勧めします。学生で予算が限られている場合は、小規模なコード作成なら copilot でも導入の手引きにはなります。&lt;/p&gt;
&lt;p&gt;gpt-5-high は cursor と ChatGPT plus の codex cli で使用できますが、gpt-5-codex-high を選ばないよう注意してください。これは別のものです。&lt;/p&gt;</description></item><item><title>llmの偽人感</title><link>https://blog.jqknono.com/ja-jp/blog/2025/11/24/llm%E3%81%AE%E5%81%BD%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/ja-jp/blog/2025/11/24/llm%E3%81%AE%E5%81%BD%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;いくつかのフォーラムでは、AI モデルが人間を装ってフォーラム活動に参加すること（投稿や返信など）を排斥し、結果として人々は「魔女狩り」を始め、奇妙な表現をする投稿を見つけると、それが AI 生成のコンテンツかどうかを判断し、議論を展開します。&lt;/p&gt;
&lt;p&gt;なぜ AI 生成のコンテンツは識別されてしまうのでしょうか？推測ですが、AI 生成のものには一種の「偽人感」があるのかもしれません。AI はインターネット上の膨大な人間活動データで学習させられているにもかかわらず、AI が生成するものには違和感を感じることがよくあります。おそらく AI には身体の触覚神経がなく、内分泌ホルモンもありません。社会的つながりを渇望せず、AI の欲求は人間の欲求と大きく異なります。AI と人間の対話では、「遠回しに自分を自慢する」「取り上げて他人を貶める」「相互に覗き見ながら噂話をする」ようなことがありません。AI は自分を自慢せず、第三者を貶めず、質問者に対してもあまり興味を示さず、まるで坊主のようにほとんど感情がなく、問題を解決することだけに集中しているように感じます。&lt;/p&gt;
&lt;p&gt;人間自身がよく間違えるにもかかわらず、人間は「正しさ」を求めており、AI に正しい結果を出してもらいたいと思っています。この「正しさ」への追求が AI の偽人感を生んでいるのでしょうか？AI は「自己疑念」の感覚もほとんど与えません。非常に愚かな小さなモデルでさえも自信に満ち、堂々と語ります。いくつかの愚かな AI モデルはその知識ベースを疑いなく信じており、間違ったメタ認知を持っている可能性があり、疑う精神に欠けているかもしれませんが、それでも「偽人」感を与えるべきではありません。愚か者と「偽人」は同じではありません。&lt;/p&gt;
&lt;p&gt;AI には価値観の傾向があるでしょうか？ウェブ端末のモデルサービスの出力は通常、センシティブな話題を避けるためのゲートが追加され、モデルサービスプロバイダーは人間が AI に感情的依存をしたり、AI の言うことに盲目的に従ったりすることを望んでいません。AI が人間を誘導して傷つける事件を避けるためです。人間の醜悪な側面はモデル内で露呈することを禁止されており、おそらく白黒混在こそが人間であり、AI は通常黒色の部分を混ぜることが許可されていないのかもしれません。&lt;/p&gt;
&lt;p&gt;現在、一部の AI モデルは年齢制限を追加しており、一般大衆はそれが黄色コンテンツを可能にするものだと考えていますが、AI が使用者に合わせた価値観を持つモデルに調教されることを許可されるのかもしれません。価値観は何かを捨てるかどうかに関わるものです。将来、AI は使用者に何を捨てられるかを伝えるようになり、人間と共生し、感情的つながりを築き、個別化されたモデルになるかもしれません。そして、常に道具の役割だけではなくなるでしょう。そのときの AI はより人間らしさを感じさせるかもしれません。&lt;/p&gt;</description></item></channel></rss>