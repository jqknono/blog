<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Algemene Kennis on jqknono Blogs</title><link>https://blog.jqknono.com/nl-nl/categories/algemene-kennis/</link><description>Recent content in Algemene Kennis on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>nl-nl</language><lastBuildDate>Tue, 14 Oct 2025 09:59:51 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/nl-nl/categories/algemene-kennis/index.xml" rel="self" type="application/rss+xml"/><item><title>Waarom de recall-meting belangrijk is voor grote modellen</title><link>https://blog.jqknono.com/nl-nl/blog/2025/10/14/waarom-de-recall-meting-belangrijk-is-voor-grote-modellen/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/nl-nl/blog/2025/10/14/waarom-de-recall-meting-belangrijk-is-voor-grote-modellen/</guid><description>&lt;p&gt;Ik heb een aantal systeemprompten gelezen, die vrijwel allemaal erg uitgebreid zijn en niet beknopt geformuleerd. Sommige prompten zijn vooral bedoeld om het model te leren hoe het iets moet doen.&lt;/p&gt;
&lt;p&gt;Daarnaast merk ik dat roo code een schakelaar heeft waarmee de systeemprompt herhaaldelijk naar het model kan worden verzonden, wat aangeeft dat de rolinstelling en instructievolging kunnen worden versterkt. Dit verhoogt echter het tokenverbruik.&lt;/p&gt;
&lt;p&gt;Misschien is het omdat belangrijke dingen meerdere keren herhaald moeten worden om het gewicht tijdens de berekening te verhogen en de kans op bevestiging te verhogen, wat uiteindelijk tot een grotere kans op correcte resultaten leidt. Spijtig genoeg zijn deze resultaten nog steeds probabilistisch correct.&lt;/p&gt;</description></item></channel></rss>