<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Overpeinzingen on jqknono Blogs</title><link>https://blog.jqknono.com/nl-nl/tags/overpeinzingen/</link><description>Recent content in Overpeinzingen on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>nl-nl</language><lastBuildDate>Wed, 11 Feb 2026 10:55:39 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/nl-nl/tags/overpeinzingen/index.xml" rel="self" type="application/rss+xml"/><item><title>return-to-gpt-non-codex</title><link>https://blog.jqknono.com/nl-nl/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/nl-nl/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;OpenAI lijkt het Codex-model erg te willen pushen. GPT-5.3 is er nog niet, maar GPT-5.3-Codex komt er wel eerst. Voor dezelfde prijs is de output van Codex actiever, is de uitvoeringstijd korter, het geheugengebruik minder en is de winstmarge groter.&lt;/p&gt;
&lt;p&gt;Ik heb GPT-5.3-Codex in de eerste week gebruikt en de ervaring was uitstekend, voornamelijk vanwege de snelheid en de snelle feedback. Maar in de tweede week vertraagde het aanzienlijk en is de nauwkeurigheid van de redenering niet op het niveau van de GPT niet-Codex serie. Daarom raad ik nog steeds de niet-Codex serie aan; de kans dat het in één keer goed is, blijft het hoogst. Het zal geen acties ondernemen die buiten de beschrijving vallen, maar wat er beschreven wordt, voert het foutloos uit.&lt;/p&gt;</description></item></channel></rss>