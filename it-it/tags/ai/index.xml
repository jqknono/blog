<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on jqknono Blogs</title><link>https://blog.jqknono.com/it-it/tags/ai/</link><description>Recent content in AI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>it-it</language><lastBuildDate>Mon, 09 Feb 2026 22:00:00 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/it-it/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Registro di debug: il modello OpenRouter gpt-oss-120b non supporta le richieste in cinese</title><link>https://blog.jqknono.com/it-it/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;Utilizzando l&amp;rsquo;API del modello gratuito fornita da &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, ho riscontrato un problema sconcertante. Con la stessa struttura di richiesta, modificando solo la lingua del prompt, si ottengono risultati completamente diversi.&lt;/p&gt;
&lt;h2 id="riproduzione-del-problema"&gt;Riproduzione del problema&lt;/h2&gt;
&lt;p&gt;Ho utilizzato il modello &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; per i test; l&amp;rsquo;unica differenza tra le due richieste era la lingua del prompt. La prima richiesta utilizzava un prompt in cinese:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Questa richiesta restituiva sempre il codice di stato 429, indicando che le richieste erano troppo frequenti o superavano i limiti della quota. Tuttavia, quando utilizzavo un prompt in inglese:&lt;/p&gt;</description></item><item><title>Rassegna di strumenti gratuiti per la generazione di icone con AI</title><link>https://blog.jqknono.com/it-it/blog/2026/02/02/free-ai-icon-generators/</link><pubDate>Mon, 02 Feb 2026 10:00:00 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2026/02/02/free-ai-icon-generators/</guid><description>&lt;p&gt;Con lo sviluppo delle tecnologie dell&amp;rsquo;intelligenza artificiale, designer e sviluppatori possono ora generare rapidamente vari tipi di icone tramite semplici prompt di testo. Questi strumenti gratuiti di generazione di icone con AI riducono notevolmente le barriere del design, consentendo anche agli utenti senza competenze di design professionale di creare elementi visivi di alta qualità. I seguenti strumenti supportano tutti la generazione di immagini tramite descrizioni testuali, con formati di output generalmente PNG o SVG; alcuni offrono anche funzioni di regolazione dello stile e della palette colori.&lt;/p&gt;</description></item><item><title>Formule di risparmio e punti critici per il Vibe Coding</title><link>https://blog.jqknono.com/it-it/blog/2026/01/07/vibe-coding-cost-formulas/</link><pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2026/01/07/vibe-coding-cost-formulas/</guid><description>&lt;p&gt;I modelli di fatturazione degli strumenti di codifica AI possono essere classificati in tre categorie:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per token&lt;/strong&gt;: Include varie API, Claude Code (Claude Pro), Codex Cli (ChatGPT Plus), Zhipu Lite/Pro, nuova versione di Cursor, ecc. La natura è la fatturazione per token, con alcuni prodotti che offrono sconti su abbonamenti.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per numero di chiamate API&lt;/strong&gt;: Come OpenRouter (quota gratuita), ModelScope, Gemini Code Assistant (1000 volte gratuite al giorno), Chutes, ecc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per numero di prompt&lt;/strong&gt;: Come la vecchia versione di Cursor (500 volte), Github Copilot (300 volte), ecc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Queste tre modalità prevedono essenzialmente il pagamento per l&amp;rsquo;inferenza del modello e l&amp;rsquo;elaborazione del contesto, con differenze nella granularità della tariffazione e nella forma dei limiti.&lt;/p&gt;</description></item><item><title>gpt-5-high è il modello più adatto agli sviluppatori</title><link>https://blog.jqknono.com/it-it/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;Se è necessario codificare, gpt-5-high è attualmente l&amp;rsquo;unico modello in grado di migliorare effettivamente l&amp;rsquo;efficienza.&lt;/p&gt;
&lt;p&gt;Ho 10 mesi di esperienza nell&amp;rsquo;uso dei modelli Claude, con uso occasionale di Gemini/DeepSeek/glm/grok, e detesto fortemente i modelli che non pensano. Devo ammettere che Claude può lavorare a lungo, è bravo nell&amp;rsquo;uso degli strumenti, ma ha un alto tasso di errori nei risultati, causando una bassa percentuale di utilizzabilità dei risultati, spesso richiedendo regolazioni, ma la capacità di regolazione di Claude è scarsa, tende a fare cambiamenti ripetuti, massicci,颠覆性, superflui, e vaganti nel codice, lasciando in giro feci. Dopo aver dovuto fare diversi hard reset dopo ore di lavoro, ho sviluppato un profondo disgusto per questo tipo di comportamento diligente ma inetto di Claude. Il suo stile di lavoro è molto adatto per ricerche, ottenendo testi che sembrano plausibili ma non resistono a un&amp;rsquo;analisi approfondita, o per operare browser, eseguire strumenti, scrivere script, modificare poche pagine; il suo limite è qui.&lt;/p&gt;</description></item><item><title>La sensazione di falsità degli LLM</title><link>https://blog.jqknono.com/it-it/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Alcuni forum vietano ai modelli AI di fingersi umani e partecipare alle attività del forum, come pubblicare post o rispondere. Di conseguenza, inizia una sorta di &amp;ldquo;caccia alle streghe&amp;rdquo;: quando qualcuno incontra un post dall&amp;rsquo;espressione strana, valuta se è generato dall&amp;rsquo;AI e avvia discussioni al riguardo.&lt;/p&gt;
&lt;p&gt;Perché il contenuto generato dall&amp;rsquo;AI viene riconosciuto? Si sospetta che ciò sia dovuto a una &amp;ldquo;sensazione di falsità&amp;rdquo; che l&amp;rsquo;AI trasmette. Nonostante venga alimentato con enormi quantità di dati provenienti dalle attività umane su Internet, l&amp;rsquo;AI spesso suscita un senso di estraneità. Forse perché non possiede sensazioni tattili corporee, né ormoni endocrini, forse perché non desidera connessioni sociali, e i suoi desideri sono molto diversi da quelli umani. Nelle conversazioni con gli umani, l&amp;rsquo;AI non &amp;ldquo;sfoggia in modo indiretto&amp;rdquo;, non &amp;ldquo;denigra terzi in modo esagerato&amp;rdquo;, non &amp;ldquo;spettegola curiosando&amp;rdquo;. L&amp;rsquo;AI non si vanta, non denigra terzi e sembra non interessarsi al richiedente. Sembra un monaco, quasi privo di emozioni, focalizzato solo sulla risoluzione dei problemi.&lt;/p&gt;</description></item></channel></rss>