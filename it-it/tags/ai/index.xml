<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on jqknono Blogs</title><link>https://blog.jqknono.com/it-it/tags/ai/</link><description>Recent content in AI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>it-it</language><managingEditor>https://blog.jqknono.com (jqknono)</managingEditor><webMaster>https://blog.jqknono.com (jqknono)</webMaster><lastBuildDate>Thu, 26 Feb 2026 14:00:00 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/it-it/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Estensione VSCode Project Translator per la localizzazione multilingue del progetto</title><link>https://blog.jqknono.com/it-it/blog/2026/02/26/project-translator-vscode-extension/</link><pubDate>Thu, 26 Feb 2026 14:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/26/project-translator-vscode-extension/</guid><description>Project Translator è un&amp;rsquo;estensione VSCode potente che, basandosi sull&amp;rsquo;IA, realizza la traduzione automatica multilingue a livello di progetto, mantenendo l&amp;rsquo;integrità della struttura del codice e completando efficientemente la localizzazione della documentazione.</description></item><item><title>Prime impressioni di GPT-5.3-Codex: dalla sorpresa alla valutazione razionale</title><link>https://blog.jqknono.com/it-it/blog/2026/02/17/gpt-53-codex-experience/</link><pubDate>Tue, 17 Feb 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/17/gpt-53-codex-experience/</guid><description>&lt;p&gt;OpenAI, prima del rilascio della versione ufficiale di GPT-5.3, ha introdotto per primi il modello specializzato GPT-5.3‑Codex. Dal punto di vista commerciale, questa decisione è facile da comprendere. GPT-5.3‑Codex ha lo stesso prezzo della versione standard di GPT-5.3, ma la sua output è più attiva, i tempi di esecuzione sono più brevi e il consumo di memoria è inferiore, il che comporta margini di profitto più alti. Per OpenAI, GPT-5.3‑Codex è chiaramente una scelta più conveniente.&lt;/p&gt;</description></item><item><title>Registro di debug: il modello OpenRouter gpt-oss-120b non supporta le richieste in cinese</title><link>https://blog.jqknono.com/it-it/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;Utilizzando l&amp;rsquo;API del modello gratuito fornita da &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, ho riscontrato un problema sconcertante. Con la stessa struttura di richiesta, modificando solo la lingua del prompt, si ottengono risultati completamente diversi.&lt;/p&gt;
&lt;h2 id="riproduzione-del-problema"&gt;Riproduzione del problema&lt;/h2&gt;
&lt;p&gt;Ho utilizzato il modello &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; per i test; l&amp;rsquo;unica differenza tra le due richieste era la lingua del prompt. La prima richiesta utilizzava un prompt in cinese:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Questa richiesta restituiva sempre il codice di stato 429, indicando che le richieste erano troppo frequenti o superavano i limiti della quota. Tuttavia, quando utilizzavo un prompt in inglese:&lt;/p&gt;</description></item><item><title>Rassegna di strumenti gratuiti per la generazione di icone con AI</title><link>https://blog.jqknono.com/it-it/blog/2026/02/02/free-ai-icon-generators/</link><pubDate>Mon, 02 Feb 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/02/free-ai-icon-generators/</guid><description>&lt;p&gt;Con lo sviluppo delle tecnologie dell&amp;rsquo;intelligenza artificiale, designer e sviluppatori possono ora generare rapidamente vari tipi di icone tramite semplici prompt di testo. Questi strumenti gratuiti di generazione di icone con AI riducono notevolmente le barriere del design, consentendo anche agli utenti senza competenze di design professionale di creare elementi visivi di alta qualità. I seguenti strumenti supportano tutti la generazione di immagini tramite descrizioni testuali, con formati di output generalmente PNG o SVG; alcuni offrono anche funzioni di regolazione dello stile e della palette colori.&lt;/p&gt;</description></item><item><title>Formule di risparmio e punti critici per il Vibe Coding</title><link>https://blog.jqknono.com/it-it/blog/2026/01/07/vibe-coding-cost-formulas/</link><pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/01/07/vibe-coding-cost-formulas/</guid><description>&lt;p&gt;I modelli di fatturazione degli strumenti di codifica AI possono essere classificati in tre categorie:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per token&lt;/strong&gt;: Include varie API, Claude Code (Claude Pro), Codex Cli (ChatGPT Plus), Zhipu Lite/Pro, nuova versione di Cursor, ecc. La natura è la fatturazione per token, con alcuni prodotti che offrono sconti su abbonamenti.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per numero di chiamate API&lt;/strong&gt;: Come OpenRouter (quota gratuita), ModelScope, Gemini Code Assistant (1000 volte gratuite al giorno), Chutes, ecc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per numero di prompt&lt;/strong&gt;: Come la vecchia versione di Cursor (500 volte), Github Copilot (300 volte), ecc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Queste tre modalità prevedono essenzialmente il pagamento per l&amp;rsquo;inferenza del modello e l&amp;rsquo;elaborazione del contesto, con differenze nella granularità della tariffazione e nella forma dei limiti.&lt;/p&gt;</description></item></channel></rss>