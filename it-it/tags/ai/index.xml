<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on jqknono Blogs</title><link>https://blog.jqknono.com/it-it/tags/ai/</link><description>Recent content in AI on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>it-it</language><lastBuildDate>Wed, 26 Nov 2025 14:44:57 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/it-it/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>gpt-5-high è il modello più adatto agli sviluppatori</title><link>https://blog.jqknono.com/it-it/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</link><pubDate>Wed, 26 Nov 2025 14:44:57 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2025/11/26/gpt-5-high%E6%98%AF%E6%9C%80%E9%80%82%E5%90%88%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;Se è necessario codificare, gpt-5-high è attualmente l&amp;rsquo;unico modello in grado di migliorare effettivamente l&amp;rsquo;efficienza.&lt;/p&gt;
&lt;p&gt;Ho 10 mesi di esperienza nell&amp;rsquo;uso dei modelli Claude, con uso occasionale di Gemini/DeepSeek/glm/grok, e detesto fortemente i modelli che non pensano. Devo ammettere che Claude può lavorare a lungo, è bravo nell&amp;rsquo;uso degli strumenti, ma ha un alto tasso di errori nei risultati, causando una bassa percentuale di utilizzabilità dei risultati, spesso richiedendo regolazioni, ma la capacità di regolazione di Claude è scarsa, tende a fare cambiamenti ripetuti, massicci,颠覆性, superflui, e vaganti nel codice, lasciando in giro feci. Dopo aver dovuto fare diversi hard reset dopo ore di lavoro, ho sviluppato un profondo disgusto per questo tipo di comportamento diligente ma inetto di Claude. Il suo stile di lavoro è molto adatto per ricerche, ottenendo testi che sembrano plausibili ma non resistono a un&amp;rsquo;analisi approfondita, o per operare browser, eseguire strumenti, scrivere script, modificare poche pagine; il suo limite è qui.&lt;/p&gt;</description></item><item><title>La sensazione di falsità degli LLM</title><link>https://blog.jqknono.com/it-it/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</link><pubDate>Mon, 24 Nov 2025 16:03:46 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2025/11/24/llm%E7%9A%84%E4%BC%AA%E4%BA%BA%E6%84%9F/</guid><description>&lt;p&gt;Alcuni forum vietano ai modelli AI di fingersi umani e partecipare alle attività del forum, come pubblicare post o rispondere. Di conseguenza, inizia una sorta di &amp;ldquo;caccia alle streghe&amp;rdquo;: quando qualcuno incontra un post dall&amp;rsquo;espressione strana, valuta se è generato dall&amp;rsquo;AI e avvia discussioni al riguardo.&lt;/p&gt;
&lt;p&gt;Perché il contenuto generato dall&amp;rsquo;AI viene riconosciuto? Si sospetta che ciò sia dovuto a una &amp;ldquo;sensazione di falsità&amp;rdquo; che l&amp;rsquo;AI trasmette. Nonostante venga alimentato con enormi quantità di dati provenienti dalle attività umane su Internet, l&amp;rsquo;AI spesso suscita un senso di estraneità. Forse perché non possiede sensazioni tattili corporee, né ormoni endocrini, forse perché non desidera connessioni sociali, e i suoi desideri sono molto diversi da quelli umani. Nelle conversazioni con gli umani, l&amp;rsquo;AI non &amp;ldquo;sfoggia in modo indiretto&amp;rdquo;, non &amp;ldquo;denigra terzi in modo esagerato&amp;rdquo;, non &amp;ldquo;spettegola curiosando&amp;rdquo;. L&amp;rsquo;AI non si vanta, non denigra terzi e sembra non interessarsi al richiedente. Sembra un monaco, quasi privo di emozioni, focalizzato solo sulla risoluzione dei problemi.&lt;/p&gt;</description></item><item><title>Come Trae impedisce la fuga dei prompt di sistema</title><link>https://blog.jqknono.com/it-it/blog/2025/10/15/come-trae-impedisce-la-fuga-dei-prompt-di-sistema/</link><pubDate>Wed, 15 Oct 2025 16:50:37 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2025/10/15/come-trae-impedisce-la-fuga-dei-prompt-di-sistema/</guid><description>&lt;p&gt;In precedenza ho realizzato uno strumento per la traduzione completa di progetti basato su grandi modelli &lt;a href="https://marketplace.visualstudio.com/items?itemName=techfetch-dev.project-translator"&gt;Project-Translation&lt;/a&gt;. Ho scelto un popolare repository di raccolta di prompt di sistema &lt;a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools"&gt;system-prompts-and-models-of-ai-tools&lt;/a&gt; per la traduzione completa e ho scoperto che tutti i prompt degli strumenti in questo repository possono essere tradotti normalmente, tranne quelli di &lt;strong&gt;Trae&lt;/strong&gt;, che non riescono mai a essere tradotti. Ho provato molti modelli e diversi prompt di traduzione, ma nessuno è riuscito a tradurre correttamente.&lt;/p&gt;</description></item><item><title>Perché l'indicatore di richiamo dei grandi modelli è importante</title><link>https://blog.jqknono.com/it-it/blog/2025/10/14/perch%C3%A9-lindicatore-di-richiamo-dei-grandi-modelli-%C3%A8-importante/</link><pubDate>Tue, 14 Oct 2025 09:59:51 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2025/10/14/perch%C3%A9-lindicatore-di-richiamo-dei-grandi-modelli-%C3%A8-importante/</guid><description>&lt;p&gt;Leggendo alcuni prompt di sistema, sono sostanzialmente molto prolissi e non espressi in modo conciso. Alcuni prompt insegnano principalmente al modello come svolgere compiti.&lt;/p&gt;
&lt;p&gt;Inoltre, ho notato che in roo code c&amp;rsquo;è un&amp;rsquo;opzione per inviare ripetutamente il prompt di sistema al modello, indicando che è possibile rafforzare l&amp;rsquo;impostazione del ruolo e il seguimento delle istruzioni. Tuttavia, ciò aumenta il consumo di token.&lt;/p&gt;
&lt;p&gt;Forse perché le cose importanti hanno bisogno di essere ripetute più volte per aumentare il loro peso durante il calcolo e migliorare la probabilità di conferma, ottenendo infine risultati più corretti. Sfortunatamente, questi risultati sono comunque corretti in modo probabilistico.&lt;/p&gt;</description></item><item><title>GitHub Spec Kit: Analisi approfondita del kit ufficiale per lo sviluppo guidato dalle specifiche</title><link>https://blog.jqknono.com/it-it/blog/2025/09/30/github-spec-kit-analisi-approfondita-del-kit-ufficiale-per-lo-sviluppo-guidato-dalle-specifiche/</link><pubDate>Tue, 30 Sep 2025 16:36:08 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2025/09/30/github-spec-kit-analisi-approfondita-del-kit-ufficiale-per-lo-sviluppo-guidato-dalle-specifiche/</guid><description>&lt;h1 id="github-spec-kit-analisi-approfondita-del-kit-ufficiale-per-lo-sviluppo-guidato-dalle-specifiche"&gt;GitHub Spec Kit: Analisi approfondita del kit ufficiale per lo sviluppo guidato dalle specifiche&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Lettore target: sviluppatori software, responsabili tecnici, ingegneri DevOps, product manager
Parole chiave: GitHub, Spec-Driven Development, AI, Strumenti per sviluppatori, Ingegneria software&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="sommario"&gt;Sommario&lt;/h2&gt;
&lt;p&gt;GitHub Spec Kit è il kit ufficiale per lo sviluppo guidato dalle specifiche lanciato da GitHub. Trasformando i documenti di specifica in codice eseguibile, ha completamente rivoluzionato il paradigma di sviluppo software tradizionale. Supporta diversi assistenti di programmazione AI e fornisce un flusso di lavoro completo per l&amp;rsquo;inizializzazione del progetto, la definizione delle specifiche, la pianificazione tecnica, la scomposizione dei compiti e la generazione del codice. Spec Kit permette agli sviluppatori di concentrarsi sui requisiti di business piuttosto che sui dettagli tecnici di implementazione, migliorando significativamente l&amp;rsquo;efficienza e la qualità del codice.&lt;/p&gt;</description></item></channel></rss>