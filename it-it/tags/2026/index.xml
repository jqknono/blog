<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2026 on jqknono Blogs</title><link>https://blog.jqknono.com/it-it/tags/2026/</link><description>Recent content in 2026 on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>it-it</language><lastBuildDate>Wed, 11 Feb 2026 10:55:39 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/it-it/tags/2026/index.xml" rel="self" type="application/rss+xml"/><item><title>return-to-gpt-non-codex</title><link>https://blog.jqknono.com/it-it/blog/2026/02/11/return-to-gpt-non-codex/</link><pubDate>Wed, 11 Feb 2026 10:55:39 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2026/02/11/return-to-gpt-non-codex/</guid><description>&lt;p&gt;OpenAI sembra voler spingere molto i modelli Codex; GPT-5.3 non è ancora uscito, ma è stato rilasciato per primo il GPT-5.3-Codex. Allo stesso prezzo, l&amp;rsquo;output di Codex è più proattivo, i tempi di esecuzione sono più brevi e l&amp;rsquo;occupazione della memoria è inferiore, lasciando maggiore spazio al profitto.&lt;/p&gt;
&lt;p&gt;Durante la prima settimana dopo l&amp;rsquo;uscita di GPT-5.3-Codex, la mia esperienza è stata ottima, principalmente grazie alla velocità e ai feedback tempestivi. Tuttavia, entrando nella seconda settimana, il rallentamento è stato evidente; allo stesso tempo, la sua rigore logico non è pari alla serie GPT non-Codex. Pertanto, raccomando ancora la serie non-Codex: la probabilità di eseguire correttamente il compito al primo tentativo rimane la più alta. Non compirà azioni al di fuori della descrizione, ma ciò che viene descritto verrà eseguito senza bug.&lt;/p&gt;</description></item><item><title>Registro di debug: il modello OpenRouter gpt-oss-120b non supporta le richieste in cinese</title><link>https://blog.jqknono.com/it-it/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><guid>https://blog.jqknono.com/it-it/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;Utilizzando l&amp;rsquo;API del modello gratuito fornita da &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, ho riscontrato un problema sconcertante. Con la stessa struttura di richiesta, modificando solo la lingua del prompt, si ottengono risultati completamente diversi.&lt;/p&gt;
&lt;h2 id="riproduzione-del-problema"&gt;Riproduzione del problema&lt;/h2&gt;
&lt;p&gt;Ho utilizzato il modello &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; per i test; l&amp;rsquo;unica differenza tra le due richieste era la lingua del prompt. La prima richiesta utilizzava un prompt in cinese:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Questa richiesta restituiva sempre il codice di stato 429, indicando che le richieste erano troppo frequenti o superavano i limiti della quota. Tuttavia, quando utilizzavo un prompt in inglese:&lt;/p&gt;</description></item></channel></rss>