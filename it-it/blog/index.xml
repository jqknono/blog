<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on jqknono Blogs</title><link>https://blog.jqknono.com/it-it/blog/</link><description>Recent content in Blog on jqknono Blogs</description><generator>Hugo -- gohugo.io</generator><language>it-it</language><managingEditor>https://blog.jqknono.com (jqknono)</managingEditor><webMaster>https://blog.jqknono.com (jqknono)</webMaster><lastBuildDate>Mon, 13 Nov 2023 14:15:31 +0800</lastBuildDate><atom:link href="https://blog.jqknono.com/it-it/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Estensione VSCode Project Translator per la localizzazione multilingue del progetto</title><link>https://blog.jqknono.com/it-it/blog/2026/02/26/project-translator-vscode-extension/</link><pubDate>Thu, 26 Feb 2026 14:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/26/project-translator-vscode-extension/</guid><description>Project Translator è un&amp;rsquo;estensione VSCode potente che, basandosi sull&amp;rsquo;IA, realizza la traduzione automatica multilingue a livello di progetto, mantenendo l&amp;rsquo;integrità della struttura del codice e completando efficientemente la localizzazione della documentazione.</description></item><item><title>Prime impressioni di GPT-5.3-Codex: dalla sorpresa alla valutazione razionale</title><link>https://blog.jqknono.com/it-it/blog/2026/02/17/gpt-53-codex-experience/</link><pubDate>Tue, 17 Feb 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/17/gpt-53-codex-experience/</guid><description>&lt;p&gt;OpenAI, prima del rilascio della versione ufficiale di GPT-5.3, ha introdotto per primi il modello specializzato GPT-5.3‑Codex. Dal punto di vista commerciale, questa decisione è facile da comprendere. GPT-5.3‑Codex ha lo stesso prezzo della versione standard di GPT-5.3, ma la sua output è più attiva, i tempi di esecuzione sono più brevi e il consumo di memoria è inferiore, il che comporta margini di profitto più alti. Per OpenAI, GPT-5.3‑Codex è chiaramente una scelta più conveniente.&lt;/p&gt;</description></item><item><title>Analisi comparativa delle tecnologie DoH e DoT</title><link>https://blog.jqknono.com/it-it/blog/2026/02/11/doh-vs-dot-comparison/</link><pubDate>Wed, 11 Feb 2026 00:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/11/doh-vs-dot-comparison/</guid><description>&lt;p&gt;DNS over HTTPS (DoH) e DNS over TLS (DoT) sono due comuni metodi di trasporto DNS crittografati, che implementano la trasmissione sicura delle query DNS utilizzando diversi stack di protocolli. Lo standard DoT è definito da &lt;a href="https://datatracker.ietf.org/doc/html/rfc7858"&gt;RFC 7858&lt;/a&gt;, mentre DoH è standardizzato da &lt;a href="https://datatracker.ietf.org/doc/html/rfc8484"&gt;DNS Queries over HTTPS (DoH)&lt;/a&gt;. Comprendere le differenze fondamentali tra queste due tecnologie richiede un&amp;rsquo;analisi a partire dalla struttura gerarchica dei protocolli di rete.&lt;/p&gt;
&lt;h2 id="struttura-gerarchica-dei-protocolli-di-rete"&gt;Struttura gerarchica dei protocolli di rete&lt;/h2&gt;
&lt;p&gt;Lo stack di protocolli di rete moderno adotta un design a strati, dove ogni livello fornisce funzionalità diverse. DNS, come protocollo di livello applicazione, non è legato a un metodo di trasporto specifico e può funzionare su vari protocolli di supporto.&lt;/p&gt;</description></item><item><title>Registro di debug: il modello OpenRouter gpt-oss-120b non supporta le richieste in cinese</title><link>https://blog.jqknono.com/it-it/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</link><pubDate>Mon, 09 Feb 2026 22:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/09/openrouter-gpt-oss-120b-chinese-bug/</guid><description>&lt;p&gt;Utilizzando l&amp;rsquo;API del modello gratuito fornita da &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, ho riscontrato un problema sconcertante. Con la stessa struttura di richiesta, modificando solo la lingua del prompt, si ottengono risultati completamente diversi.&lt;/p&gt;
&lt;h2 id="riproduzione-del-problema"&gt;Riproduzione del problema&lt;/h2&gt;
&lt;p&gt;Ho utilizzato il modello &lt;code&gt;openai/gpt-oss-120b:free&lt;/code&gt; per i test; l&amp;rsquo;unica differenza tra le due richieste era la lingua del prompt. La prima richiesta utilizzava un prompt in cinese:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;curl https://openrouter.ai/api/v1/chat/completions &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Content-Type: application/json&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -H &lt;span class="s2"&gt;&amp;#34;Authorization: Bearer sk-or-v1-xxxxxxxxxxxxxxxxxxxxxx&amp;#34;&lt;/span&gt; &lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; -d &lt;span class="s1"&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;model&amp;#34;: &amp;#34;openai/gpt-oss-120b:free&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;messages&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; &amp;#34;content&amp;#34;: &amp;#34;你是一个专业的本地化翻译专家&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="s1"&gt;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Questa richiesta restituiva sempre il codice di stato 429, indicando che le richieste erano troppo frequenti o superavano i limiti della quota. Tuttavia, quando utilizzavo un prompt in inglese:&lt;/p&gt;</description></item><item><title>Rassegna di strumenti gratuiti per la generazione di icone con AI</title><link>https://blog.jqknono.com/it-it/blog/2026/02/02/free-ai-icon-generators/</link><pubDate>Mon, 02 Feb 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/02/02/free-ai-icon-generators/</guid><description>&lt;p&gt;Con lo sviluppo delle tecnologie dell&amp;rsquo;intelligenza artificiale, designer e sviluppatori possono ora generare rapidamente vari tipi di icone tramite semplici prompt di testo. Questi strumenti gratuiti di generazione di icone con AI riducono notevolmente le barriere del design, consentendo anche agli utenti senza competenze di design professionale di creare elementi visivi di alta qualità. I seguenti strumenti supportano tutti la generazione di immagini tramite descrizioni testuali, con formati di output generalmente PNG o SVG; alcuni offrono anche funzioni di regolazione dello stile e della palette colori.&lt;/p&gt;</description></item><item><title>Formule di risparmio e punti critici per il Vibe Coding</title><link>https://blog.jqknono.com/it-it/blog/2026/01/07/vibe-coding-cost-formulas/</link><pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/01/07/vibe-coding-cost-formulas/</guid><description>&lt;p&gt;I modelli di fatturazione degli strumenti di codifica AI possono essere classificati in tre categorie:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per token&lt;/strong&gt;: Include varie API, Claude Code (Claude Pro), Codex Cli (ChatGPT Plus), Zhipu Lite/Pro, nuova versione di Cursor, ecc. La natura è la fatturazione per token, con alcuni prodotti che offrono sconti su abbonamenti.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per numero di chiamate API&lt;/strong&gt;: Come OpenRouter (quota gratuita), ModelScope, Gemini Code Assistant (1000 volte gratuite al giorno), Chutes, ecc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fatturazione per numero di prompt&lt;/strong&gt;: Come la vecchia versione di Cursor (500 volte), Github Copilot (300 volte), ecc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Queste tre modalità prevedono essenzialmente il pagamento per l&amp;rsquo;inferenza del modello e l&amp;rsquo;elaborazione del contesto, con differenze nella granularità della tariffazione e nella forma dei limiti.&lt;/p&gt;</description></item><item><title>Configurazione di un punto di accesso per il debug remoto del browser su Windows</title><link>https://blog.jqknono.com/it-it/blog/2026/01/01/windows-remote-browser-cdp/</link><pubDate>Thu, 01 Jan 2026 10:30:00 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2026/01/01/windows-remote-browser-cdp/</guid><description>&lt;p&gt;In questo articolo viene spiegato come eseguire Chrome su un host Windows e fornire un punto di accesso di debug remoto tramite CDP, utilizzabile da client Linux o MCP nella rete locale. L&amp;rsquo;approccio prevede che Chrome ascolti solo su 127.0.0.1, con portproxy che lo mappa su un indirizzo LAN e il firewall che limita le origini remote.&lt;/p&gt;
&lt;h2 id="topologia-e-flusso"&gt;Topologia e flusso&lt;/h2&gt;
&lt;p&gt;Il diagramma seguente mostra il flusso delle porte all&amp;rsquo;interno dell&amp;rsquo;host Windows e come i client accedono tramite indirizzo LAN.&lt;/p&gt;</description></item><item><title>I blog tecnici sono morti</title><link>https://blog.jqknono.com/it-it/blog/2025/12/23/technical-blogs-are-dead/</link><pubDate>Tue, 23 Dec 2025 17:05:13 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2025/12/23/technical-blogs-are-dead/</guid><description>&lt;p&gt;Negli ultimi anni, gli strumenti di scrittura basati sull&amp;rsquo;intelligenza artificiale (IA) come ChatGPT, Claude, ecc., si sono rapidamente diffusi. Questi strumenti sono in grado di generare articoli tecnici fluidi e persino di imitare lo stile di scrittura umano. Questo cambiamento ha suscitato ampi dibattiti nella comunità dei blog tecnici: molte persone sostengono che &amp;ldquo;i blog tecnici sono morti&amp;rdquo;. Questo articolo esplorerà l&amp;rsquo;impatto degli strumenti di IA sui blog tecnici e analizzerà il futuro dei blog tecnici.&lt;/p&gt;</description></item><item><title>L'arte della denominazione di OpenAI</title><link>https://blog.jqknono.com/it-it/blog/2025/12/12/larte-della-denominazione-di-openai/</link><pubDate>Fri, 12 Dec 2025 11:46:01 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2025/12/12/larte-della-denominazione-di-openai/</guid><description>&lt;p&gt;Qui &lt;a href="https://platform.openai.com/docs/models/"&gt;https://platform.openai.com/docs/models/&lt;/a&gt; sono registrati tutti i modelli di OpenAI.&lt;/p&gt;
&lt;p&gt;Non parliamo dei più vecchi, partiamo dalla serie &lt;code&gt;GPT-4&lt;/code&gt; e modelli contemporanei, questa è la mia tabella riassuntiva:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Nome&lt;/th&gt;
&lt;th&gt;Descrizione&lt;/th&gt;
&lt;th&gt;Link alla scheda del modello&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ChatGPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello GPT-4o utilizzato in ChatGPT&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/chatgpt-4o-latest"&gt;https://platform.openai.com/docs/models/chatgpt-4o-latest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Un vecchio modello GPT ad alta intelligenza&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4"&gt;https://platform.openai.com/docs/models/gpt-4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Un vecchio modello GPT ad alta intelligenza&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo"&gt;https://platform.openai.com/docs/models/gpt-4-turbo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4 Turbo Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecato - vecchio modello GPT veloce&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4-turbo-preview"&gt;https://platform.openai.com/docs/models/gpt-4-turbo-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello più intelligente senza ragionamento&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1"&gt;https://platform.openai.com/docs/models/gpt-4.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Versione più piccola e veloce di GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-mini"&gt;https://platform.openai.com/docs/models/gpt-4.1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.1 nano&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Versione più veloce ed efficiente di GPT-4.1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.1-nano"&gt;https://platform.openai.com/docs/models/gpt-4.1-nano&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Grande modello deprecato&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4.5-preview"&gt;https://platform.openai.com/docs/models/gpt-4.5-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello GPT veloce, intelligente e flessibile&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o"&gt;https://platform.openai.com/docs/models/gpt-4o&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modelli GPT-4o capaci di input/output audio&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello piccolo, veloce ed economico per task specifici&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini"&gt;https://platform.openai.com/docs/models/gpt-4o-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Audio&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello più piccolo capace di input/output audio&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello realtime più piccolo per testo e audio&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello piccolo ed economico per ricerche web&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello speech-to-text basato su GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o mini TTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello text-to-speech basato su GPT-4o mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-mini-tts"&gt;https://platform.openai.com/docs/models/gpt-4o-mini-tts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Realtime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello capace di input/output realtime per testo e audio&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-realtime-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Search Preview&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello GPT per ricerche web in Chat Completions&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-search-preview"&gt;https://platform.openai.com/docs/models/gpt-4o-search-preview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello speech-to-text basato su GPT-4o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello di trascrizione che identifica chi parla&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize"&gt;https://platform.openai.com/docs/models/gpt-4o-transcribe-diarize&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Precedente modello completo di ragionamento serie o&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1"&gt;https://platform.openai.com/docs/models/o1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Alternativa più piccola a o1&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-mini"&gt;https://platform.openai.com/docs/models/o1-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o1-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Versione di o1 con più potenza per risposte migliori&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o1-pro"&gt;https://platform.openai.com/docs/models/o1-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello di ragionamento per task complessi, sostituito da GPT-5&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3"&gt;https://platform.openai.com/docs/models/o3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-pro&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Versione di o3 con più potenza per risposte migliori&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-pro"&gt;https://platform.openai.com/docs/models/o3-pro&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o3-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Alternativa più piccola a o3&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o3-mini"&gt;https://platform.openai.com/docs/models/o3-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;o4-mini&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Modello di ragionamento veloce ed efficiente, sostituito da GPT-5 mini&lt;/td&gt;
&lt;td&gt;&lt;a href="https://platform.openai.com/docs/models/o4-mini"&gt;https://platform.openai.com/docs/models/o4-mini&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Per scenari come audio (Audio), tempo reale (Realtime), ricerca (Search), trascrizione audio (Transcribe), sintesi vocale (TTS), esistono modelli specifici.&lt;br&gt;
Per lo stesso scenario, ad esempio audio &lt;code&gt;Audio&lt;/code&gt;, sono disponibili due modelli: &lt;code&gt;GPT-4o Audio&lt;/code&gt; e &lt;code&gt;GPT-4o mini Audio&lt;/code&gt;, gli utenti devono testare per decidere se accettarne i risultati.&lt;br&gt;
Per la trascrizione audio &lt;code&gt;Transcribe&lt;/code&gt;, sono disponibili tre modelli: &lt;code&gt;GPT-4o Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o mini Transcribe&lt;/code&gt;, &lt;code&gt;GPT-4o Transcribe Diarize&lt;/code&gt;.&lt;br&gt;
&lt;code&gt;ChatGPT-4o&lt;/code&gt; è una versione speciale di &lt;code&gt;GPT-4o&lt;/code&gt; utilizzata in ChatGPT, non disponibile per altri scenari.&lt;/p&gt;</description></item><item><title>I server istantanei sono un grande affare</title><link>https://blog.jqknono.com/it-it/blog/2025/12/05/%E6%8A%A2%E5%8D%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E4%B8%AA%E5%A4%A7%E4%BE%BF%E5%AE%9C/</link><pubDate>Fri, 05 Dec 2025 11:51:04 +0800</pubDate><author>https://blog.jqknono.com (jqknono)</author><guid>https://blog.jqknono.com/it-it/blog/2025/12/05/%E6%8A%A2%E5%8D%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E4%B8%AA%E5%A4%A7%E4%BE%BF%E5%AE%9C/</guid><description>&lt;p&gt;C&amp;rsquo;è sempre stato un grande affare che non ho mai pubblicizzato in nessuna community pubblica: i &lt;strong&gt;server istantanei&lt;/strong&gt; di Alibaba Cloud sono incredibilmente convenienti.&lt;/p&gt;
&lt;h2 id="sconti-a-lungo-termine"&gt;Sconti a lungo termine&lt;/h2&gt;
&lt;p&gt;Nel titolo si afferma che il &lt;em&gt;risparmio massimo è del 90%&lt;/em&gt;, e non è affatto esagerato. Per i server con configurazioni popolari, solitamente si applica uno sconto del 20%, ovvero il 20% del prezzo originale, mentre per le configurazioni meno comuni si può arrivare al 9%, meno del 10% del prezzo originale.&lt;/p&gt;</description></item></channel></rss>